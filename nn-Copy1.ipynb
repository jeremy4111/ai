{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10 as data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>手機螢幕溫度(平均)</th>\n",
       "      <th>手機螢幕溫度(最大)</th>\n",
       "      <th>手機背蓋溫度(平均)</th>\n",
       "      <th>平均APP運作指標/小時</th>\n",
       "      <th>充電時間指標</th>\n",
       "      <th>手機電池電量</th>\n",
       "      <th>CPU跑分階級</th>\n",
       "      <th>手機外殼/包膜指標</th>\n",
       "      <th>外型平均曲率</th>\n",
       "      <th>上網頻率指標</th>\n",
       "      <th>通話頻率指標</th>\n",
       "      <th>新機/二手/老舊</th>\n",
       "      <th>內容容量比率</th>\n",
       "      <th>CPU效能等級</th>\n",
       "      <th>Underclocking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.984541</td>\n",
       "      <td>45.294944</td>\n",
       "      <td>52.784871</td>\n",
       "      <td>656.507337</td>\n",
       "      <td>0.225864</td>\n",
       "      <td>75.190124</td>\n",
       "      <td>3.319754</td>\n",
       "      <td>0.109481</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>2553.566565</td>\n",
       "      <td>2209.062206</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>0.833713</td>\n",
       "      <td>1.319754</td>\n",
       "      <td>0.428132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.540574</td>\n",
       "      <td>15.546263</td>\n",
       "      <td>64.786127</td>\n",
       "      <td>717.237752</td>\n",
       "      <td>0.232311</td>\n",
       "      <td>14.008806</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.090865</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>1829.663990</td>\n",
       "      <td>1810.428997</td>\n",
       "      <td>0.572666</td>\n",
       "      <td>12.506317</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.494871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.902370</td>\n",
       "      <td>8.047619</td>\n",
       "      <td>2.562656</td>\n",
       "      <td>-8000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.889610</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>-1.043000</td>\n",
       "      <td>0.675070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-600.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.642857</td>\n",
       "      <td>34.880952</td>\n",
       "      <td>43.504429</td>\n",
       "      <td>224.700000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>62.761544</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.058475</td>\n",
       "      <td>-0.055860</td>\n",
       "      <td>948.100000</td>\n",
       "      <td>579.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.976190</td>\n",
       "      <td>47.023810</td>\n",
       "      <td>53.053333</td>\n",
       "      <td>413.100000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>76.677489</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>2276.000000</td>\n",
       "      <td>1898.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.119048</td>\n",
       "      <td>57.345238</td>\n",
       "      <td>60.650000</td>\n",
       "      <td>834.969651</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>86.821260</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>0.078966</td>\n",
       "      <td>3839.552040</td>\n",
       "      <td>3455.073327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.619048</td>\n",
       "      <td>79.547619</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4412.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.776212</td>\n",
       "      <td>1.208233</td>\n",
       "      <td>8410.000000</td>\n",
       "      <td>8129.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        手機螢幕溫度(平均)   手機螢幕溫度(最大)   手機背蓋溫度(平均)  平均APP運作指標/小時       充電時間指標  \\\n",
       "count  3903.000000  3903.000000  3903.000000   3903.000000  3903.000000   \n",
       "mean     38.984541    45.294944    52.784871    656.507337     0.225864   \n",
       "std      14.540574    15.546263    64.786127    717.237752     0.232311   \n",
       "min       7.902370     8.047619     2.562656  -8000.000000     0.000000   \n",
       "25%      28.642857    34.880952    43.504429    224.700000     0.030303   \n",
       "50%      38.976190    47.023810    53.053333    413.100000     0.142857   \n",
       "75%      50.119048    57.345238    60.650000    834.969651     0.371429   \n",
       "max      75.619048    79.547619  4000.000000   4412.000000     0.966667   \n",
       "\n",
       "            手機電池電量      CPU跑分階級    手機外殼/包膜指標       外型平均曲率       上網頻率指標  \\\n",
       "count  3903.000000  3903.000000  3903.000000  3903.000000  3903.000000   \n",
       "mean     75.190124     3.319754     0.109481     0.015342  2553.566565   \n",
       "std      14.008806     0.684632     0.090865     0.125137  1829.663990   \n",
       "min      47.889610     3.000000     0.003690    -1.043000     0.675070   \n",
       "25%      62.761544     3.000000     0.058475    -0.055860   948.100000   \n",
       "50%      76.677489     3.000000     0.085307     0.005701  2276.000000   \n",
       "75%      86.821260     3.000000     0.143723     0.078966  3839.552040   \n",
       "max     100.000000     6.000000     1.776212     1.208233  8410.000000   \n",
       "\n",
       "            通話頻率指標     新機/二手/老舊       內容容量比率      CPU效能等級  Underclocking  \n",
       "count  3903.000000  3903.000000  3903.000000  3903.000000    3903.000000  \n",
       "mean   2209.062206     0.297463     0.833713     1.319754       0.428132  \n",
       "std    1810.428997     0.572666    12.506317     0.684632       0.494871  \n",
       "min       0.000000     0.000000  -600.000000     1.000000       0.000000  \n",
       "25%     579.800000     0.000000     0.802960     1.000000       0.000000  \n",
       "50%    1898.000000     0.000000     0.937191     1.000000       0.000000  \n",
       "75%    3455.073327     1.000000     0.987258     1.000000       1.000000  \n",
       "max    8129.000000     5.000000   500.000000     4.000000       1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#immport data\n",
    "data_frame = pd.read_excel(\"train.xlsx\")\n",
    "data_frame1 = pd.read_excel(\"data_anysis.xlsx\")\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手機螢幕溫度(平均)\n",
      "Shape Of The Before Ouliers:  (3903,)\n",
      "Shape Of The After Ouliers:  (3903,)\n",
      "===================================================================================================================\n",
      "手機螢幕溫度(最大)\n",
      "Shape Of The Before Ouliers:  (3903,)\n",
      "Shape Of The After Ouliers:  (3903,)\n",
      "===================================================================================================================\n",
      "手機背蓋溫度(平均)\n",
      "Shape Of The Before Ouliers:  (3903,)\n",
      "Shape Of The After Ouliers:  (3839,)\n",
      "===================================================================================================================\n",
      "平均APP運作指標/小時\n",
      "Shape Of The Before Ouliers:  (3839,)\n",
      "Shape Of The After Ouliers:  (3632,)\n",
      "===================================================================================================================\n",
      "充電時間指標\n",
      "Shape Of The Before Ouliers:  (3632,)\n",
      "Shape Of The After Ouliers:  (3632,)\n",
      "===================================================================================================================\n",
      "手機電池電量\n",
      "Shape Of The Before Ouliers:  (3632,)\n",
      "Shape Of The After Ouliers:  (3632,)\n",
      "===================================================================================================================\n",
      "CPU跑分階級\n",
      "Shape Of The Before Ouliers:  (3632,)\n",
      "Shape Of The After Ouliers:  (2952,)\n",
      "===================================================================================================================\n",
      "手機外殼/包膜指標\n",
      "Shape Of The Before Ouliers:  (2952,)\n",
      "Shape Of The After Ouliers:  (2949,)\n",
      "===================================================================================================================\n",
      "外型平均曲率\n",
      "Shape Of The Before Ouliers:  (2949,)\n",
      "Shape Of The After Ouliers:  (2892,)\n",
      "===================================================================================================================\n",
      "上網頻率指標\n",
      "Shape Of The Before Ouliers:  (2892,)\n",
      "Shape Of The After Ouliers:  (2892,)\n",
      "===================================================================================================================\n",
      "通話頻率指標\n",
      "Shape Of The Before Ouliers:  (2892,)\n",
      "Shape Of The After Ouliers:  (2892,)\n",
      "===================================================================================================================\n",
      "新機/二手/老舊\n",
      "Shape Of The Before Ouliers:  (2892,)\n",
      "Shape Of The After Ouliers:  (2885,)\n",
      "===================================================================================================================\n",
      "內容容量比率\n",
      "Shape Of The Before Ouliers:  (2885,)\n",
      "Shape Of The After Ouliers:  (2771,)\n",
      "===================================================================================================================\n",
      "CPU效能等級\n",
      "Shape Of The Before Ouliers:  (2771,)\n",
      "Shape Of The After Ouliers:  (2771,)\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>手機螢幕溫度(平均)</th>\n",
       "      <th>手機螢幕溫度(最大)</th>\n",
       "      <th>手機背蓋溫度(平均)</th>\n",
       "      <th>平均APP運作指標/小時</th>\n",
       "      <th>充電時間指標</th>\n",
       "      <th>手機電池電量</th>\n",
       "      <th>CPU跑分階級</th>\n",
       "      <th>手機外殼/包膜指標</th>\n",
       "      <th>外型平均曲率</th>\n",
       "      <th>上網頻率指標</th>\n",
       "      <th>通話頻率指標</th>\n",
       "      <th>新機/二手/老舊</th>\n",
       "      <th>內容容量比率</th>\n",
       "      <th>CPU效能等級</th>\n",
       "      <th>Underclocking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>2771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.327929</td>\n",
       "      <td>48.192487</td>\n",
       "      <td>54.220187</td>\n",
       "      <td>573.428495</td>\n",
       "      <td>0.234997</td>\n",
       "      <td>74.767248</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>2699.908807</td>\n",
       "      <td>2339.694106</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>0.892168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.201440</td>\n",
       "      <td>12.652690</td>\n",
       "      <td>11.739885</td>\n",
       "      <td>412.597872</td>\n",
       "      <td>0.236992</td>\n",
       "      <td>14.157427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052317</td>\n",
       "      <td>0.102983</td>\n",
       "      <td>1681.185940</td>\n",
       "      <td>1678.517468</td>\n",
       "      <td>0.550307</td>\n",
       "      <td>0.126315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.601610</td>\n",
       "      <td>16.904762</td>\n",
       "      <td>16.255404</td>\n",
       "      <td>2.806544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.889610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>-0.307900</td>\n",
       "      <td>11.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.790540</td>\n",
       "      <td>38.428571</td>\n",
       "      <td>46.933333</td>\n",
       "      <td>255.300000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>62.382756</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>-0.055830</td>\n",
       "      <td>1299.505295</td>\n",
       "      <td>968.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.452381</td>\n",
       "      <td>48.119048</td>\n",
       "      <td>54.853333</td>\n",
       "      <td>450.200000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>75.595238</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.085901</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>2491.000000</td>\n",
       "      <td>2137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.119048</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>61.511030</td>\n",
       "      <td>808.800000</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>87.209427</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.143479</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>3858.000000</td>\n",
       "      <td>3490.750415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.619048</td>\n",
       "      <td>79.547619</td>\n",
       "      <td>92.866667</td>\n",
       "      <td>2068.043920</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.288882</td>\n",
       "      <td>0.332365</td>\n",
       "      <td>8221.000000</td>\n",
       "      <td>7838.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        手機螢幕溫度(平均)   手機螢幕溫度(最大)   手機背蓋溫度(平均)  平均APP運作指標/小時       充電時間指標  \\\n",
       "count  2771.000000  2771.000000  2771.000000   2771.000000  2771.000000   \n",
       "mean     41.327929    48.192487    54.220187    573.428495     0.234997   \n",
       "std      12.201440    12.652690    11.739885    412.597872     0.236992   \n",
       "min      15.601610    16.904762    16.255404      2.806544     0.000000   \n",
       "25%      31.790540    38.428571    46.933333    255.300000     0.034483   \n",
       "50%      40.452381    48.119048    54.853333    450.200000     0.162500   \n",
       "75%      50.119048    57.642857    61.511030    808.800000     0.382716   \n",
       "max      75.619048    79.547619    92.866667   2068.043920     0.966667   \n",
       "\n",
       "            手機電池電量  CPU跑分階級    手機外殼/包膜指標       外型平均曲率       上網頻率指標  \\\n",
       "count  2771.000000   2771.0  2771.000000  2771.000000  2771.000000   \n",
       "mean     74.767248      3.0     0.102213     0.009980  2699.908807   \n",
       "std      14.157427      0.0     0.052317     0.102983  1681.185940   \n",
       "min      47.889610      3.0     0.016377    -0.307900    11.370000   \n",
       "25%      62.382756      3.0     0.059031    -0.055830  1299.505295   \n",
       "50%      75.595238      3.0     0.085901     0.004436  2491.000000   \n",
       "75%      87.209427      3.0     0.143479     0.069507  3858.000000   \n",
       "max     100.000000      3.0     0.288882     0.332365  8221.000000   \n",
       "\n",
       "            通話頻率指標     新機/二手/老舊       內容容量比率  CPU效能等級  Underclocking  \n",
       "count  2771.000000  2771.000000  2771.000000   2771.0    2771.000000  \n",
       "mean   2339.694106     0.330206     0.892168      1.0       0.443522  \n",
       "std    1678.517468     0.550307     0.126315      0.0       0.496890  \n",
       "min       0.000000     0.000000     0.460998      1.0       0.000000  \n",
       "25%     968.600000     0.000000     0.833479      1.0       0.000000  \n",
       "50%    2137.000000     0.000000     0.946174      1.0       0.000000  \n",
       "75%    3490.750415     1.000000     0.987878      1.0       1.000000  \n",
       "max    7838.000000     3.000000     1.000000      1.0       1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  #建構standardization的物件\n",
    "name_list_outlier =['手機螢幕溫度(平均)','手機螢幕溫度(最大)','手機背蓋溫度(平均)',\n",
    "            '平均APP運作指標/小時','充電時間指標','手機電池電量','CPU跑分階級',\n",
    "            '手機外殼/包膜指標','外型平均曲率','上網頻率指標','通話頻率指標','新機/二手/老舊','內容容量比率','CPU效能等級']\n",
    "#name_list_outlier =['手機螢幕溫度(平均)','手機螢幕溫度(最大)','手機背蓋溫度(平均)','平均APP運作指標/小時','上網頻率指標','通話頻率指標','內容容量比率']\n",
    "name_pre_outlier = ['Mobile Screen Temperature (Max)','Mobile Phone Back Cover Temperature (Average)','Average APP Operation Index/Hour','Mobile Phone Battery Level','Content Capacity Ratio']\n",
    "\n",
    "\n",
    "#離群值處理\n",
    "def  outlier_del(data_frame,name_list_outlier):\n",
    "    for i, name in enumerate(name_list_outlier):\n",
    "        print(name)\n",
    "        print(\"Shape Of The Before Ouliers: \", data_frame[name].shape)\n",
    "    \n",
    "        # 计算IQR\n",
    "        Q1 = np.percentile(data_frame[name], 25)\n",
    "        Q3 = np.percentile(data_frame[name], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        n = 2\n",
    "\n",
    "        # 定义离群值范围\n",
    "        lower_bound = Q1 - n * IQR\n",
    "        upper_bound = Q3 + n * IQR\n",
    "\n",
    "        # 过滤离群值\n",
    "        filtered_entries = ((data_frame[name] >= lower_bound) & (data_frame[name] <= upper_bound))\n",
    "        data_frame = data_frame[filtered_entries]\n",
    "    \n",
    "        print(\"Shape Of The After Ouliers: \",data_frame[name].shape)\n",
    "        print('===================================================================================================================')\n",
    "    return data_frame\n",
    "\n",
    "data_frame=outlier_del(data_frame,name_list_outlier)\n",
    "data_frame.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_data = data_frame['Underclocking'].to_numpy()\n",
    "feature_ex = ['手機螢幕溫度(平均)', '手機背蓋溫度(平均)', '充電時間指標', '手機電池電量', 'CPU跑分階級', '上網頻率指標', '通話頻率指標', '內容容量比率']\n",
    "#feature_ex=['手機螢幕溫度(平均)','手機背蓋溫度(平均)','平均APP運作指標/小時','充電時間指標','手機電池電量','手機外殼/包膜指標','通話頻率指標','新機/二手/老舊','CPU效能等級']\n",
    "x_data = data_frame[feature_ex].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1542, 1: 1229})\n",
      "Resampled dataset shape Counter({0: 1277, 1: 1277})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETomek\n",
    "print('Original dataset shape %s' % Counter(y_data))\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "\n",
    "x_data, y_data= smote_tomek.fit_resample(x_data, y_data)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.47142636e+00 -9.83724269e-01 -8.23314387e-01 ...  2.12896528e+00\n",
      "   2.22202980e+00  8.76126718e-01]\n",
      " [-8.86136063e-01 -1.54643002e+00 -9.71200801e-03 ...  2.31006168e-03\n",
      "  -7.11207654e-02  8.82041332e-01]\n",
      " [ 7.38591819e-01 -2.61140172e-01  2.89661356e+00 ...  3.37574156e-01\n",
      "   3.79446744e-01  8.82041332e-01]\n",
      " ...\n",
      " [-6.21727858e-01  2.33853050e+00 -8.28228437e-01 ... -1.36281724e+00\n",
      "  -1.38945695e+00 -2.02544544e-01]\n",
      " [-4.77671296e-01 -1.11193717e+00  1.06222201e+00 ...  7.28725622e-01\n",
      "   6.67671749e-01  1.36370603e-01]\n",
      " [ 6.91370771e-02 -1.57376634e+00  1.08680641e+00 ...  9.23948374e-01\n",
      "   8.79233631e-01  3.71879476e-01]]\n",
      "[0 0 1 ... 1 1 1]\n",
      "[[ 1.47142636e+00 -9.83724269e-01 -8.23314387e-01 ...  2.12896528e+00\n",
      "   2.22202980e+00  8.76126718e-01]\n",
      " [-8.86136063e-01 -1.54643002e+00 -9.71200801e-03 ...  2.31006168e-03\n",
      "  -7.11207654e-02  8.82041332e-01]\n",
      " [ 7.38591819e-01 -2.61140172e-01  2.89661356e+00 ...  3.37574156e-01\n",
      "   3.79446744e-01  8.82041332e-01]\n",
      " ...\n",
      " [-6.21727858e-01  2.33853050e+00 -8.28228437e-01 ... -1.36281724e+00\n",
      "  -1.38945695e+00 -2.02544544e-01]\n",
      " [-4.77671296e-01 -1.11193717e+00  1.06222201e+00 ...  7.28725622e-01\n",
      "   6.67671749e-01  1.36370603e-01]\n",
      " [ 6.91370771e-02 -1.57376634e+00  1.08680641e+00 ...  9.23948374e-01\n",
      "   8.79233631e-01  3.71879476e-01]]\n",
      "[0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "def data_normalized(data):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_normalized = min_max_scaler.fit_transform(data)\n",
    "    return data_normalized\n",
    "def data_standardized(data):\n",
    "    standard_scaler = StandardScaler()\n",
    "    data_standardized = standard_scaler.fit_transform(data)\n",
    "    return data_standardized \n",
    "x_data=data_normalized(x_data)\n",
    "x_data=data_standardized(x_data)\n",
    "print(x_data) \n",
    "print(y_data) \n",
    "print(x_data) \n",
    "print(y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca=PCA(n_components=6)\n",
    "#x_data=pca.fit(x_data).transform(x_data)\n",
    "#np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: (2170, 8)\n",
      "Xtrain type: <class 'numpy.ndarray'>\n",
      "Xtest shape: (384, 8)\n",
      "Xtest type: <class 'numpy.ndarray'>\n",
      "ytrain shape: (2170,)\n",
      "ytrain type: <class 'numpy.ndarray'>\n",
      "ytest shape: (384,)\n",
      "ytest type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 使用 train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(x_data, y_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Xtrain shape:\", Xtrain.shape)\n",
    "print(\"Xtrain type:\", type(Xtrain))\n",
    "print(\"Xtest shape:\", Xtest.shape)\n",
    "print(\"Xtest type:\", type(Xtest))\n",
    "print(\"ytrain shape:\", ytrain.shape)\n",
    "print(\"ytrain type:\", type(ytrain))\n",
    "print(\"ytest shape:\", ytest.shape)\n",
    "print(\"ytest type:\", type(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1088, 1: 1082})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.keras import BalancedBatchGenerator\n",
    "from imblearn.under_sampling import NearMiss\n",
    "#undersampler = RandomUnderSampler(sampling_strategy='auto')\n",
    "print('Original dataset shape %s' % Counter(ytrain))\n",
    "# 创建一个平衡批生成器\n",
    "train_generator = BalancedBatchGenerator(Xtrain, ytrain, sampler=NearMiss(), batch_size=32, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,201</span> (47.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,201\u001b[0m (47.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,201</span> (47.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,201\u001b[0m (47.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "l2_regularizer = tf.keras.regularizers.l2(0.05)\n",
    "input_features = x_data.shape[1]\n",
    "print( x_data.shape[1])\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_features,)),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.001),\n",
    "    tf.keras.layers.Dense(32, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(16, activation='tanh',kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dense(8, activation='tanh', kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4, activation='tanh'),# kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dense(2, activation='tanh'), #kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),     \n",
    "])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.4939 - loss: 2.2976 - learning_rate: 0.0100\n",
      "Epoch 2/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.5503 - loss: 2.0681 - learning_rate: 0.0100\n",
      "Epoch 3/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.5796 - loss: 1.8784 - learning_rate: 0.0100\n",
      "Epoch 4/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6017 - loss: 1.7235 - learning_rate: 0.0100\n",
      "Epoch 5/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6145 - loss: 1.5849 - learning_rate: 0.0100\n",
      "Epoch 6/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6242 - loss: 1.4635 - learning_rate: 0.0100\n",
      "Epoch 7/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6161 - loss: 1.3624 - learning_rate: 0.0100\n",
      "Epoch 8/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6417 - loss: 1.2699 - learning_rate: 0.0100\n",
      "Epoch 9/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6337 - loss: 1.1906 - learning_rate: 0.0100\n",
      "Epoch 10/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6407 - loss: 1.1257 - learning_rate: 0.0100\n",
      "Epoch 11/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6514 - loss: 1.0670 - learning_rate: 0.0100\n",
      "Epoch 12/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6537 - loss: 1.0086 - learning_rate: 0.0100\n",
      "Epoch 13/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6463 - loss: 0.9686 - learning_rate: 0.0100\n",
      "Epoch 14/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6538 - loss: 0.9288 - learning_rate: 0.0100\n",
      "Epoch 15/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6567 - loss: 0.8887 - learning_rate: 0.0100\n",
      "Epoch 16/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6472 - loss: 0.8597 - learning_rate: 0.0099\n",
      "Epoch 17/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6528 - loss: 0.8386 - learning_rate: 0.0099\n",
      "Epoch 18/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6564 - loss: 0.8114 - learning_rate: 0.0099\n",
      "Epoch 19/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6814 - loss: 0.7903 - learning_rate: 0.0099\n",
      "Epoch 20/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6627 - loss: 0.7765 - learning_rate: 0.0099\n",
      "Epoch 21/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6558 - loss: 0.7610 - learning_rate: 0.0099\n",
      "Epoch 22/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6778 - loss: 0.7412 - learning_rate: 0.0099\n",
      "Epoch 23/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.6645 - loss: 0.7298 - learning_rate: 0.0099\n",
      "Epoch 24/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6510 - loss: 0.7257 - learning_rate: 0.0099\n",
      "Epoch 25/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6690 - loss: 0.7119 - learning_rate: 0.0099\n",
      "Epoch 26/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6593 - loss: 0.7113 - learning_rate: 0.0098\n",
      "Epoch 27/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6618 - loss: 0.7011 - learning_rate: 0.0098\n",
      "Epoch 28/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6642 - loss: 0.6907 - learning_rate: 0.0098\n",
      "Epoch 29/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6738 - loss: 0.6871 - learning_rate: 0.0098\n",
      "Epoch 30/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6645 - loss: 0.6843 - learning_rate: 0.0098\n",
      "Epoch 31/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6730 - loss: 0.6713 - learning_rate: 0.0098\n",
      "Epoch 32/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6746 - loss: 0.6699 - learning_rate: 0.0098\n",
      "Epoch 33/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6554 - loss: 0.6778 - learning_rate: 0.0098\n",
      "Epoch 34/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6642 - loss: 0.6655 - learning_rate: 0.0098\n",
      "Epoch 35/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6708 - loss: 0.6699 - learning_rate: 0.0098\n",
      "Epoch 36/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6799 - loss: 0.6578 - learning_rate: 0.0097\n",
      "Epoch 37/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6660 - loss: 0.6594 - learning_rate: 0.0097\n",
      "Epoch 38/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6796 - loss: 0.6552 - learning_rate: 0.0097\n",
      "Epoch 39/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6693 - loss: 0.6617 - learning_rate: 0.0097\n",
      "Epoch 40/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6564 - loss: 0.6534 - learning_rate: 0.0097\n",
      "Epoch 41/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6631 - loss: 0.6574 - learning_rate: 0.0097\n",
      "Epoch 42/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6805 - loss: 0.6535 - learning_rate: 0.0097\n",
      "Epoch 43/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6345 - loss: 0.6655 - learning_rate: 0.0097\n",
      "Epoch 44/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6730 - loss: 0.6545 - learning_rate: 0.0097\n",
      "Epoch 45/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6866 - loss: 0.6440 - learning_rate: 0.0097\n",
      "Epoch 46/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6760 - loss: 0.6461 - learning_rate: 0.0096\n",
      "Epoch 47/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6704 - loss: 0.6426 - learning_rate: 0.0096\n",
      "Epoch 48/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6932 - loss: 0.6334 - learning_rate: 0.0096\n",
      "Epoch 49/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6786 - loss: 0.6470 - learning_rate: 0.0096\n",
      "Epoch 50/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6799 - loss: 0.6386 - learning_rate: 0.0096\n",
      "Epoch 51/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6745 - loss: 0.6428 - learning_rate: 0.0096\n",
      "Epoch 52/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.6773 - loss: 0.6344 - learning_rate: 0.0096\n",
      "Epoch 53/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.6644 - loss: 0.6499 - learning_rate: 0.0096\n",
      "Epoch 54/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6816 - loss: 0.6327 - learning_rate: 0.0096\n",
      "Epoch 55/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6587 - loss: 0.6429 - learning_rate: 0.0096\n",
      "Epoch 56/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6718 - loss: 0.6366 - learning_rate: 0.0096\n",
      "Epoch 57/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6681 - loss: 0.6466 - learning_rate: 0.0095\n",
      "Epoch 58/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6756 - loss: 0.6420 - learning_rate: 0.0095\n",
      "Epoch 59/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6553 - loss: 0.6529 - learning_rate: 0.0095\n",
      "Epoch 60/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6723 - loss: 0.6379 - learning_rate: 0.0095\n",
      "Epoch 61/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6723 - loss: 0.6465 - learning_rate: 0.0095\n",
      "Epoch 62/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6540 - loss: 0.6482 - learning_rate: 0.0095\n",
      "Epoch 63/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6669 - loss: 0.6423 - learning_rate: 0.0095\n",
      "Epoch 64/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.6535 - loss: 0.6524 - learning_rate: 0.0095\n",
      "Epoch 65/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6685 - loss: 0.6388 - learning_rate: 0.0095\n",
      "Epoch 66/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6665 - loss: 0.6356 - learning_rate: 0.0095\n",
      "Epoch 67/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.6611 - loss: 0.6458 - learning_rate: 0.0094\n",
      "Epoch 68/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6596 - loss: 0.6463 - learning_rate: 0.0094\n",
      "Epoch 69/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6673 - loss: 0.6449 - learning_rate: 0.0094\n",
      "Epoch 70/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6738 - loss: 0.6353 - learning_rate: 0.0094\n",
      "Epoch 71/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6775 - loss: 0.6346 - learning_rate: 0.0094\n",
      "Epoch 72/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6917 - loss: 0.6293 - learning_rate: 0.0094\n",
      "Epoch 73/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6626 - loss: 0.6481 - learning_rate: 0.0094\n",
      "Epoch 74/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.6783 - loss: 0.6383 - learning_rate: 0.0094\n",
      "Epoch 75/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6691 - loss: 0.6445 - learning_rate: 0.0094\n",
      "Epoch 76/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6666 - loss: 0.6389 - learning_rate: 0.0094\n",
      "Epoch 77/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6641 - loss: 0.6382 - learning_rate: 0.0094\n",
      "Epoch 78/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6568 - loss: 0.6462 - learning_rate: 0.0093\n",
      "Epoch 79/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6786 - loss: 0.6265 - learning_rate: 0.0093\n",
      "Epoch 80/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6711 - loss: 0.6343 - learning_rate: 0.0093\n",
      "Epoch 81/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6753 - loss: 0.6337 - learning_rate: 0.0093\n",
      "Epoch 82/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6591 - loss: 0.6539 - learning_rate: 0.0093\n",
      "Epoch 83/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6658 - loss: 0.6345 - learning_rate: 0.0093\n",
      "Epoch 84/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6721 - loss: 0.6360 - learning_rate: 0.0093\n",
      "Epoch 85/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6705 - loss: 0.6361 - learning_rate: 0.0093\n",
      "Epoch 86/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6763 - loss: 0.6365 - learning_rate: 0.0093\n",
      "Epoch 87/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6761 - loss: 0.6427 - learning_rate: 0.0093\n",
      "Epoch 88/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6763 - loss: 0.6363 - learning_rate: 0.0092\n",
      "Epoch 89/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6683 - loss: 0.6357 - learning_rate: 0.0092\n",
      "Epoch 90/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.6675 - loss: 0.6356 - learning_rate: 0.0092\n",
      "Epoch 91/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.6690 - loss: 0.6469 - learning_rate: 0.0092\n",
      "Epoch 92/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6844 - loss: 0.6194 - learning_rate: 0.0092\n",
      "Epoch 93/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6730 - loss: 0.6351 - learning_rate: 0.0092\n",
      "Epoch 94/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6879 - loss: 0.6204 - learning_rate: 0.0092\n",
      "Epoch 95/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6765 - loss: 0.6327 - learning_rate: 0.0092\n",
      "Epoch 96/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6653 - loss: 0.6434 - learning_rate: 0.0092\n",
      "Epoch 97/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6759 - loss: 0.6340 - learning_rate: 0.0092\n",
      "Epoch 98/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6723 - loss: 0.6387 - learning_rate: 0.0092\n",
      "Epoch 99/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6588 - loss: 0.6323 - learning_rate: 0.0091\n",
      "Epoch 100/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6953 - loss: 0.6119 - learning_rate: 0.0091\n",
      "Epoch 101/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6826 - loss: 0.6254 - learning_rate: 0.0091\n",
      "Epoch 102/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6527 - loss: 0.6489 - learning_rate: 0.0091\n",
      "Epoch 103/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6803 - loss: 0.6239 - learning_rate: 0.0091\n",
      "Epoch 104/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6696 - loss: 0.6362 - learning_rate: 0.0091\n",
      "Epoch 105/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6767 - loss: 0.6348 - learning_rate: 0.0091\n",
      "Epoch 106/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6802 - loss: 0.6281 - learning_rate: 0.0091\n",
      "Epoch 107/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6644 - loss: 0.6358 - learning_rate: 0.0091\n",
      "Epoch 108/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6742 - loss: 0.6345 - learning_rate: 0.0091\n",
      "Epoch 109/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6573 - loss: 0.6406 - learning_rate: 0.0091\n",
      "Epoch 110/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.6725 - loss: 0.6401 - learning_rate: 0.0090\n",
      "Epoch 111/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.6799 - loss: 0.6398 - learning_rate: 0.0090\n",
      "Epoch 112/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6664 - loss: 0.6454 - learning_rate: 0.0090\n",
      "Epoch 113/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6729 - loss: 0.6432 - learning_rate: 0.0090\n",
      "Epoch 114/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6758 - loss: 0.6350 - learning_rate: 0.0090\n",
      "Epoch 115/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6740 - loss: 0.6306 - learning_rate: 0.0090\n",
      "Epoch 116/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6875 - loss: 0.6317 - learning_rate: 0.0090\n",
      "Epoch 117/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6769 - loss: 0.6317 - learning_rate: 0.0090\n",
      "Epoch 118/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6800 - loss: 0.6350 - learning_rate: 0.0090\n",
      "Epoch 119/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6796 - loss: 0.6347 - learning_rate: 0.0090\n",
      "Epoch 120/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6847 - loss: 0.6263 - learning_rate: 0.0090\n",
      "Epoch 121/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6559 - loss: 0.6461 - learning_rate: 0.0089\n",
      "Epoch 122/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6824 - loss: 0.6301 - learning_rate: 0.0089\n",
      "Epoch 123/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6640 - loss: 0.6348 - learning_rate: 0.0089\n",
      "Epoch 124/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6826 - loss: 0.6386 - learning_rate: 0.0089\n",
      "Epoch 125/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6794 - loss: 0.6250 - learning_rate: 0.0089\n",
      "Epoch 126/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6904 - loss: 0.6334 - learning_rate: 0.0089\n",
      "Epoch 127/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6687 - loss: 0.6316 - learning_rate: 0.0089\n",
      "Epoch 128/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6970 - loss: 0.6136 - learning_rate: 0.0089\n",
      "Epoch 129/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6693 - loss: 0.6288 - learning_rate: 0.0089\n",
      "Epoch 130/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6658 - loss: 0.6380 - learning_rate: 0.0089\n",
      "Epoch 131/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6741 - loss: 0.6371 - learning_rate: 0.0089\n",
      "Epoch 132/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6665 - loss: 0.6363 - learning_rate: 0.0089\n",
      "Epoch 133/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6527 - loss: 0.6504 - learning_rate: 0.0088\n",
      "Epoch 134/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6764 - loss: 0.6425 - learning_rate: 0.0088\n",
      "Epoch 135/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6726 - loss: 0.6384 - learning_rate: 0.0088\n",
      "Epoch 136/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6561 - loss: 0.6386 - learning_rate: 0.0088\n",
      "Epoch 137/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6745 - loss: 0.6314 - learning_rate: 0.0088\n",
      "Epoch 138/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6881 - loss: 0.6209 - learning_rate: 0.0088\n",
      "Epoch 139/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6704 - loss: 0.6246 - learning_rate: 0.0088\n",
      "Epoch 140/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6727 - loss: 0.6320 - learning_rate: 0.0088\n",
      "Epoch 141/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6649 - loss: 0.6332 - learning_rate: 0.0088\n",
      "Epoch 142/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6763 - loss: 0.6381 - learning_rate: 0.0088\n",
      "Epoch 143/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6659 - loss: 0.6381 - learning_rate: 0.0088\n",
      "Epoch 144/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.6707 - loss: 0.6337 - learning_rate: 0.0087\n",
      "Epoch 145/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6724 - loss: 0.6390 - learning_rate: 0.0087\n",
      "Epoch 146/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6691 - loss: 0.6347 - learning_rate: 0.0087\n",
      "Epoch 147/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6832 - loss: 0.6242 - learning_rate: 0.0087\n",
      "Epoch 148/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6605 - loss: 0.6407 - learning_rate: 0.0087\n",
      "Epoch 149/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6685 - loss: 0.6381 - learning_rate: 0.0087\n",
      "Epoch 150/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6707 - loss: 0.6433 - learning_rate: 0.0087\n",
      "Epoch 151/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6837 - loss: 0.6154 - learning_rate: 0.0087\n",
      "Epoch 152/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6812 - loss: 0.6347 - learning_rate: 0.0087\n",
      "Epoch 153/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6866 - loss: 0.6229 - learning_rate: 0.0087\n",
      "Epoch 154/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6785 - loss: 0.6340 - learning_rate: 0.0087\n",
      "Epoch 155/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6494 - loss: 0.6423 - learning_rate: 0.0087\n",
      "Epoch 156/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6767 - loss: 0.6352 - learning_rate: 0.0086\n",
      "Epoch 157/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6703 - loss: 0.6263 - learning_rate: 0.0086\n",
      "Epoch 158/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6825 - loss: 0.6274 - learning_rate: 0.0086\n",
      "Epoch 159/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.6724 - loss: 0.6335 - learning_rate: 0.0086\n",
      "Epoch 160/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6567 - loss: 0.6379 - learning_rate: 0.0086\n",
      "Epoch 161/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6633 - loss: 0.6372 - learning_rate: 0.0086\n",
      "Epoch 162/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6640 - loss: 0.6424 - learning_rate: 0.0086\n",
      "Epoch 163/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6759 - loss: 0.6274 - learning_rate: 0.0086\n",
      "Epoch 164/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6834 - loss: 0.6231 - learning_rate: 0.0086\n",
      "Epoch 165/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6864 - loss: 0.6218 - learning_rate: 0.0086\n",
      "Epoch 166/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6809 - loss: 0.6327 - learning_rate: 0.0086\n",
      "Epoch 167/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6550 - loss: 0.6427 - learning_rate: 0.0085\n",
      "Epoch 168/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6650 - loss: 0.6403 - learning_rate: 0.0085\n",
      "Epoch 169/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6743 - loss: 0.6263 - learning_rate: 0.0085\n",
      "Epoch 170/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6643 - loss: 0.6262 - learning_rate: 0.0085\n",
      "Epoch 171/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6935 - loss: 0.6141 - learning_rate: 0.0085\n",
      "Epoch 172/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6935 - loss: 0.6201 - learning_rate: 0.0085\n",
      "Epoch 173/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6593 - loss: 0.6411 - learning_rate: 0.0085\n",
      "Epoch 174/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.6724 - loss: 0.6362 - learning_rate: 0.0085\n",
      "Epoch 175/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6521 - loss: 0.6363 - learning_rate: 0.0085\n",
      "Epoch 176/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6736 - loss: 0.6262 - learning_rate: 0.0085\n",
      "Epoch 177/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6899 - loss: 0.6207 - learning_rate: 0.0085\n",
      "Epoch 178/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6745 - loss: 0.6364 - learning_rate: 0.0085\n",
      "Epoch 179/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6796 - loss: 0.6255 - learning_rate: 0.0084\n",
      "Epoch 180/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6704 - loss: 0.6357 - learning_rate: 0.0084\n",
      "Epoch 181/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6661 - loss: 0.6353 - learning_rate: 0.0084\n",
      "Epoch 182/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6722 - loss: 0.6285 - learning_rate: 0.0084\n",
      "Epoch 183/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6762 - loss: 0.6262 - learning_rate: 0.0084\n",
      "Epoch 184/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6686 - loss: 0.6338 - learning_rate: 0.0084\n",
      "Epoch 185/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6752 - loss: 0.6311 - learning_rate: 0.0084\n",
      "Epoch 186/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6632 - loss: 0.6330 - learning_rate: 0.0084\n",
      "Epoch 187/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.6702 - loss: 0.6356 - learning_rate: 0.0084\n",
      "Epoch 188/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6823 - loss: 0.6285 - learning_rate: 0.0084\n",
      "Epoch 189/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6856 - loss: 0.6293 - learning_rate: 0.0084\n",
      "Epoch 190/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6763 - loss: 0.6256 - learning_rate: 0.0084\n",
      "Epoch 191/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6708 - loss: 0.6269 - learning_rate: 0.0083\n",
      "Epoch 192/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6756 - loss: 0.6265 - learning_rate: 0.0083\n",
      "Epoch 193/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6932 - loss: 0.6152 - learning_rate: 0.0083\n",
      "Epoch 194/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6699 - loss: 0.6373 - learning_rate: 0.0083\n",
      "Epoch 195/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6790 - loss: 0.6330 - learning_rate: 0.0083\n",
      "Epoch 196/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6645 - loss: 0.6289 - learning_rate: 0.0083\n",
      "Epoch 197/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6648 - loss: 0.6217 - learning_rate: 0.0083\n",
      "Epoch 198/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6768 - loss: 0.6261 - learning_rate: 0.0083\n",
      "Epoch 199/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.6830 - loss: 0.6231 - learning_rate: 0.0083\n",
      "Epoch 200/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6597 - loss: 0.6300 - learning_rate: 0.0083\n",
      "Epoch 201/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6678 - loss: 0.6275 - learning_rate: 0.0083\n",
      "Epoch 202/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6653 - loss: 0.6407 - learning_rate: 0.0083\n",
      "Epoch 203/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6767 - loss: 0.6303 - learning_rate: 0.0082\n",
      "Epoch 204/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.6632 - loss: 0.6353 - learning_rate: 0.0082\n",
      "Epoch 205/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.6708 - loss: 0.6271 - learning_rate: 0.0082\n",
      "Epoch 206/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6601 - loss: 0.6304 - learning_rate: 0.0082\n",
      "Epoch 207/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6811 - loss: 0.6315 - learning_rate: 0.0082\n",
      "Epoch 208/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6769 - loss: 0.6287 - learning_rate: 0.0082\n",
      "Epoch 209/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6950 - loss: 0.6175 - learning_rate: 0.0082\n",
      "Epoch 210/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6738 - loss: 0.6332 - learning_rate: 0.0082\n",
      "Epoch 211/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.6819 - loss: 0.6291 - learning_rate: 0.0082\n",
      "Epoch 212/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6715 - loss: 0.6374 - learning_rate: 0.0082\n",
      "Epoch 213/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6734 - loss: 0.6238 - learning_rate: 0.0082\n",
      "Epoch 214/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6858 - loss: 0.6200 - learning_rate: 0.0082\n",
      "Epoch 215/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6740 - loss: 0.6292 - learning_rate: 0.0081\n",
      "Epoch 216/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6841 - loss: 0.6195 - learning_rate: 0.0081\n",
      "Epoch 217/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6768 - loss: 0.6368 - learning_rate: 0.0081\n",
      "Epoch 218/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6817 - loss: 0.6168 - learning_rate: 0.0081\n",
      "Epoch 219/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6948 - loss: 0.6158 - learning_rate: 0.0081\n",
      "Epoch 220/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6821 - loss: 0.6253 - learning_rate: 0.0081\n",
      "Epoch 221/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6815 - loss: 0.6305 - learning_rate: 0.0081\n",
      "Epoch 222/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.6777 - loss: 0.6253 - learning_rate: 0.0081\n",
      "Epoch 223/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6747 - loss: 0.6262 - learning_rate: 0.0081\n",
      "Epoch 224/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6830 - loss: 0.6189 - learning_rate: 0.0081\n",
      "Epoch 225/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6727 - loss: 0.6276 - learning_rate: 0.0081\n",
      "Epoch 226/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6681 - loss: 0.6373 - learning_rate: 0.0081\n",
      "Epoch 227/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6703 - loss: 0.6331 - learning_rate: 0.0080\n",
      "Epoch 228/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6829 - loss: 0.6158 - learning_rate: 0.0080\n",
      "Epoch 229/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6748 - loss: 0.6214 - learning_rate: 0.0080\n",
      "Epoch 230/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6755 - loss: 0.6283 - learning_rate: 0.0080\n",
      "Epoch 231/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6735 - loss: 0.6163 - learning_rate: 0.0080\n",
      "Epoch 232/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6692 - loss: 0.6332 - learning_rate: 0.0080\n",
      "Epoch 233/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.6703 - loss: 0.6277 - learning_rate: 0.0080\n",
      "Epoch 234/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.6751 - loss: 0.6306 - learning_rate: 0.0080\n",
      "Epoch 235/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.6890 - loss: 0.6212 - learning_rate: 0.0080\n",
      "Epoch 236/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6876 - loss: 0.6145 - learning_rate: 0.0080\n",
      "Epoch 237/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.6744 - loss: 0.6191 - learning_rate: 0.0080\n",
      "Epoch 238/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.6727 - loss: 0.6222 - learning_rate: 0.0080\n",
      "Epoch 239/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6639 - loss: 0.6334 - learning_rate: 0.0080\n",
      "Epoch 240/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6735 - loss: 0.6279 - learning_rate: 0.0079\n",
      "Epoch 241/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6684 - loss: 0.6292 - learning_rate: 0.0079\n",
      "Epoch 242/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.6897 - loss: 0.6210 - learning_rate: 0.0079\n",
      "Epoch 243/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.6766 - loss: 0.6250 - learning_rate: 0.0079\n",
      "Epoch 244/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6757 - loss: 0.6227 - learning_rate: 0.0079\n",
      "Epoch 245/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6670 - loss: 0.6346 - learning_rate: 0.0079\n",
      "Epoch 246/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6721 - loss: 0.6269 - learning_rate: 0.0079\n",
      "Epoch 247/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6796 - loss: 0.6225 - learning_rate: 0.0079\n",
      "Epoch 248/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.6792 - loss: 0.6202 - learning_rate: 0.0079\n",
      "Epoch 249/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6762 - loss: 0.6353 - learning_rate: 0.0079\n",
      "Epoch 250/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6910 - loss: 0.6140 - learning_rate: 0.0079\n",
      "Epoch 251/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6643 - loss: 0.6206 - learning_rate: 0.0079\n",
      "Epoch 252/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6822 - loss: 0.6090 - learning_rate: 0.0079\n",
      "Epoch 253/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.6862 - loss: 0.6133 - learning_rate: 0.0078\n",
      "Epoch 254/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6829 - loss: 0.6258 - learning_rate: 0.0078\n",
      "Epoch 255/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6713 - loss: 0.6354 - learning_rate: 0.0078\n",
      "Epoch 256/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6817 - loss: 0.6297 - learning_rate: 0.0078\n",
      "Epoch 257/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6579 - loss: 0.6411 - learning_rate: 0.0078\n",
      "Epoch 258/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6819 - loss: 0.6165 - learning_rate: 0.0078\n",
      "Epoch 259/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6701 - loss: 0.6236 - learning_rate: 0.0078\n",
      "Epoch 260/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.6644 - loss: 0.6299 - learning_rate: 0.0078\n",
      "Epoch 261/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6424 - loss: 0.6495 - learning_rate: 0.0078\n",
      "Epoch 262/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6620 - loss: 0.6374 - learning_rate: 0.0078\n",
      "Epoch 263/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.6580 - loss: 0.6431 - learning_rate: 0.0078\n",
      "Epoch 264/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6658 - loss: 0.6342 - learning_rate: 0.0078\n",
      "Epoch 265/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6848 - loss: 0.6144 - learning_rate: 0.0077\n",
      "Epoch 266/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6943 - loss: 0.6214 - learning_rate: 0.0077\n",
      "Epoch 267/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6808 - loss: 0.6264 - learning_rate: 0.0077\n",
      "Epoch 268/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6634 - loss: 0.6319 - learning_rate: 0.0077\n",
      "Epoch 269/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6775 - loss: 0.6199 - learning_rate: 0.0077\n",
      "Epoch 270/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6923 - loss: 0.6104 - learning_rate: 0.0077\n",
      "Epoch 271/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6722 - loss: 0.6196 - learning_rate: 0.0077\n",
      "Epoch 272/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6815 - loss: 0.6233 - learning_rate: 0.0077\n",
      "Epoch 273/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.6875 - loss: 0.6133 - learning_rate: 0.0077\n",
      "Epoch 274/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6709 - loss: 0.6233 - learning_rate: 0.0077\n",
      "Epoch 275/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6873 - loss: 0.6110 - learning_rate: 0.0077\n",
      "Epoch 276/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6790 - loss: 0.6451 - learning_rate: 0.0077\n",
      "Epoch 277/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6817 - loss: 0.6226 - learning_rate: 0.0077\n",
      "Epoch 278/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6708 - loss: 0.6262 - learning_rate: 0.0076\n",
      "Epoch 279/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6958 - loss: 0.6102 - learning_rate: 0.0076\n",
      "Epoch 280/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6744 - loss: 0.6248 - learning_rate: 0.0076\n",
      "Epoch 281/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.6611 - loss: 0.6319 - learning_rate: 0.0076\n",
      "Epoch 282/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.6622 - loss: 0.6362 - learning_rate: 0.0076\n",
      "Epoch 283/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6712 - loss: 0.6262 - learning_rate: 0.0076\n",
      "Epoch 284/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6765 - loss: 0.6312 - learning_rate: 0.0076\n",
      "Epoch 285/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6727 - loss: 0.6279 - learning_rate: 0.0076\n",
      "Epoch 286/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6813 - loss: 0.6167 - learning_rate: 0.0076\n",
      "Epoch 287/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6962 - loss: 0.6122 - learning_rate: 0.0076\n",
      "Epoch 288/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6782 - loss: 0.6291 - learning_rate: 0.0076\n",
      "Epoch 289/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6920 - loss: 0.6109 - learning_rate: 0.0076\n",
      "Epoch 290/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.6721 - loss: 0.6263 - learning_rate: 0.0076\n",
      "Epoch 291/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6730 - loss: 0.6311 - learning_rate: 0.0076\n",
      "Epoch 292/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6754 - loss: 0.6335 - learning_rate: 0.0075\n",
      "Epoch 293/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6873 - loss: 0.6185 - learning_rate: 0.0075\n",
      "Epoch 294/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6728 - loss: 0.6331 - learning_rate: 0.0075\n",
      "Epoch 295/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6702 - loss: 0.6433 - learning_rate: 0.0075\n",
      "Epoch 296/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6646 - loss: 0.6301 - learning_rate: 0.0075\n",
      "Epoch 297/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6849 - loss: 0.6179 - learning_rate: 0.0075\n",
      "Epoch 298/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6823 - loss: 0.6253 - learning_rate: 0.0075\n",
      "Epoch 299/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.6878 - loss: 0.6173 - learning_rate: 0.0075\n",
      "Epoch 300/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6710 - loss: 0.6345 - learning_rate: 0.0075\n",
      "Epoch 301/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6802 - loss: 0.6159 - learning_rate: 0.0075\n",
      "Epoch 302/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6806 - loss: 0.6196 - learning_rate: 0.0075\n",
      "Epoch 303/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6720 - loss: 0.6235 - learning_rate: 0.0075\n",
      "Epoch 304/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6875 - loss: 0.6297 - learning_rate: 0.0075\n",
      "Epoch 305/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6733 - loss: 0.6276 - learning_rate: 0.0074\n",
      "Epoch 306/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6849 - loss: 0.6116 - learning_rate: 0.0074\n",
      "Epoch 307/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6917 - loss: 0.6063 - learning_rate: 0.0074\n",
      "Epoch 308/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.6677 - loss: 0.6284 - learning_rate: 0.0074\n",
      "Epoch 309/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6780 - loss: 0.6259 - learning_rate: 0.0074\n",
      "Epoch 310/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6739 - loss: 0.6178 - learning_rate: 0.0074\n",
      "Epoch 311/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6774 - loss: 0.6262 - learning_rate: 0.0074\n",
      "Epoch 312/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6914 - loss: 0.6083 - learning_rate: 0.0074\n",
      "Epoch 313/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6775 - loss: 0.6170 - learning_rate: 0.0074\n",
      "Epoch 314/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6908 - loss: 0.6118 - learning_rate: 0.0074\n",
      "Epoch 315/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6728 - loss: 0.6285 - learning_rate: 0.0074\n",
      "Epoch 316/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6754 - loss: 0.6256 - learning_rate: 0.0074\n",
      "Epoch 317/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.6844 - loss: 0.6129 - learning_rate: 0.0074\n",
      "Epoch 318/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6699 - loss: 0.6344 - learning_rate: 0.0073\n",
      "Epoch 319/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6735 - loss: 0.6231 - learning_rate: 0.0073\n",
      "Epoch 320/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6593 - loss: 0.6343 - learning_rate: 0.0073\n",
      "Epoch 321/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6862 - loss: 0.6161 - learning_rate: 0.0073\n",
      "Epoch 322/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6746 - loss: 0.6260 - learning_rate: 0.0073\n",
      "Epoch 323/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6712 - loss: 0.6330 - learning_rate: 0.0073\n",
      "Epoch 324/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6687 - loss: 0.6276 - learning_rate: 0.0073\n",
      "Epoch 325/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6696 - loss: 0.6261 - learning_rate: 0.0073\n",
      "Epoch 326/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6683 - loss: 0.6274 - learning_rate: 0.0073\n",
      "Epoch 327/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.6802 - loss: 0.6170 - learning_rate: 0.0073\n",
      "Epoch 328/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6739 - loss: 0.6280 - learning_rate: 0.0073\n",
      "Epoch 329/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6678 - loss: 0.6271 - learning_rate: 0.0073\n",
      "Epoch 330/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6644 - loss: 0.6394 - learning_rate: 0.0073\n",
      "Epoch 331/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6748 - loss: 0.6270 - learning_rate: 0.0073\n",
      "Epoch 332/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6758 - loss: 0.6170 - learning_rate: 0.0072\n",
      "Epoch 333/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6677 - loss: 0.6289 - learning_rate: 0.0072\n",
      "Epoch 334/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6796 - loss: 0.6225 - learning_rate: 0.0072\n",
      "Epoch 335/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6636 - loss: 0.6363 - learning_rate: 0.0072\n",
      "Epoch 336/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.6798 - loss: 0.6313 - learning_rate: 0.0072\n",
      "Epoch 337/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6712 - loss: 0.6281 - learning_rate: 0.0072\n",
      "Epoch 338/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6692 - loss: 0.6361 - learning_rate: 0.0072\n",
      "Epoch 339/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6823 - loss: 0.6142 - learning_rate: 0.0072\n",
      "Epoch 340/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6852 - loss: 0.6216 - learning_rate: 0.0072\n",
      "Epoch 341/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6967 - loss: 0.6126 - learning_rate: 0.0072\n",
      "Epoch 342/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6808 - loss: 0.6170 - learning_rate: 0.0072\n",
      "Epoch 343/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6679 - loss: 0.6300 - learning_rate: 0.0072\n",
      "Epoch 344/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6706 - loss: 0.6299 - learning_rate: 0.0072\n",
      "Epoch 345/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6686 - loss: 0.6236 - learning_rate: 0.0072\n",
      "Epoch 346/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6953 - loss: 0.6079 - learning_rate: 0.0071\n",
      "Epoch 347/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6795 - loss: 0.6195 - learning_rate: 0.0071\n",
      "Epoch 348/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6759 - loss: 0.6209 - learning_rate: 0.0071\n",
      "Epoch 349/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6776 - loss: 0.6235 - learning_rate: 0.0071\n",
      "Epoch 350/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6846 - loss: 0.5990 - learning_rate: 0.0071\n",
      "Epoch 351/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6911 - loss: 0.6170 - learning_rate: 0.0071\n",
      "Epoch 352/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6769 - loss: 0.6299 - learning_rate: 0.0071\n",
      "Epoch 353/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6699 - loss: 0.6270 - learning_rate: 0.0071\n",
      "Epoch 354/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.6539 - loss: 0.6339 - learning_rate: 0.0071\n",
      "Epoch 355/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.6718 - loss: 0.6276 - learning_rate: 0.0071\n",
      "Epoch 356/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6832 - loss: 0.6176 - learning_rate: 0.0071\n",
      "Epoch 357/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6586 - loss: 0.6310 - learning_rate: 0.0071\n",
      "Epoch 358/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6877 - loss: 0.6128 - learning_rate: 0.0071\n",
      "Epoch 359/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6944 - loss: 0.6111 - learning_rate: 0.0071\n",
      "Epoch 360/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6774 - loss: 0.6223 - learning_rate: 0.0070\n",
      "Epoch 361/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6660 - loss: 0.6319 - learning_rate: 0.0070\n",
      "Epoch 362/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6624 - loss: 0.6246 - learning_rate: 0.0070\n",
      "Epoch 363/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6753 - loss: 0.6328 - learning_rate: 0.0070\n",
      "Epoch 364/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.6762 - loss: 0.6201 - learning_rate: 0.0070\n",
      "Epoch 365/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6940 - loss: 0.6175 - learning_rate: 0.0070\n",
      "Epoch 366/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6688 - loss: 0.6340 - learning_rate: 0.0070\n",
      "Epoch 367/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6786 - loss: 0.6274 - learning_rate: 0.0070\n",
      "Epoch 368/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6833 - loss: 0.6100 - learning_rate: 0.0070\n",
      "Epoch 369/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6735 - loss: 0.6259 - learning_rate: 0.0070\n",
      "Epoch 370/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6773 - loss: 0.6235 - learning_rate: 0.0070\n",
      "Epoch 371/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6933 - loss: 0.6032 - learning_rate: 0.0070\n",
      "Epoch 372/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.6792 - loss: 0.6211 - learning_rate: 0.0070\n",
      "Epoch 373/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.6846 - loss: 0.6185 - learning_rate: 0.0070\n",
      "Epoch 374/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6756 - loss: 0.6273 - learning_rate: 0.0069\n",
      "Epoch 375/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6780 - loss: 0.6172 - learning_rate: 0.0069\n",
      "Epoch 376/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6925 - loss: 0.6111 - learning_rate: 0.0069\n",
      "Epoch 377/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6726 - loss: 0.6252 - learning_rate: 0.0069\n",
      "Epoch 378/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6879 - loss: 0.6085 - learning_rate: 0.0069\n",
      "Epoch 379/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6610 - loss: 0.6373 - learning_rate: 0.0069\n",
      "Epoch 380/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.6630 - loss: 0.6364 - learning_rate: 0.0069\n",
      "Epoch 381/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.6675 - loss: 0.6372 - learning_rate: 0.0069\n",
      "Epoch 382/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7041 - loss: 0.6103 - learning_rate: 0.0069\n",
      "Epoch 383/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6671 - loss: 0.6333 - learning_rate: 0.0069\n",
      "Epoch 384/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6659 - loss: 0.6272 - learning_rate: 0.0069\n",
      "Epoch 385/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6875 - loss: 0.6026 - learning_rate: 0.0069\n",
      "Epoch 386/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6667 - loss: 0.6281 - learning_rate: 0.0069\n",
      "Epoch 387/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6712 - loss: 0.6293 - learning_rate: 0.0069\n",
      "Epoch 388/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6832 - loss: 0.6151 - learning_rate: 0.0069\n",
      "Epoch 389/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6857 - loss: 0.6033 - learning_rate: 0.0068\n",
      "Epoch 390/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.6802 - loss: 0.6198 - learning_rate: 0.0068\n",
      "Epoch 391/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6670 - loss: 0.6332 - learning_rate: 0.0068\n",
      "Epoch 392/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6568 - loss: 0.6328 - learning_rate: 0.0068\n",
      "Epoch 393/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6825 - loss: 0.6210 - learning_rate: 0.0068\n",
      "Epoch 394/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6624 - loss: 0.6385 - learning_rate: 0.0068\n",
      "Epoch 395/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6758 - loss: 0.6297 - learning_rate: 0.0068\n",
      "Epoch 396/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6945 - loss: 0.6009 - learning_rate: 0.0068\n",
      "Epoch 397/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6787 - loss: 0.6293 - learning_rate: 0.0068\n",
      "Epoch 398/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6799 - loss: 0.6173 - learning_rate: 0.0068\n",
      "Epoch 399/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.6949 - loss: 0.6179 - learning_rate: 0.0068\n",
      "Epoch 400/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6738 - loss: 0.6193 - learning_rate: 0.0068\n",
      "Epoch 401/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6810 - loss: 0.6251 - learning_rate: 0.0068\n",
      "Epoch 402/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6762 - loss: 0.6226 - learning_rate: 0.0068\n",
      "Epoch 403/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6793 - loss: 0.6300 - learning_rate: 0.0068\n",
      "Epoch 404/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6930 - loss: 0.6131 - learning_rate: 0.0067\n",
      "Epoch 405/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6909 - loss: 0.6194 - learning_rate: 0.0067\n",
      "Epoch 406/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7036 - loss: 0.6101 - learning_rate: 0.0067\n",
      "Epoch 407/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.6709 - loss: 0.6318 - learning_rate: 0.0067\n",
      "Epoch 408/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6911 - loss: 0.6128 - learning_rate: 0.0067\n",
      "Epoch 409/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6955 - loss: 0.6198 - learning_rate: 0.0067\n",
      "Epoch 410/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6603 - loss: 0.6342 - learning_rate: 0.0067\n",
      "Epoch 411/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6934 - loss: 0.6096 - learning_rate: 0.0067\n",
      "Epoch 412/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6951 - loss: 0.6148 - learning_rate: 0.0067\n",
      "Epoch 413/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6628 - loss: 0.6253 - learning_rate: 0.0067\n",
      "Epoch 414/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6708 - loss: 0.6151 - learning_rate: 0.0067\n",
      "Epoch 415/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6792 - loss: 0.6128 - learning_rate: 0.0067\n",
      "Epoch 416/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.6652 - loss: 0.6304 - learning_rate: 0.0067\n",
      "Epoch 417/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.6933 - loss: 0.6024 - learning_rate: 0.0067\n",
      "Epoch 418/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6862 - loss: 0.6174 - learning_rate: 0.0066\n",
      "Epoch 419/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6685 - loss: 0.6254 - learning_rate: 0.0066\n",
      "Epoch 420/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6837 - loss: 0.6155 - learning_rate: 0.0066\n",
      "Epoch 421/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6875 - loss: 0.6119 - learning_rate: 0.0066\n",
      "Epoch 422/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6915 - loss: 0.6150 - learning_rate: 0.0066\n",
      "Epoch 423/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6904 - loss: 0.6103 - learning_rate: 0.0066\n",
      "Epoch 424/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6741 - loss: 0.6256 - learning_rate: 0.0066\n",
      "Epoch 425/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.6828 - loss: 0.6127 - learning_rate: 0.0066\n",
      "Epoch 426/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6807 - loss: 0.6256 - learning_rate: 0.0066\n",
      "Epoch 427/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6613 - loss: 0.6321 - learning_rate: 0.0066\n",
      "Epoch 428/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6599 - loss: 0.6292 - learning_rate: 0.0066\n",
      "Epoch 429/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6846 - loss: 0.6232 - learning_rate: 0.0066\n",
      "Epoch 430/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6898 - loss: 0.6093 - learning_rate: 0.0066\n",
      "Epoch 431/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6679 - loss: 0.6333 - learning_rate: 0.0066\n",
      "Epoch 432/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.6673 - loss: 0.6270 - learning_rate: 0.0066\n",
      "Epoch 433/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6801 - loss: 0.6298 - learning_rate: 0.0066\n",
      "Epoch 434/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.6903 - loss: 0.6063 - learning_rate: 0.0065\n",
      "Epoch 435/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7083 - loss: 0.6014 - learning_rate: 0.0065\n",
      "Epoch 436/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6725 - loss: 0.6263 - learning_rate: 0.0065\n",
      "Epoch 437/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6811 - loss: 0.6240 - learning_rate: 0.0065\n",
      "Epoch 438/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6768 - loss: 0.6212 - learning_rate: 0.0065\n",
      "Epoch 439/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6753 - loss: 0.6197 - learning_rate: 0.0065\n",
      "Epoch 440/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6727 - loss: 0.6202 - learning_rate: 0.0065\n",
      "Epoch 441/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6717 - loss: 0.6259 - learning_rate: 0.0065\n",
      "Epoch 442/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6734 - loss: 0.6232 - learning_rate: 0.0065\n",
      "Epoch 443/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6460 - loss: 0.6372 - learning_rate: 0.0065\n",
      "Epoch 444/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.6866 - loss: 0.6104 - learning_rate: 0.0065\n",
      "Epoch 445/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6762 - loss: 0.6212 - learning_rate: 0.0065\n",
      "Epoch 446/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6858 - loss: 0.6106 - learning_rate: 0.0065\n",
      "Epoch 447/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6753 - loss: 0.6157 - learning_rate: 0.0065\n",
      "Epoch 448/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6875 - loss: 0.6137 - learning_rate: 0.0065\n",
      "Epoch 449/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6791 - loss: 0.6164 - learning_rate: 0.0064\n",
      "Epoch 450/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6779 - loss: 0.6211 - learning_rate: 0.0064\n",
      "Epoch 451/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6620 - loss: 0.6243 - learning_rate: 0.0064\n",
      "Epoch 452/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.6804 - loss: 0.6214 - learning_rate: 0.0064\n",
      "Epoch 453/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6753 - loss: 0.6253 - learning_rate: 0.0064\n",
      "Epoch 454/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.6732 - loss: 0.6209 - learning_rate: 0.0064\n",
      "Epoch 455/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6867 - loss: 0.6152 - learning_rate: 0.0064\n",
      "Epoch 456/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6603 - loss: 0.6333 - learning_rate: 0.0064\n",
      "Epoch 457/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6583 - loss: 0.6329 - learning_rate: 0.0064\n",
      "Epoch 458/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6912 - loss: 0.6263 - learning_rate: 0.0064\n",
      "Epoch 459/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6871 - loss: 0.6062 - learning_rate: 0.0064\n",
      "Epoch 460/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6832 - loss: 0.6087 - learning_rate: 0.0064\n",
      "Epoch 461/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6689 - loss: 0.6240 - learning_rate: 0.0064\n",
      "Epoch 462/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6770 - loss: 0.6240 - learning_rate: 0.0064\n",
      "Epoch 463/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.6805 - loss: 0.6192 - learning_rate: 0.0064\n",
      "Epoch 464/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7025 - loss: 0.6008 - learning_rate: 0.0064\n",
      "Epoch 465/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6749 - loss: 0.6188 - learning_rate: 0.0063\n",
      "Epoch 466/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6815 - loss: 0.6224 - learning_rate: 0.0063\n",
      "Epoch 467/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6791 - loss: 0.6178 - learning_rate: 0.0063\n",
      "Epoch 468/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6892 - loss: 0.6142 - learning_rate: 0.0063\n",
      "Epoch 469/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6936 - loss: 0.6081 - learning_rate: 0.0063\n",
      "Epoch 470/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6809 - loss: 0.6183 - learning_rate: 0.0063\n",
      "Epoch 471/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6868 - loss: 0.6151 - learning_rate: 0.0063\n",
      "Epoch 472/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.6763 - loss: 0.6226 - learning_rate: 0.0063\n",
      "Epoch 473/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6986 - loss: 0.6148 - learning_rate: 0.0063\n",
      "Epoch 474/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6941 - loss: 0.6055 - learning_rate: 0.0063\n",
      "Epoch 475/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6794 - loss: 0.6155 - learning_rate: 0.0063\n",
      "Epoch 476/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6950 - loss: 0.6073 - learning_rate: 0.0063\n",
      "Epoch 477/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6879 - loss: 0.6184 - learning_rate: 0.0063\n",
      "Epoch 478/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6557 - loss: 0.6371 - learning_rate: 0.0063\n",
      "Epoch 479/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6759 - loss: 0.6275 - learning_rate: 0.0063\n",
      "Epoch 480/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6884 - loss: 0.6206 - learning_rate: 0.0062\n",
      "Epoch 481/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.6818 - loss: 0.6229 - learning_rate: 0.0062\n",
      "Epoch 482/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6847 - loss: 0.6135 - learning_rate: 0.0062\n",
      "Epoch 483/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6898 - loss: 0.6167 - learning_rate: 0.0062\n",
      "Epoch 484/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6804 - loss: 0.6146 - learning_rate: 0.0062\n",
      "Epoch 485/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6643 - loss: 0.6332 - learning_rate: 0.0062\n",
      "Epoch 486/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6591 - loss: 0.6310 - learning_rate: 0.0062\n",
      "Epoch 487/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6686 - loss: 0.6250 - learning_rate: 0.0062\n",
      "Epoch 488/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6887 - loss: 0.6132 - learning_rate: 0.0062\n",
      "Epoch 489/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6815 - loss: 0.6177 - learning_rate: 0.0062\n",
      "Epoch 490/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.6828 - loss: 0.6133 - learning_rate: 0.0062\n",
      "Epoch 491/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6871 - loss: 0.6122 - learning_rate: 0.0062\n",
      "Epoch 492/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6947 - loss: 0.6039 - learning_rate: 0.0062\n",
      "Epoch 493/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6977 - loss: 0.6087 - learning_rate: 0.0062\n",
      "Epoch 494/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.6756 - loss: 0.6240 - learning_rate: 0.0062\n",
      "Epoch 495/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6895 - loss: 0.6195 - learning_rate: 0.0062\n",
      "Epoch 496/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6782 - loss: 0.6187 - learning_rate: 0.0062\n",
      "Epoch 497/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6888 - loss: 0.6117 - learning_rate: 0.0061\n",
      "Epoch 498/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6797 - loss: 0.6243 - learning_rate: 0.0061\n",
      "Epoch 499/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.6715 - loss: 0.6188 - learning_rate: 0.0061\n",
      "Epoch 500/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6871 - loss: 0.6172 - learning_rate: 0.0061\n",
      "Epoch 501/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6736 - loss: 0.6340 - learning_rate: 0.0061\n",
      "Epoch 502/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6785 - loss: 0.6159 - learning_rate: 0.0061\n",
      "Epoch 503/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6807 - loss: 0.6170 - learning_rate: 0.0061\n",
      "Epoch 504/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6868 - loss: 0.6203 - learning_rate: 0.0061\n",
      "Epoch 505/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6864 - loss: 0.6123 - learning_rate: 0.0061\n",
      "Epoch 506/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6712 - loss: 0.6188 - learning_rate: 0.0061\n",
      "Epoch 507/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6831 - loss: 0.6133 - learning_rate: 0.0061\n",
      "Epoch 508/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.6668 - loss: 0.6160 - learning_rate: 0.0061\n",
      "Epoch 509/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.6868 - loss: 0.6070 - learning_rate: 0.0061\n",
      "Epoch 510/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6827 - loss: 0.6104 - learning_rate: 0.0061\n",
      "Epoch 511/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6701 - loss: 0.6130 - learning_rate: 0.0061\n",
      "Epoch 512/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6833 - loss: 0.6148 - learning_rate: 0.0061\n",
      "Epoch 513/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6767 - loss: 0.6194 - learning_rate: 0.0060\n",
      "Epoch 514/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6836 - loss: 0.6119 - learning_rate: 0.0060\n",
      "Epoch 515/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6789 - loss: 0.6091 - learning_rate: 0.0060\n",
      "Epoch 516/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7017 - loss: 0.6103 - learning_rate: 0.0060\n",
      "Epoch 517/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6666 - loss: 0.6258 - learning_rate: 0.0060\n",
      "Epoch 518/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.6606 - loss: 0.6297 - learning_rate: 0.0060\n",
      "Epoch 519/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6801 - loss: 0.6130 - learning_rate: 0.0060\n",
      "Epoch 520/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6727 - loss: 0.6233 - learning_rate: 0.0060\n",
      "Epoch 521/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6820 - loss: 0.6097 - learning_rate: 0.0060\n",
      "Epoch 522/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6806 - loss: 0.6181 - learning_rate: 0.0060\n",
      "Epoch 523/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6848 - loss: 0.6167 - learning_rate: 0.0060\n",
      "Epoch 524/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6753 - loss: 0.6252 - learning_rate: 0.0060\n",
      "Epoch 525/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6894 - loss: 0.6127 - learning_rate: 0.0060\n",
      "Epoch 526/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6858 - loss: 0.6058 - learning_rate: 0.0060\n",
      "Epoch 527/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.6750 - loss: 0.6241 - learning_rate: 0.0060\n",
      "Epoch 528/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6679 - loss: 0.6227 - learning_rate: 0.0060\n",
      "Epoch 529/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6871 - loss: 0.6062 - learning_rate: 0.0060\n",
      "Epoch 530/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6789 - loss: 0.6194 - learning_rate: 0.0059\n",
      "Epoch 531/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6892 - loss: 0.6143 - learning_rate: 0.0059\n",
      "Epoch 532/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7007 - loss: 0.6038 - learning_rate: 0.0059\n",
      "Epoch 533/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6858 - loss: 0.6068 - learning_rate: 0.0059\n",
      "Epoch 534/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6662 - loss: 0.6210 - learning_rate: 0.0059\n",
      "Epoch 535/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6962 - loss: 0.6147 - learning_rate: 0.0059\n",
      "Epoch 536/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6750 - loss: 0.6258 - learning_rate: 0.0059\n",
      "Epoch 537/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6981 - loss: 0.6063 - learning_rate: 0.0059\n",
      "Epoch 538/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6767 - loss: 0.6135 - learning_rate: 0.0059\n",
      "Epoch 539/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6783 - loss: 0.6098 - learning_rate: 0.0059\n",
      "Epoch 540/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6759 - loss: 0.6304 - learning_rate: 0.0059\n",
      "Epoch 541/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6887 - loss: 0.6129 - learning_rate: 0.0059\n",
      "Epoch 542/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.6842 - loss: 0.6166 - learning_rate: 0.0059\n",
      "Epoch 543/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6756 - loss: 0.6226 - learning_rate: 0.0059\n",
      "Epoch 544/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6695 - loss: 0.6181 - learning_rate: 0.0059\n",
      "Epoch 545/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6939 - loss: 0.6046 - learning_rate: 0.0059\n",
      "Epoch 546/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.6785 - loss: 0.6210 - learning_rate: 0.0059\n",
      "Epoch 547/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6706 - loss: 0.6223 - learning_rate: 0.0058\n",
      "Epoch 548/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6827 - loss: 0.6086 - learning_rate: 0.0058\n",
      "Epoch 549/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6656 - loss: 0.6258 - learning_rate: 0.0058\n",
      "Epoch 550/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6773 - loss: 0.6256 - learning_rate: 0.0058\n",
      "Epoch 551/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6969 - loss: 0.6025 - learning_rate: 0.0058\n",
      "Epoch 552/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6723 - loss: 0.6117 - learning_rate: 0.0058\n",
      "Epoch 553/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6834 - loss: 0.6178 - learning_rate: 0.0058\n",
      "Epoch 554/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6809 - loss: 0.6140 - learning_rate: 0.0058\n",
      "Epoch 555/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6825 - loss: 0.6188 - learning_rate: 0.0058\n",
      "Epoch 556/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.6730 - loss: 0.6296 - learning_rate: 0.0058\n",
      "Epoch 557/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.6599 - loss: 0.6342 - learning_rate: 0.0058\n",
      "Epoch 558/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6728 - loss: 0.6310 - learning_rate: 0.0058\n",
      "Epoch 559/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6717 - loss: 0.6266 - learning_rate: 0.0058\n",
      "Epoch 560/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6671 - loss: 0.6315 - learning_rate: 0.0058\n",
      "Epoch 561/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6772 - loss: 0.6068 - learning_rate: 0.0058\n",
      "Epoch 562/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6711 - loss: 0.6190 - learning_rate: 0.0058\n",
      "Epoch 563/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6755 - loss: 0.6204 - learning_rate: 0.0058\n",
      "Epoch 564/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.6761 - loss: 0.6231 - learning_rate: 0.0057\n",
      "Epoch 565/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.6680 - loss: 0.6320 - learning_rate: 0.0057\n",
      "Epoch 566/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6886 - loss: 0.6125 - learning_rate: 0.0057\n",
      "Epoch 567/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6799 - loss: 0.6234 - learning_rate: 0.0057\n",
      "Epoch 568/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6979 - loss: 0.6111 - learning_rate: 0.0057\n",
      "Epoch 569/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6791 - loss: 0.6202 - learning_rate: 0.0057\n",
      "Epoch 570/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6663 - loss: 0.6293 - learning_rate: 0.0057\n",
      "Epoch 571/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6924 - loss: 0.6103 - learning_rate: 0.0057\n",
      "Epoch 572/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6792 - loss: 0.6167 - learning_rate: 0.0057\n",
      "Epoch 573/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.6960 - loss: 0.6040 - learning_rate: 0.0057\n",
      "Epoch 574/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6787 - loss: 0.6157 - learning_rate: 0.0057\n",
      "Epoch 575/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6924 - loss: 0.6047 - learning_rate: 0.0057\n",
      "Epoch 576/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6824 - loss: 0.6176 - learning_rate: 0.0057\n",
      "Epoch 577/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6925 - loss: 0.6085 - learning_rate: 0.0057\n",
      "Epoch 578/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6830 - loss: 0.6166 - learning_rate: 0.0057\n",
      "Epoch 579/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6879 - loss: 0.6179 - learning_rate: 0.0057\n",
      "Epoch 580/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6712 - loss: 0.6133 - learning_rate: 0.0057\n",
      "Epoch 581/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6874 - loss: 0.6148 - learning_rate: 0.0056\n",
      "Epoch 582/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.6833 - loss: 0.6141 - learning_rate: 0.0056\n",
      "Epoch 583/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.6927 - loss: 0.6069 - learning_rate: 0.0056\n",
      "Epoch 584/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6975 - loss: 0.6075 - learning_rate: 0.0056\n",
      "Epoch 585/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.6752 - loss: 0.6230 - learning_rate: 0.0056\n",
      "Epoch 586/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6784 - loss: 0.6177 - learning_rate: 0.0056\n",
      "Epoch 587/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7018 - loss: 0.6012 - learning_rate: 0.0056\n",
      "Epoch 588/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6692 - loss: 0.6229 - learning_rate: 0.0056\n",
      "Epoch 589/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6603 - loss: 0.6265 - learning_rate: 0.0056\n",
      "Epoch 590/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6890 - loss: 0.6172 - learning_rate: 0.0056\n",
      "Epoch 591/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.6788 - loss: 0.6174 - learning_rate: 0.0056\n",
      "Epoch 592/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6901 - loss: 0.6067 - learning_rate: 0.0056\n",
      "Epoch 593/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6885 - loss: 0.6146 - learning_rate: 0.0056\n",
      "Epoch 594/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.6856 - loss: 0.6124 - learning_rate: 0.0056\n",
      "Epoch 595/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6720 - loss: 0.6148 - learning_rate: 0.0056\n",
      "Epoch 596/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6923 - loss: 0.6091 - learning_rate: 0.0056\n",
      "Epoch 597/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6954 - loss: 0.6049 - learning_rate: 0.0056\n",
      "Epoch 598/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6756 - loss: 0.6251 - learning_rate: 0.0056\n",
      "Epoch 599/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6812 - loss: 0.6103 - learning_rate: 0.0055\n",
      "Epoch 600/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6782 - loss: 0.6218 - learning_rate: 0.0055\n",
      "Epoch 601/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.6967 - loss: 0.6059 - learning_rate: 0.0055\n",
      "Epoch 602/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6953 - loss: 0.6077 - learning_rate: 0.0055\n",
      "Epoch 603/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6861 - loss: 0.6108 - learning_rate: 0.0055\n",
      "Epoch 604/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6781 - loss: 0.6087 - learning_rate: 0.0055\n",
      "Epoch 605/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6739 - loss: 0.6245 - learning_rate: 0.0055\n",
      "Epoch 606/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6742 - loss: 0.6140 - learning_rate: 0.0055\n",
      "Epoch 607/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6848 - loss: 0.6109 - learning_rate: 0.0055\n",
      "Epoch 608/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6834 - loss: 0.6056 - learning_rate: 0.0055\n",
      "Epoch 609/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6839 - loss: 0.6181 - learning_rate: 0.0055\n",
      "Epoch 610/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.6824 - loss: 0.6166 - learning_rate: 0.0055\n",
      "Epoch 611/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6812 - loss: 0.6236 - learning_rate: 0.0055\n",
      "Epoch 612/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.6892 - loss: 0.6074 - learning_rate: 0.0055\n",
      "Epoch 613/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6876 - loss: 0.6127 - learning_rate: 0.0055\n",
      "Epoch 614/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6751 - loss: 0.6195 - learning_rate: 0.0055\n",
      "Epoch 615/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6919 - loss: 0.6034 - learning_rate: 0.0055\n",
      "Epoch 616/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6783 - loss: 0.6216 - learning_rate: 0.0055\n",
      "Epoch 617/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.6767 - loss: 0.6203 - learning_rate: 0.0054\n",
      "Epoch 618/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6851 - loss: 0.6171 - learning_rate: 0.0054\n",
      "Epoch 619/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6924 - loss: 0.6188 - learning_rate: 0.0054\n",
      "Epoch 620/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6782 - loss: 0.6149 - learning_rate: 0.0054\n",
      "Epoch 621/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6969 - loss: 0.5990 - learning_rate: 0.0054\n",
      "Epoch 622/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6661 - loss: 0.6270 - learning_rate: 0.0054\n",
      "Epoch 623/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6651 - loss: 0.6271 - learning_rate: 0.0054\n",
      "Epoch 624/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6718 - loss: 0.6170 - learning_rate: 0.0054\n",
      "Epoch 625/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7057 - loss: 0.6073 - learning_rate: 0.0054\n",
      "Epoch 626/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.6906 - loss: 0.6120 - learning_rate: 0.0054\n",
      "Epoch 627/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6865 - loss: 0.6141 - learning_rate: 0.0054\n",
      "Epoch 628/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.6843 - loss: 0.6093 - learning_rate: 0.0054\n",
      "Epoch 629/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6893 - loss: 0.6031 - learning_rate: 0.0054\n",
      "Epoch 630/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6862 - loss: 0.6191 - learning_rate: 0.0054\n",
      "Epoch 631/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.6755 - loss: 0.6204 - learning_rate: 0.0054\n",
      "Epoch 632/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6874 - loss: 0.6119 - learning_rate: 0.0054\n",
      "Epoch 633/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6820 - loss: 0.6165 - learning_rate: 0.0054\n",
      "Epoch 634/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6989 - loss: 0.5982 - learning_rate: 0.0054\n",
      "Epoch 635/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6964 - loss: 0.6107 - learning_rate: 0.0054\n",
      "Epoch 636/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6994 - loss: 0.5997 - learning_rate: 0.0053\n",
      "Epoch 637/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6818 - loss: 0.6200 - learning_rate: 0.0053\n",
      "Epoch 638/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6972 - loss: 0.6001 - learning_rate: 0.0053\n",
      "Epoch 639/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7030 - loss: 0.5987 - learning_rate: 0.0053\n",
      "Epoch 640/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6893 - loss: 0.6077 - learning_rate: 0.0053\n",
      "Epoch 641/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6674 - loss: 0.6283 - learning_rate: 0.0053\n",
      "Epoch 642/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6778 - loss: 0.6266 - learning_rate: 0.0053\n",
      "Epoch 643/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.6939 - loss: 0.6076 - learning_rate: 0.0053\n",
      "Epoch 644/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.6812 - loss: 0.6194 - learning_rate: 0.0053\n",
      "Epoch 645/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6847 - loss: 0.6214 - learning_rate: 0.0053\n",
      "Epoch 646/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.6908 - loss: 0.6139 - learning_rate: 0.0053\n",
      "Epoch 647/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6889 - loss: 0.6149 - learning_rate: 0.0053\n",
      "Epoch 648/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6823 - loss: 0.6050 - learning_rate: 0.0053\n",
      "Epoch 649/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6806 - loss: 0.6136 - learning_rate: 0.0053\n",
      "Epoch 650/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6815 - loss: 0.6077 - learning_rate: 0.0053\n",
      "Epoch 651/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6907 - loss: 0.6114 - learning_rate: 0.0053\n",
      "Epoch 652/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7018 - loss: 0.6063 - learning_rate: 0.0053\n",
      "Epoch 653/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6796 - loss: 0.6095 - learning_rate: 0.0053\n",
      "Epoch 654/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6767 - loss: 0.6249 - learning_rate: 0.0053\n",
      "Epoch 655/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6776 - loss: 0.6183 - learning_rate: 0.0052\n",
      "Epoch 656/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6846 - loss: 0.6224 - learning_rate: 0.0052\n",
      "Epoch 657/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6785 - loss: 0.6196 - learning_rate: 0.0052\n",
      "Epoch 658/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6900 - loss: 0.6089 - learning_rate: 0.0052\n",
      "Epoch 659/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.6855 - loss: 0.6117 - learning_rate: 0.0052\n",
      "Epoch 660/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.6820 - loss: 0.6212 - learning_rate: 0.0052\n",
      "Epoch 661/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.6864 - loss: 0.6115 - learning_rate: 0.0052\n",
      "Epoch 662/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6701 - loss: 0.6305 - learning_rate: 0.0052\n",
      "Epoch 663/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6807 - loss: 0.6161 - learning_rate: 0.0052\n",
      "Epoch 664/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6871 - loss: 0.6177 - learning_rate: 0.0052\n",
      "Epoch 665/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6814 - loss: 0.6105 - learning_rate: 0.0052\n",
      "Epoch 666/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6824 - loss: 0.6141 - learning_rate: 0.0052\n",
      "Epoch 667/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6854 - loss: 0.6188 - learning_rate: 0.0052\n",
      "Epoch 668/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.6712 - loss: 0.6128 - learning_rate: 0.0052\n",
      "Epoch 669/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.6689 - loss: 0.6255 - learning_rate: 0.0052\n",
      "Epoch 670/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.6773 - loss: 0.6219 - learning_rate: 0.0052\n",
      "Epoch 671/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6671 - loss: 0.6196 - learning_rate: 0.0052\n",
      "Epoch 672/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6854 - loss: 0.6166 - learning_rate: 0.0052\n",
      "Epoch 673/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6779 - loss: 0.6105 - learning_rate: 0.0052\n",
      "Epoch 674/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7005 - loss: 0.6044 - learning_rate: 0.0051\n",
      "Epoch 675/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6924 - loss: 0.6016 - learning_rate: 0.0051\n",
      "Epoch 676/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.7001 - loss: 0.6069 - learning_rate: 0.0051\n",
      "Epoch 677/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.6668 - loss: 0.6240 - learning_rate: 0.0051\n",
      "Epoch 678/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6755 - loss: 0.6084 - learning_rate: 0.0051\n",
      "Epoch 679/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6707 - loss: 0.6183 - learning_rate: 0.0051\n",
      "Epoch 680/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6838 - loss: 0.6189 - learning_rate: 0.0051\n",
      "Epoch 681/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6821 - loss: 0.6091 - learning_rate: 0.0051\n",
      "Epoch 682/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6870 - loss: 0.6147 - learning_rate: 0.0051\n",
      "Epoch 683/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6736 - loss: 0.6186 - learning_rate: 0.0051\n",
      "Epoch 684/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6852 - loss: 0.6168 - learning_rate: 0.0051\n",
      "Epoch 685/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.6851 - loss: 0.6100 - learning_rate: 0.0051\n",
      "Epoch 686/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.6821 - loss: 0.6191 - learning_rate: 0.0051\n",
      "Epoch 687/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.6798 - loss: 0.6186 - learning_rate: 0.0051\n",
      "Epoch 688/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6782 - loss: 0.6221 - learning_rate: 0.0051\n",
      "Epoch 689/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6922 - loss: 0.6025 - learning_rate: 0.0051\n",
      "Epoch 690/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6970 - loss: 0.6062 - learning_rate: 0.0051\n",
      "Epoch 691/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6661 - loss: 0.6223 - learning_rate: 0.0051\n",
      "Epoch 692/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6933 - loss: 0.6050 - learning_rate: 0.0051\n",
      "Epoch 693/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6878 - loss: 0.6185 - learning_rate: 0.0051\n",
      "Epoch 694/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6928 - loss: 0.6026 - learning_rate: 0.0050\n",
      "Epoch 695/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.6836 - loss: 0.6161 - learning_rate: 0.0050\n",
      "Epoch 696/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6760 - loss: 0.6197 - learning_rate: 0.0050\n",
      "Epoch 697/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6815 - loss: 0.6076 - learning_rate: 0.0050\n",
      "Epoch 698/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6713 - loss: 0.6202 - learning_rate: 0.0050\n",
      "Epoch 699/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.6935 - loss: 0.6024 - learning_rate: 0.0050\n",
      "Epoch 700/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6904 - loss: 0.5998 - learning_rate: 0.0050\n",
      "Epoch 701/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6922 - loss: 0.6083 - learning_rate: 0.0050\n",
      "Epoch 702/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6667 - loss: 0.6254 - learning_rate: 0.0050\n",
      "Epoch 703/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6863 - loss: 0.6125 - learning_rate: 0.0050\n",
      "Epoch 704/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.6938 - loss: 0.6054 - learning_rate: 0.0050\n",
      "Epoch 705/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6782 - loss: 0.6216 - learning_rate: 0.0050\n",
      "Epoch 706/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6859 - loss: 0.6112 - learning_rate: 0.0050\n",
      "Epoch 707/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6769 - loss: 0.6151 - learning_rate: 0.0050\n",
      "Epoch 708/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6805 - loss: 0.6162 - learning_rate: 0.0050\n",
      "Epoch 709/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6792 - loss: 0.6185 - learning_rate: 0.0050\n",
      "Epoch 710/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6854 - loss: 0.6061 - learning_rate: 0.0050\n",
      "Epoch 711/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6826 - loss: 0.6032 - learning_rate: 0.0050\n",
      "Epoch 712/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.6714 - loss: 0.6237 - learning_rate: 0.0050\n",
      "Epoch 713/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6909 - loss: 0.5981 - learning_rate: 0.0050\n",
      "Epoch 714/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6718 - loss: 0.6175 - learning_rate: 0.0049\n",
      "Epoch 715/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6857 - loss: 0.6099 - learning_rate: 0.0049\n",
      "Epoch 716/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6872 - loss: 0.6104 - learning_rate: 0.0049\n",
      "Epoch 717/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6831 - loss: 0.6089 - learning_rate: 0.0049\n",
      "Epoch 718/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6745 - loss: 0.6117 - learning_rate: 0.0049\n",
      "Epoch 719/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7045 - loss: 0.6003 - learning_rate: 0.0049\n",
      "Epoch 720/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6848 - loss: 0.6049 - learning_rate: 0.0049\n",
      "Epoch 721/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.6856 - loss: 0.6084 - learning_rate: 0.0049\n",
      "Epoch 722/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7014 - loss: 0.6100 - learning_rate: 0.0049\n",
      "Epoch 723/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6668 - loss: 0.6221 - learning_rate: 0.0049\n",
      "Epoch 724/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6857 - loss: 0.6138 - learning_rate: 0.0049\n",
      "Epoch 725/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6891 - loss: 0.6040 - learning_rate: 0.0049\n",
      "Epoch 726/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6870 - loss: 0.6113 - learning_rate: 0.0049\n",
      "Epoch 727/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6896 - loss: 0.6035 - learning_rate: 0.0049\n",
      "Epoch 728/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6719 - loss: 0.6167 - learning_rate: 0.0049\n",
      "Epoch 729/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6758 - loss: 0.6189 - learning_rate: 0.0049\n",
      "Epoch 730/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.6721 - loss: 0.6285 - learning_rate: 0.0049\n",
      "Epoch 731/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6911 - loss: 0.5964 - learning_rate: 0.0049\n",
      "Epoch 732/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6849 - loss: 0.6079 - learning_rate: 0.0049\n",
      "Epoch 733/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6903 - loss: 0.6099 - learning_rate: 0.0049\n",
      "Epoch 734/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6757 - loss: 0.6127 - learning_rate: 0.0048\n",
      "Epoch 735/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6812 - loss: 0.6010 - learning_rate: 0.0048\n",
      "Epoch 736/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6640 - loss: 0.6181 - learning_rate: 0.0048\n",
      "Epoch 737/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6760 - loss: 0.6168 - learning_rate: 0.0048\n",
      "Epoch 738/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6694 - loss: 0.6203 - learning_rate: 0.0048\n",
      "Epoch 739/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.6878 - loss: 0.6162 - learning_rate: 0.0048\n",
      "Epoch 740/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6964 - loss: 0.6063 - learning_rate: 0.0048\n",
      "Epoch 741/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6745 - loss: 0.6188 - learning_rate: 0.0048\n",
      "Epoch 742/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6756 - loss: 0.6189 - learning_rate: 0.0048\n",
      "Epoch 743/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7041 - loss: 0.5983 - learning_rate: 0.0048\n",
      "Epoch 744/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6829 - loss: 0.6168 - learning_rate: 0.0048\n",
      "Epoch 745/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6843 - loss: 0.6170 - learning_rate: 0.0048\n",
      "Epoch 746/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6647 - loss: 0.6264 - learning_rate: 0.0048\n",
      "Epoch 747/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6869 - loss: 0.6127 - learning_rate: 0.0048\n",
      "Epoch 748/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.6928 - loss: 0.6037 - learning_rate: 0.0048\n",
      "Epoch 749/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6839 - loss: 0.6064 - learning_rate: 0.0048\n",
      "Epoch 750/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.6891 - loss: 0.6092 - learning_rate: 0.0048\n",
      "Epoch 751/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6759 - loss: 0.6217 - learning_rate: 0.0048\n",
      "Epoch 752/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6907 - loss: 0.6034 - learning_rate: 0.0048\n",
      "Epoch 753/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7009 - loss: 0.6068 - learning_rate: 0.0048\n",
      "Epoch 754/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6878 - loss: 0.6138 - learning_rate: 0.0048\n",
      "Epoch 755/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6982 - loss: 0.5986 - learning_rate: 0.0047\n",
      "Epoch 756/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6906 - loss: 0.6145 - learning_rate: 0.0047\n",
      "Epoch 757/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6982 - loss: 0.6036 - learning_rate: 0.0047\n",
      "Epoch 758/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.6895 - loss: 0.6061 - learning_rate: 0.0047\n",
      "Epoch 759/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.6846 - loss: 0.6150 - learning_rate: 0.0047\n",
      "Epoch 760/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6786 - loss: 0.6126 - learning_rate: 0.0047\n",
      "Epoch 761/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6925 - loss: 0.6038 - learning_rate: 0.0047\n",
      "Epoch 762/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6949 - loss: 0.5960 - learning_rate: 0.0047\n",
      "Epoch 763/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6896 - loss: 0.6065 - learning_rate: 0.0047\n",
      "Epoch 764/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6855 - loss: 0.6155 - learning_rate: 0.0047\n",
      "Epoch 765/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6871 - loss: 0.6097 - learning_rate: 0.0047\n",
      "Epoch 766/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6618 - loss: 0.6244 - learning_rate: 0.0047\n",
      "Epoch 767/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.6955 - loss: 0.6049 - learning_rate: 0.0047\n",
      "Epoch 768/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6825 - loss: 0.6161 - learning_rate: 0.0047\n",
      "Epoch 769/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6791 - loss: 0.6118 - learning_rate: 0.0047\n",
      "Epoch 770/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7028 - loss: 0.6004 - learning_rate: 0.0047\n",
      "Epoch 771/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6872 - loss: 0.6137 - learning_rate: 0.0047\n",
      "Epoch 772/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7035 - loss: 0.5926 - learning_rate: 0.0047\n",
      "Epoch 773/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6977 - loss: 0.5951 - learning_rate: 0.0047\n",
      "Epoch 774/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6807 - loss: 0.6123 - learning_rate: 0.0047\n",
      "Epoch 775/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6952 - loss: 0.5968 - learning_rate: 0.0047\n",
      "Epoch 776/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6726 - loss: 0.6220 - learning_rate: 0.0046\n",
      "Epoch 777/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6784 - loss: 0.6197 - learning_rate: 0.0046\n",
      "Epoch 778/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6688 - loss: 0.6245 - learning_rate: 0.0046\n",
      "Epoch 779/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6978 - loss: 0.6013 - learning_rate: 0.0046\n",
      "Epoch 780/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6626 - loss: 0.6271 - learning_rate: 0.0046\n",
      "Epoch 781/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7096 - loss: 0.5982 - learning_rate: 0.0046\n",
      "Epoch 782/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7027 - loss: 0.6024 - learning_rate: 0.0046\n",
      "Epoch 783/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7062 - loss: 0.6000 - learning_rate: 0.0046\n",
      "Epoch 784/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6878 - loss: 0.6050 - learning_rate: 0.0046\n",
      "Epoch 785/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.6968 - loss: 0.6046 - learning_rate: 0.0046\n",
      "Epoch 786/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6835 - loss: 0.6106 - learning_rate: 0.0046\n",
      "Epoch 787/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.6803 - loss: 0.6242 - learning_rate: 0.0046\n",
      "Epoch 788/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6861 - loss: 0.6088 - learning_rate: 0.0046\n",
      "Epoch 789/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7000 - loss: 0.5967 - learning_rate: 0.0046\n",
      "Epoch 790/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6837 - loss: 0.6113 - learning_rate: 0.0046\n",
      "Epoch 791/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.6964 - loss: 0.6027 - learning_rate: 0.0046\n",
      "Epoch 792/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6956 - loss: 0.5995 - learning_rate: 0.0046\n",
      "Epoch 793/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6798 - loss: 0.6136 - learning_rate: 0.0046\n",
      "Epoch 794/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6987 - loss: 0.5974 - learning_rate: 0.0046\n",
      "Epoch 795/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6910 - loss: 0.6192 - learning_rate: 0.0046\n",
      "Epoch 796/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7040 - loss: 0.6032 - learning_rate: 0.0046\n",
      "Epoch 797/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.6880 - loss: 0.6093 - learning_rate: 0.0046\n",
      "Epoch 798/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6892 - loss: 0.5993 - learning_rate: 0.0045\n",
      "Epoch 799/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6919 - loss: 0.6026 - learning_rate: 0.0045\n",
      "Epoch 800/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6965 - loss: 0.6057 - learning_rate: 0.0045\n",
      "Epoch 801/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6805 - loss: 0.6219 - learning_rate: 0.0045\n",
      "Epoch 802/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.6898 - loss: 0.6045 - learning_rate: 0.0045\n",
      "Epoch 803/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6938 - loss: 0.6056 - learning_rate: 0.0045\n",
      "Epoch 804/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.6902 - loss: 0.6062 - learning_rate: 0.0045\n",
      "Epoch 805/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.6730 - loss: 0.6174 - learning_rate: 0.0045\n",
      "Epoch 806/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.6961 - loss: 0.5983 - learning_rate: 0.0045\n",
      "Epoch 807/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6730 - loss: 0.6142 - learning_rate: 0.0045\n",
      "Epoch 808/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7026 - loss: 0.5930 - learning_rate: 0.0045\n",
      "Epoch 809/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6770 - loss: 0.6252 - learning_rate: 0.0045\n",
      "Epoch 810/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6957 - loss: 0.6065 - learning_rate: 0.0045\n",
      "Epoch 811/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6867 - loss: 0.6023 - learning_rate: 0.0045\n",
      "Epoch 812/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6919 - loss: 0.6058 - learning_rate: 0.0045\n",
      "Epoch 813/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7054 - loss: 0.6010 - learning_rate: 0.0045\n",
      "Epoch 814/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.6963 - loss: 0.6011 - learning_rate: 0.0045\n",
      "Epoch 815/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6916 - loss: 0.6084 - learning_rate: 0.0045\n",
      "Epoch 816/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6833 - loss: 0.6070 - learning_rate: 0.0045\n",
      "Epoch 817/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.6762 - loss: 0.6118 - learning_rate: 0.0045\n",
      "Epoch 818/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.6875 - loss: 0.6036 - learning_rate: 0.0045\n",
      "Epoch 819/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6994 - loss: 0.6024 - learning_rate: 0.0045\n",
      "Epoch 820/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6951 - loss: 0.5931 - learning_rate: 0.0044\n",
      "Epoch 821/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6721 - loss: 0.6218 - learning_rate: 0.0044\n",
      "Epoch 822/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.6946 - loss: 0.6004 - learning_rate: 0.0044\n",
      "Epoch 823/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.6847 - loss: 0.6272 - learning_rate: 0.0044\n",
      "Epoch 824/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6890 - loss: 0.6085 - learning_rate: 0.0044\n",
      "Epoch 825/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6757 - loss: 0.6156 - learning_rate: 0.0044\n",
      "Epoch 826/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6771 - loss: 0.6324 - learning_rate: 0.0044\n",
      "Epoch 827/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7074 - loss: 0.6029 - learning_rate: 0.0044\n",
      "Epoch 828/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6592 - loss: 0.6317 - learning_rate: 0.0044\n",
      "Epoch 829/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6912 - loss: 0.5948 - learning_rate: 0.0044\n",
      "Epoch 830/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.6895 - loss: 0.6098 - learning_rate: 0.0044\n",
      "Epoch 831/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.6773 - loss: 0.6170 - learning_rate: 0.0044\n",
      "Epoch 832/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6809 - loss: 0.6148 - learning_rate: 0.0044\n",
      "Epoch 833/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6941 - loss: 0.6073 - learning_rate: 0.0044\n",
      "Epoch 834/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6680 - loss: 0.6238 - learning_rate: 0.0044\n",
      "Epoch 835/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6884 - loss: 0.6027 - learning_rate: 0.0044\n",
      "Epoch 836/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6711 - loss: 0.6225 - learning_rate: 0.0044\n",
      "Epoch 837/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6734 - loss: 0.6185 - learning_rate: 0.0044\n",
      "Epoch 838/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.6926 - loss: 0.6103 - learning_rate: 0.0044\n",
      "Epoch 839/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6950 - loss: 0.5990 - learning_rate: 0.0044\n",
      "Epoch 840/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.6897 - loss: 0.6187 - learning_rate: 0.0044\n",
      "Epoch 841/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6876 - loss: 0.6034 - learning_rate: 0.0044\n",
      "Epoch 842/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.6677 - loss: 0.6277 - learning_rate: 0.0044\n",
      "Epoch 843/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6796 - loss: 0.6178 - learning_rate: 0.0043\n",
      "Epoch 844/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6978 - loss: 0.6086 - learning_rate: 0.0043\n",
      "Epoch 845/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6996 - loss: 0.5983 - learning_rate: 0.0043\n",
      "Epoch 846/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7022 - loss: 0.5956 - learning_rate: 0.0043\n",
      "Epoch 847/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6581 - loss: 0.6230 - learning_rate: 0.0043\n",
      "Epoch 848/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.6979 - loss: 0.6141 - learning_rate: 0.0043\n",
      "Epoch 849/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6879 - loss: 0.6112 - learning_rate: 0.0043\n",
      "Epoch 850/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6834 - loss: 0.6119 - learning_rate: 0.0043\n",
      "Epoch 851/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6867 - loss: 0.6165 - learning_rate: 0.0043\n",
      "Epoch 852/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7130 - loss: 0.5802 - learning_rate: 0.0043\n",
      "Epoch 853/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6690 - loss: 0.6245 - learning_rate: 0.0043\n",
      "Epoch 854/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7102 - loss: 0.6050 - learning_rate: 0.0043\n",
      "Epoch 855/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.6965 - loss: 0.6004 - learning_rate: 0.0043\n",
      "Epoch 856/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6772 - loss: 0.6141 - learning_rate: 0.0043\n",
      "Epoch 857/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.6940 - loss: 0.6114 - learning_rate: 0.0043\n",
      "Epoch 858/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6845 - loss: 0.6162 - learning_rate: 0.0043\n",
      "Epoch 859/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6954 - loss: 0.6070 - learning_rate: 0.0043\n",
      "Epoch 860/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6913 - loss: 0.6103 - learning_rate: 0.0043\n",
      "Epoch 861/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6862 - loss: 0.6090 - learning_rate: 0.0043\n",
      "Epoch 862/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7009 - loss: 0.6013 - learning_rate: 0.0043\n",
      "Epoch 863/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6756 - loss: 0.6112 - learning_rate: 0.0043\n",
      "Epoch 864/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7006 - loss: 0.5900 - learning_rate: 0.0043\n",
      "Epoch 865/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6956 - loss: 0.6030 - learning_rate: 0.0043\n",
      "Epoch 866/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.6802 - loss: 0.6164 - learning_rate: 0.0042\n",
      "Epoch 867/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6876 - loss: 0.6084 - learning_rate: 0.0042\n",
      "Epoch 868/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.6896 - loss: 0.6001 - learning_rate: 0.0042\n",
      "Epoch 869/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7011 - loss: 0.5963 - learning_rate: 0.0042\n",
      "Epoch 870/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6966 - loss: 0.6038 - learning_rate: 0.0042\n",
      "Epoch 871/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6701 - loss: 0.6180 - learning_rate: 0.0042\n",
      "Epoch 872/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6961 - loss: 0.5996 - learning_rate: 0.0042\n",
      "Epoch 873/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6861 - loss: 0.6104 - learning_rate: 0.0042\n",
      "Epoch 874/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.6944 - loss: 0.6042 - learning_rate: 0.0042\n",
      "Epoch 875/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.6998 - loss: 0.6070 - learning_rate: 0.0042\n",
      "Epoch 876/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7030 - loss: 0.5909 - learning_rate: 0.0042\n",
      "Epoch 877/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6753 - loss: 0.6062 - learning_rate: 0.0042\n",
      "Epoch 878/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.6955 - loss: 0.6021 - learning_rate: 0.0042\n",
      "Epoch 879/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.6961 - loss: 0.5944 - learning_rate: 0.0042\n",
      "Epoch 880/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.6863 - loss: 0.6187 - learning_rate: 0.0042\n",
      "Epoch 881/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6774 - loss: 0.6177 - learning_rate: 0.0042\n",
      "Epoch 882/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6884 - loss: 0.6028 - learning_rate: 0.0042\n",
      "Epoch 883/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7057 - loss: 0.6018 - learning_rate: 0.0042\n",
      "Epoch 884/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6981 - loss: 0.6002 - learning_rate: 0.0042\n",
      "Epoch 885/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6826 - loss: 0.6169 - learning_rate: 0.0042\n",
      "Epoch 886/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6923 - loss: 0.6107 - learning_rate: 0.0042\n",
      "Epoch 887/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6813 - loss: 0.6037 - learning_rate: 0.0042\n",
      "Epoch 888/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7056 - loss: 0.5892 - learning_rate: 0.0042\n",
      "Epoch 889/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.6733 - loss: 0.6197 - learning_rate: 0.0042\n",
      "Epoch 890/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6862 - loss: 0.5999 - learning_rate: 0.0041\n",
      "Epoch 891/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6762 - loss: 0.6190 - learning_rate: 0.0041\n",
      "Epoch 892/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6798 - loss: 0.6113 - learning_rate: 0.0041\n",
      "Epoch 893/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7082 - loss: 0.5910 - learning_rate: 0.0041\n",
      "Epoch 894/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7074 - loss: 0.5972 - learning_rate: 0.0041\n",
      "Epoch 895/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7140 - loss: 0.5959 - learning_rate: 0.0041\n",
      "Epoch 896/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6845 - loss: 0.6043 - learning_rate: 0.0041\n",
      "Epoch 897/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6847 - loss: 0.6064 - learning_rate: 0.0041\n",
      "Epoch 898/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6906 - loss: 0.6132 - learning_rate: 0.0041\n",
      "Epoch 899/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6982 - loss: 0.5987 - learning_rate: 0.0041\n",
      "Epoch 900/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6746 - loss: 0.6162 - learning_rate: 0.0041\n",
      "Epoch 901/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.6812 - loss: 0.6096 - learning_rate: 0.0041\n",
      "Epoch 902/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.6935 - loss: 0.6026 - learning_rate: 0.0041\n",
      "Epoch 903/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6835 - loss: 0.6011 - learning_rate: 0.0041\n",
      "Epoch 904/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6836 - loss: 0.6134 - learning_rate: 0.0041\n",
      "Epoch 905/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6809 - loss: 0.6144 - learning_rate: 0.0041\n",
      "Epoch 906/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6906 - loss: 0.6049 - learning_rate: 0.0041\n",
      "Epoch 907/2000\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6854 - loss: 0.6167 - learning_rate: 0.0041\n",
      "Epoch 908/2000\n",
      "\u001b[1m 1/67\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6562 - loss: 0.6386"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.001).numpy())\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                             # patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_generator, batch_size=1024, epochs=2000, callbacks=[lr_scheduler ]) #default batch=32\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(Xtest, ytest)\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_ = range(1,len(acc)+1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_, acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs_, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_, loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs_, val_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], 'r', label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 使用相同的 history 對象\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplot_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m, in \u001b[0;36mplot_accuracy\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and Validation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], 'r', label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'b', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 使用相同的 history 對象\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_excel(\"01test.xlsx\")\n",
    "\n",
    "feature_ex = ['手機螢幕溫度(平均)', '手機背蓋溫度(平均)', '充電時間指標', '手機電池電量', 'CPU跑分階級', '上網頻率指標', '通話頻率指標', '內容容量比率']\n",
    "test_data = test[feature_ex].to_numpy()\n",
    "\n",
    "test_data=data_normalized(test_data)\n",
    "test_data=data_standardized(test_data)\n",
    "test_data=data_normalized(test_data)\n",
    "test_data=data_standardized(test_data)\n",
    "\n",
    "pca=PCA(n_components=6)\n",
    "test_data_pca=pca.fit(test_data).transform(test_data)\n",
    "test_data=test_data_pca\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans = model.predict(test_data)\n",
    "print(np.mean(predicted_ans))\n",
    "predicted_classes = (predicted_ans > 0.5).astype(int)\n",
    "\n",
    "\n",
    "print(predicted_classes .shape)\n",
    "\n",
    "if predicted_classes .ndim > 1:\n",
    "    predicted_classes  = predicted_classes .squeeze()\n",
    "print(predicted_classes .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'id': test.id, 'Underclocking': predicted_classes })\n",
    "my_submission.to_csv('submision_67_7472.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model-cross \n",
    "def create_model(input_dim):\n",
    "    l2_regularizer = tf.keras.regularizers.l2(0.001)\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_features,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),   \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "input_dim = x_data.shape[1]  # 获取输入特征的数量\n",
    "\n",
    "for train_index, test_index in kf.split(x_data):\n",
    "    # 分割数据\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    # 创建模型\n",
    "    model = create_model(input_dim)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # 评估模型\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    scores.append(score[1])  # 假设我们关心的是准确率\n",
    "\n",
    "# 打印每折的准确率以及平均准确率\n",
    "print(\"每折的准确率:\", scores)\n",
    "print(\"平均准确率:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "def build_model(n_layers, input_dim, regularization_rate=0.01, dropout_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(input_dim,), kernel_regularizer=l2(regularization_rate)))\n",
    "    for _ in range(n_layers - 1):\n",
    "        model.add(Dense(64 // _ if 64 // _ > 4 else 4, activation='relu', kernel_regularizer=l2(regularization_rate)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, y_train, x_test, y_test, epochs=50):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), verbose=0)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_data.shape[1]  # 假設x_data已經定義並準備好了\n",
    "regularization_rate = 0.01\n",
    "dropout_rate = 0.001\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "max_layers = 20  # 嘗試的最大層數\n",
    "results = {}\n",
    "\n",
    "for n_layers in range(1, max_layers + 1):\n",
    "    model = build_model(n_layers, input_dim, regularization_rate, dropout_rate)\n",
    "    history = evaluate_model(model, x_train, y_train, x_test, y_test)\n",
    "    accuracy = np.max(history.history['val_accuracy'])  # 取最好的驗證準確率\n",
    "    results[n_layers] = accuracy\n",
    "    print(f\"Tested {n_layers} layers: Validation Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# 找到最佳層數\n",
    "best_layers = max(results, key=results.get)\n",
    "print(f\"Best number of layers: {best_layers} with Accuracy: {results[best_layers]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ecaae8ee4afd5bfff7a9898a6bb698a1db0284ded0ac21bd42c4412026a1621f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
