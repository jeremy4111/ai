{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10 as data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>手機螢幕溫度(平均)</th>\n",
       "      <th>手機螢幕溫度(最大)</th>\n",
       "      <th>手機背蓋溫度(平均)</th>\n",
       "      <th>平均APP運作指標/小時</th>\n",
       "      <th>充電時間指標</th>\n",
       "      <th>手機電池電量</th>\n",
       "      <th>CPU跑分階級</th>\n",
       "      <th>手機外殼/包膜指標</th>\n",
       "      <th>外型平均曲率</th>\n",
       "      <th>上網頻率指標</th>\n",
       "      <th>通話頻率指標</th>\n",
       "      <th>新機/二手/老舊</th>\n",
       "      <th>內容容量比率</th>\n",
       "      <th>CPU效能等級</th>\n",
       "      <th>Underclocking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.984541</td>\n",
       "      <td>45.294944</td>\n",
       "      <td>52.784871</td>\n",
       "      <td>656.507337</td>\n",
       "      <td>0.225864</td>\n",
       "      <td>75.190124</td>\n",
       "      <td>3.319754</td>\n",
       "      <td>0.109481</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>2553.566565</td>\n",
       "      <td>2209.062206</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>0.833713</td>\n",
       "      <td>1.319754</td>\n",
       "      <td>0.428132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.540574</td>\n",
       "      <td>15.546263</td>\n",
       "      <td>64.786127</td>\n",
       "      <td>717.237752</td>\n",
       "      <td>0.232311</td>\n",
       "      <td>14.008806</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.090865</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>1829.663990</td>\n",
       "      <td>1810.428997</td>\n",
       "      <td>0.572666</td>\n",
       "      <td>12.506317</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.494871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.902370</td>\n",
       "      <td>8.047619</td>\n",
       "      <td>2.562656</td>\n",
       "      <td>-8000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.889610</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>-1.043000</td>\n",
       "      <td>0.675070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-600.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.642857</td>\n",
       "      <td>34.880952</td>\n",
       "      <td>43.504429</td>\n",
       "      <td>224.700000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>62.761544</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.058475</td>\n",
       "      <td>-0.055860</td>\n",
       "      <td>948.100000</td>\n",
       "      <td>579.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.976190</td>\n",
       "      <td>47.023810</td>\n",
       "      <td>53.053333</td>\n",
       "      <td>413.100000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>76.677489</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>2276.000000</td>\n",
       "      <td>1898.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.119048</td>\n",
       "      <td>57.345238</td>\n",
       "      <td>60.650000</td>\n",
       "      <td>834.969651</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>86.821260</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>0.078966</td>\n",
       "      <td>3839.552040</td>\n",
       "      <td>3455.073327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.619048</td>\n",
       "      <td>79.547619</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4412.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.776212</td>\n",
       "      <td>1.208233</td>\n",
       "      <td>8410.000000</td>\n",
       "      <td>8129.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        手機螢幕溫度(平均)   手機螢幕溫度(最大)   手機背蓋溫度(平均)  平均APP運作指標/小時       充電時間指標  \\\n",
       "count  3903.000000  3903.000000  3903.000000   3903.000000  3903.000000   \n",
       "mean     38.984541    45.294944    52.784871    656.507337     0.225864   \n",
       "std      14.540574    15.546263    64.786127    717.237752     0.232311   \n",
       "min       7.902370     8.047619     2.562656  -8000.000000     0.000000   \n",
       "25%      28.642857    34.880952    43.504429    224.700000     0.030303   \n",
       "50%      38.976190    47.023810    53.053333    413.100000     0.142857   \n",
       "75%      50.119048    57.345238    60.650000    834.969651     0.371429   \n",
       "max      75.619048    79.547619  4000.000000   4412.000000     0.966667   \n",
       "\n",
       "            手機電池電量      CPU跑分階級    手機外殼/包膜指標       外型平均曲率       上網頻率指標  \\\n",
       "count  3903.000000  3903.000000  3903.000000  3903.000000  3903.000000   \n",
       "mean     75.190124     3.319754     0.109481     0.015342  2553.566565   \n",
       "std      14.008806     0.684632     0.090865     0.125137  1829.663990   \n",
       "min      47.889610     3.000000     0.003690    -1.043000     0.675070   \n",
       "25%      62.761544     3.000000     0.058475    -0.055860   948.100000   \n",
       "50%      76.677489     3.000000     0.085307     0.005701  2276.000000   \n",
       "75%      86.821260     3.000000     0.143723     0.078966  3839.552040   \n",
       "max     100.000000     6.000000     1.776212     1.208233  8410.000000   \n",
       "\n",
       "            通話頻率指標     新機/二手/老舊       內容容量比率      CPU效能等級  Underclocking  \n",
       "count  3903.000000  3903.000000  3903.000000  3903.000000    3903.000000  \n",
       "mean   2209.062206     0.297463     0.833713     1.319754       0.428132  \n",
       "std    1810.428997     0.572666    12.506317     0.684632       0.494871  \n",
       "min       0.000000     0.000000  -600.000000     1.000000       0.000000  \n",
       "25%     579.800000     0.000000     0.802960     1.000000       0.000000  \n",
       "50%    1898.000000     0.000000     0.937191     1.000000       0.000000  \n",
       "75%    3455.073327     1.000000     0.987258     1.000000       1.000000  \n",
       "max    8129.000000     5.000000   500.000000     4.000000       1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#immport data\n",
    "data_frame = pd.read_excel(\"train.xlsx\")\n",
    "data_frame1 = pd.read_excel(\"data_anysis.xlsx\")\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手機螢幕溫度(平均)\n",
      "Shape Of The Before Ouliers:  (3903,)\n",
      "Shape Of The After Ouliers:  (3903,)\n",
      "===================================================================================================================\n",
      "手機螢幕溫度(最大)\n",
      "Shape Of The Before Ouliers:  (3903,)\n",
      "Shape Of The After Ouliers:  (3903,)\n",
      "===================================================================================================================\n",
      "手機背蓋溫度(平均)\n",
      "Shape Of The Before Ouliers:  (3903,)\n",
      "Shape Of The After Ouliers:  (3839,)\n",
      "===================================================================================================================\n",
      "平均APP運作指標/小時\n",
      "Shape Of The Before Ouliers:  (3839,)\n",
      "Shape Of The After Ouliers:  (3632,)\n",
      "===================================================================================================================\n",
      "充電時間指標\n",
      "Shape Of The Before Ouliers:  (3632,)\n",
      "Shape Of The After Ouliers:  (3632,)\n",
      "===================================================================================================================\n",
      "手機電池電量\n",
      "Shape Of The Before Ouliers:  (3632,)\n",
      "Shape Of The After Ouliers:  (3632,)\n",
      "===================================================================================================================\n",
      "CPU跑分階級\n",
      "Shape Of The Before Ouliers:  (3632,)\n",
      "Shape Of The After Ouliers:  (2952,)\n",
      "===================================================================================================================\n",
      "手機外殼/包膜指標\n",
      "Shape Of The Before Ouliers:  (2952,)\n",
      "Shape Of The After Ouliers:  (2949,)\n",
      "===================================================================================================================\n",
      "外型平均曲率\n",
      "Shape Of The Before Ouliers:  (2949,)\n",
      "Shape Of The After Ouliers:  (2892,)\n",
      "===================================================================================================================\n",
      "上網頻率指標\n",
      "Shape Of The Before Ouliers:  (2892,)\n",
      "Shape Of The After Ouliers:  (2892,)\n",
      "===================================================================================================================\n",
      "通話頻率指標\n",
      "Shape Of The Before Ouliers:  (2892,)\n",
      "Shape Of The After Ouliers:  (2892,)\n",
      "===================================================================================================================\n",
      "新機/二手/老舊\n",
      "Shape Of The Before Ouliers:  (2892,)\n",
      "Shape Of The After Ouliers:  (2885,)\n",
      "===================================================================================================================\n",
      "內容容量比率\n",
      "Shape Of The Before Ouliers:  (2885,)\n",
      "Shape Of The After Ouliers:  (2771,)\n",
      "===================================================================================================================\n",
      "CPU效能等級\n",
      "Shape Of The Before Ouliers:  (2771,)\n",
      "Shape Of The After Ouliers:  (2771,)\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>手機螢幕溫度(平均)</th>\n",
       "      <th>手機螢幕溫度(最大)</th>\n",
       "      <th>手機背蓋溫度(平均)</th>\n",
       "      <th>平均APP運作指標/小時</th>\n",
       "      <th>充電時間指標</th>\n",
       "      <th>手機電池電量</th>\n",
       "      <th>CPU跑分階級</th>\n",
       "      <th>手機外殼/包膜指標</th>\n",
       "      <th>外型平均曲率</th>\n",
       "      <th>上網頻率指標</th>\n",
       "      <th>通話頻率指標</th>\n",
       "      <th>新機/二手/老舊</th>\n",
       "      <th>內容容量比率</th>\n",
       "      <th>CPU效能等級</th>\n",
       "      <th>Underclocking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>2771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.327929</td>\n",
       "      <td>48.192487</td>\n",
       "      <td>54.220187</td>\n",
       "      <td>573.428495</td>\n",
       "      <td>0.234997</td>\n",
       "      <td>74.767248</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>2699.908807</td>\n",
       "      <td>2339.694106</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>0.892168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.201440</td>\n",
       "      <td>12.652690</td>\n",
       "      <td>11.739885</td>\n",
       "      <td>412.597872</td>\n",
       "      <td>0.236992</td>\n",
       "      <td>14.157427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052317</td>\n",
       "      <td>0.102983</td>\n",
       "      <td>1681.185940</td>\n",
       "      <td>1678.517468</td>\n",
       "      <td>0.550307</td>\n",
       "      <td>0.126315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.601610</td>\n",
       "      <td>16.904762</td>\n",
       "      <td>16.255404</td>\n",
       "      <td>2.806544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.889610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>-0.307900</td>\n",
       "      <td>11.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.790540</td>\n",
       "      <td>38.428571</td>\n",
       "      <td>46.933333</td>\n",
       "      <td>255.300000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>62.382756</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>-0.055830</td>\n",
       "      <td>1299.505295</td>\n",
       "      <td>968.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.452381</td>\n",
       "      <td>48.119048</td>\n",
       "      <td>54.853333</td>\n",
       "      <td>450.200000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>75.595238</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.085901</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>2491.000000</td>\n",
       "      <td>2137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.119048</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>61.511030</td>\n",
       "      <td>808.800000</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>87.209427</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.143479</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>3858.000000</td>\n",
       "      <td>3490.750415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.619048</td>\n",
       "      <td>79.547619</td>\n",
       "      <td>92.866667</td>\n",
       "      <td>2068.043920</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.288882</td>\n",
       "      <td>0.332365</td>\n",
       "      <td>8221.000000</td>\n",
       "      <td>7838.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        手機螢幕溫度(平均)   手機螢幕溫度(最大)   手機背蓋溫度(平均)  平均APP運作指標/小時       充電時間指標  \\\n",
       "count  2771.000000  2771.000000  2771.000000   2771.000000  2771.000000   \n",
       "mean     41.327929    48.192487    54.220187    573.428495     0.234997   \n",
       "std      12.201440    12.652690    11.739885    412.597872     0.236992   \n",
       "min      15.601610    16.904762    16.255404      2.806544     0.000000   \n",
       "25%      31.790540    38.428571    46.933333    255.300000     0.034483   \n",
       "50%      40.452381    48.119048    54.853333    450.200000     0.162500   \n",
       "75%      50.119048    57.642857    61.511030    808.800000     0.382716   \n",
       "max      75.619048    79.547619    92.866667   2068.043920     0.966667   \n",
       "\n",
       "            手機電池電量  CPU跑分階級    手機外殼/包膜指標       外型平均曲率       上網頻率指標  \\\n",
       "count  2771.000000   2771.0  2771.000000  2771.000000  2771.000000   \n",
       "mean     74.767248      3.0     0.102213     0.009980  2699.908807   \n",
       "std      14.157427      0.0     0.052317     0.102983  1681.185940   \n",
       "min      47.889610      3.0     0.016377    -0.307900    11.370000   \n",
       "25%      62.382756      3.0     0.059031    -0.055830  1299.505295   \n",
       "50%      75.595238      3.0     0.085901     0.004436  2491.000000   \n",
       "75%      87.209427      3.0     0.143479     0.069507  3858.000000   \n",
       "max     100.000000      3.0     0.288882     0.332365  8221.000000   \n",
       "\n",
       "            通話頻率指標     新機/二手/老舊       內容容量比率  CPU效能等級  Underclocking  \n",
       "count  2771.000000  2771.000000  2771.000000   2771.0    2771.000000  \n",
       "mean   2339.694106     0.330206     0.892168      1.0       0.443522  \n",
       "std    1678.517468     0.550307     0.126315      0.0       0.496890  \n",
       "min       0.000000     0.000000     0.460998      1.0       0.000000  \n",
       "25%     968.600000     0.000000     0.833479      1.0       0.000000  \n",
       "50%    2137.000000     0.000000     0.946174      1.0       0.000000  \n",
       "75%    3490.750415     1.000000     0.987878      1.0       1.000000  \n",
       "max    7838.000000     3.000000     1.000000      1.0       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  #建構standardization的物件\n",
    "name_list_outlier =['手機螢幕溫度(平均)','手機螢幕溫度(最大)','手機背蓋溫度(平均)',\n",
    "            '平均APP運作指標/小時','充電時間指標','手機電池電量','CPU跑分階級',\n",
    "            '手機外殼/包膜指標','外型平均曲率','上網頻率指標','通話頻率指標','新機/二手/老舊','內容容量比率','CPU效能等級']\n",
    "#name_list_outlier =['手機螢幕溫度(平均)','手機螢幕溫度(最大)','手機背蓋溫度(平均)','平均APP運作指標/小時','上網頻率指標','通話頻率指標','內容容量比率']\n",
    "name_pre_outlier = ['Mobile Screen Temperature (Max)','Mobile Phone Back Cover Temperature (Average)','Average APP Operation Index/Hour','Mobile Phone Battery Level','Content Capacity Ratio']\n",
    "\n",
    "\n",
    "#離群值處理\n",
    "def  outlier_del(data_frame,name_list_outlier):\n",
    "    for i, name in enumerate(name_list_outlier):\n",
    "        print(name)\n",
    "        print(\"Shape Of The Before Ouliers: \", data_frame[name].shape)\n",
    "    \n",
    "        # 计算IQR\n",
    "        Q1 = np.percentile(data_frame[name], 25)\n",
    "        Q3 = np.percentile(data_frame[name], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        n = 2\n",
    "\n",
    "        # 定义离群值范围\n",
    "        lower_bound = Q1 - n * IQR\n",
    "        upper_bound = Q3 + n * IQR\n",
    "\n",
    "        # 过滤离群值\n",
    "        filtered_entries = ((data_frame[name] >= lower_bound) & (data_frame[name] <= upper_bound))\n",
    "        data_frame = data_frame[filtered_entries]\n",
    "    \n",
    "        print(\"Shape Of The After Ouliers: \",data_frame[name].shape)\n",
    "        print('===================================================================================================================')\n",
    "    return data_frame\n",
    "\n",
    "data_frame=outlier_del(data_frame,name_list_outlier)\n",
    "data_frame.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_data = data_frame['Underclocking'].to_numpy()\n",
    "feature_ex = ['手機螢幕溫度(平均)', '手機背蓋溫度(平均)', '充電時間指標', '手機電池電量', 'CPU跑分階級', '上網頻率指標', '通話頻率指標', '內容容量比率']\n",
    "#feature_ex=['手機螢幕溫度(平均)','手機背蓋溫度(平均)','平均APP運作指標/小時','充電時間指標','手機電池電量','手機外殼/包膜指標','通話頻率指標','新機/二手/老舊','CPU效能等級']\n",
    "x_data = data_frame[feature_ex].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1542, 1: 1229})\n",
      "Resampled dataset shape Counter({0: 1277, 1: 1277})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETomek\n",
    "print('Original dataset shape %s' % Counter(y_data))\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "\n",
    "x_data, y_data= smote_tomek.fit_resample(x_data, y_data)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.47142636e+00 -9.83724269e-01 -8.23314387e-01 ...  2.12896528e+00\n",
      "   2.22202980e+00  8.76126718e-01]\n",
      " [-8.86136063e-01 -1.54643002e+00 -9.71200801e-03 ...  2.31006168e-03\n",
      "  -7.11207654e-02  8.82041332e-01]\n",
      " [ 7.38591819e-01 -2.61140172e-01  2.89661356e+00 ...  3.37574156e-01\n",
      "   3.79446744e-01  8.82041332e-01]\n",
      " ...\n",
      " [-6.21727858e-01  2.33853050e+00 -8.28228437e-01 ... -1.36281724e+00\n",
      "  -1.38945695e+00 -2.02544544e-01]\n",
      " [-4.77671296e-01 -1.11193717e+00  1.06222201e+00 ...  7.28725622e-01\n",
      "   6.67671749e-01  1.36370603e-01]\n",
      " [ 6.91370771e-02 -1.57376634e+00  1.08680641e+00 ...  9.23948374e-01\n",
      "   8.79233631e-01  3.71879476e-01]]\n",
      "[0 0 1 ... 1 1 1]\n",
      "[[ 1.47142636e+00 -9.83724269e-01 -8.23314387e-01 ...  2.12896528e+00\n",
      "   2.22202980e+00  8.76126718e-01]\n",
      " [-8.86136063e-01 -1.54643002e+00 -9.71200801e-03 ...  2.31006168e-03\n",
      "  -7.11207654e-02  8.82041332e-01]\n",
      " [ 7.38591819e-01 -2.61140172e-01  2.89661356e+00 ...  3.37574156e-01\n",
      "   3.79446744e-01  8.82041332e-01]\n",
      " ...\n",
      " [-6.21727858e-01  2.33853050e+00 -8.28228437e-01 ... -1.36281724e+00\n",
      "  -1.38945695e+00 -2.02544544e-01]\n",
      " [-4.77671296e-01 -1.11193717e+00  1.06222201e+00 ...  7.28725622e-01\n",
      "   6.67671749e-01  1.36370603e-01]\n",
      " [ 6.91370771e-02 -1.57376634e+00  1.08680641e+00 ...  9.23948374e-01\n",
      "   8.79233631e-01  3.71879476e-01]]\n",
      "[0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "def data_normalized(data):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_normalized = min_max_scaler.fit_transform(data)\n",
    "    return data_normalized\n",
    "def data_standardized(data):\n",
    "    standard_scaler = StandardScaler()\n",
    "    data_standardized = standard_scaler.fit_transform(data)\n",
    "    return data_standardized \n",
    "x_data=data_normalized(x_data)\n",
    "x_data=data_standardized(x_data)\n",
    "print(x_data) \n",
    "print(y_data) \n",
    "print(x_data) \n",
    "print(y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca=PCA(n_components=6)\n",
    "#x_data=pca.fit(x_data).transform(x_data)\n",
    "#np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: (2170, 8)\n",
      "Xtrain type: <class 'numpy.ndarray'>\n",
      "Xtest shape: (384, 8)\n",
      "Xtest type: <class 'numpy.ndarray'>\n",
      "ytrain shape: (2170,)\n",
      "ytrain type: <class 'numpy.ndarray'>\n",
      "ytest shape: (384,)\n",
      "ytest type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 使用 train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(x_data, y_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Xtrain shape:\", Xtrain.shape)\n",
    "print(\"Xtrain type:\", type(Xtrain))\n",
    "print(\"Xtest shape:\", Xtest.shape)\n",
    "print(\"Xtest type:\", type(Xtest))\n",
    "print(\"ytrain shape:\", ytrain.shape)\n",
    "print(\"ytrain type:\", type(ytrain))\n",
    "print(\"ytest shape:\", ytest.shape)\n",
    "print(\"ytest type:\", type(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1088, 1: 1082})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.keras import BalancedBatchGenerator\n",
    "from imblearn.under_sampling import NearMiss\n",
    "#undersampler = RandomUnderSampler(sampling_strategy='auto')\n",
    "print('Original dataset shape %s' % Counter(ytrain))\n",
    "# 创建一个平衡批生成器\n",
    "train_generator = BalancedBatchGenerator(Xtrain, ytrain, sampler=NearMiss(), batch_size=32, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,201</span> (47.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,201\u001b[0m (47.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,201</span> (47.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,201\u001b[0m (47.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "l2_regularizer = tf.keras.regularizers.l2(0.05)\n",
    "input_features = x_data.shape[1]\n",
    "print( x_data.shape[1])\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_features,)),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.001),\n",
    "    tf.keras.layers.Dense(32, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(16, activation='tanh',kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dense(8, activation='tanh', kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4, activation='tanh'),# kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dense(2, activation='tanh'), #kernel_regularizer=l2_regularizer),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),     \n",
    "])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.6996 - loss: 0.5915 - learning_rate: 0.0100\n",
      "Epoch 2/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7192 - loss: 0.5798 - learning_rate: 0.0100\n",
      "Epoch 3/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7021 - loss: 0.5861 - learning_rate: 0.0100\n",
      "Epoch 4/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6804 - loss: 0.6114 - learning_rate: 0.0100\n",
      "Epoch 5/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6924 - loss: 0.5982 - learning_rate: 0.0100\n",
      "Epoch 6/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7173 - loss: 0.5900 - learning_rate: 0.0100\n",
      "Epoch 7/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7099 - loss: 0.5842 - learning_rate: 0.0100\n",
      "Epoch 8/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7174 - loss: 0.5860 - learning_rate: 0.0100\n",
      "Epoch 9/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7065 - loss: 0.5929 - learning_rate: 0.0100\n",
      "Epoch 10/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7203 - loss: 0.5847 - learning_rate: 0.0100\n",
      "Epoch 11/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6837 - loss: 0.6018 - learning_rate: 0.0100\n",
      "Epoch 12/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7065 - loss: 0.5917 - learning_rate: 0.0100\n",
      "Epoch 13/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6896 - loss: 0.5940 - learning_rate: 0.0100\n",
      "Epoch 14/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7000 - loss: 0.5950 - learning_rate: 0.0100\n",
      "Epoch 15/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7167 - loss: 0.5807 - learning_rate: 0.0100\n",
      "Epoch 16/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6922 - loss: 0.5947 - learning_rate: 0.0099\n",
      "Epoch 17/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7018 - loss: 0.5931 - learning_rate: 0.0099\n",
      "Epoch 18/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.6765 - loss: 0.6167 - learning_rate: 0.0099\n",
      "Epoch 19/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7033 - loss: 0.5933 - learning_rate: 0.0099\n",
      "Epoch 20/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7092 - loss: 0.5982 - learning_rate: 0.0099\n",
      "Epoch 21/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.6936 - loss: 0.6000 - learning_rate: 0.0099\n",
      "Epoch 22/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7115 - loss: 0.5978 - learning_rate: 0.0099\n",
      "Epoch 23/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6817 - loss: 0.6052 - learning_rate: 0.0099\n",
      "Epoch 24/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6918 - loss: 0.5931 - learning_rate: 0.0099\n",
      "Epoch 25/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6925 - loss: 0.5901 - learning_rate: 0.0099\n",
      "Epoch 26/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7129 - loss: 0.5850 - learning_rate: 0.0098\n",
      "Epoch 27/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6955 - loss: 0.5966 - learning_rate: 0.0098\n",
      "Epoch 28/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6931 - loss: 0.6014 - learning_rate: 0.0098\n",
      "Epoch 29/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.6877 - loss: 0.6098 - learning_rate: 0.0098\n",
      "Epoch 30/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7032 - loss: 0.5872 - learning_rate: 0.0098\n",
      "Epoch 31/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6898 - loss: 0.5970 - learning_rate: 0.0098\n",
      "Epoch 32/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.6957 - loss: 0.5977 - learning_rate: 0.0098\n",
      "Epoch 33/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6977 - loss: 0.5927 - learning_rate: 0.0098\n",
      "Epoch 34/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7097 - loss: 0.5940 - learning_rate: 0.0098\n",
      "Epoch 35/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.6814 - loss: 0.5976 - learning_rate: 0.0098\n",
      "Epoch 36/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6907 - loss: 0.6053 - learning_rate: 0.0097\n",
      "Epoch 37/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7091 - loss: 0.5827 - learning_rate: 0.0097\n",
      "Epoch 38/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6873 - loss: 0.6092 - learning_rate: 0.0097\n",
      "Epoch 39/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6918 - loss: 0.5988 - learning_rate: 0.0097\n",
      "Epoch 40/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6940 - loss: 0.6100 - learning_rate: 0.0097\n",
      "Epoch 41/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6960 - loss: 0.5894 - learning_rate: 0.0097\n",
      "Epoch 42/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6983 - loss: 0.6022 - learning_rate: 0.0097\n",
      "Epoch 43/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7048 - loss: 0.5913 - learning_rate: 0.0097\n",
      "Epoch 44/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6807 - loss: 0.6113 - learning_rate: 0.0097\n",
      "Epoch 45/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7121 - loss: 0.5785 - learning_rate: 0.0097\n",
      "Epoch 46/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7187 - loss: 0.5818 - learning_rate: 0.0096\n",
      "Epoch 47/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7156 - loss: 0.5728 - learning_rate: 0.0096\n",
      "Epoch 48/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6931 - loss: 0.5861 - learning_rate: 0.0096\n",
      "Epoch 49/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7073 - loss: 0.5812 - learning_rate: 0.0096\n",
      "Epoch 50/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6754 - loss: 0.6035 - learning_rate: 0.0096\n",
      "Epoch 51/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7117 - loss: 0.5900 - learning_rate: 0.0096\n",
      "Epoch 52/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7054 - loss: 0.5879 - learning_rate: 0.0096\n",
      "Epoch 53/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7087 - loss: 0.5914 - learning_rate: 0.0096\n",
      "Epoch 54/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7063 - loss: 0.5913 - learning_rate: 0.0096\n",
      "Epoch 55/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6904 - loss: 0.5899 - learning_rate: 0.0096\n",
      "Epoch 56/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6998 - loss: 0.5838 - learning_rate: 0.0096\n",
      "Epoch 57/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7142 - loss: 0.5795 - learning_rate: 0.0095\n",
      "Epoch 58/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7131 - loss: 0.5806 - learning_rate: 0.0095\n",
      "Epoch 59/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7170 - loss: 0.5814 - learning_rate: 0.0095\n",
      "Epoch 60/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6994 - loss: 0.5809 - learning_rate: 0.0095\n",
      "Epoch 61/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7108 - loss: 0.5907 - learning_rate: 0.0095\n",
      "Epoch 62/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7076 - loss: 0.5760 - learning_rate: 0.0095\n",
      "Epoch 63/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7176 - loss: 0.5805 - learning_rate: 0.0095\n",
      "Epoch 64/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6774 - loss: 0.6086 - learning_rate: 0.0095\n",
      "Epoch 65/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7009 - loss: 0.5925 - learning_rate: 0.0095\n",
      "Epoch 66/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7100 - loss: 0.5892 - learning_rate: 0.0095\n",
      "Epoch 67/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7168 - loss: 0.5842 - learning_rate: 0.0094\n",
      "Epoch 68/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6975 - loss: 0.5863 - learning_rate: 0.0094\n",
      "Epoch 69/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7090 - loss: 0.5819 - learning_rate: 0.0094\n",
      "Epoch 70/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6982 - loss: 0.5852 - learning_rate: 0.0094\n",
      "Epoch 71/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7330 - loss: 0.5737 - learning_rate: 0.0094\n",
      "Epoch 72/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7030 - loss: 0.5781 - learning_rate: 0.0094\n",
      "Epoch 73/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6933 - loss: 0.5820 - learning_rate: 0.0094\n",
      "Epoch 74/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7048 - loss: 0.5861 - learning_rate: 0.0094\n",
      "Epoch 75/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7082 - loss: 0.5850 - learning_rate: 0.0094\n",
      "Epoch 76/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.6981 - loss: 0.5871 - learning_rate: 0.0094\n",
      "Epoch 77/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7162 - loss: 0.5745 - learning_rate: 0.0094\n",
      "Epoch 78/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7075 - loss: 0.5773 - learning_rate: 0.0093\n",
      "Epoch 79/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6849 - loss: 0.6073 - learning_rate: 0.0093\n",
      "Epoch 80/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7099 - loss: 0.5795 - learning_rate: 0.0093\n",
      "Epoch 81/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.6893 - loss: 0.5999 - learning_rate: 0.0093\n",
      "Epoch 82/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7039 - loss: 0.5966 - learning_rate: 0.0093\n",
      "Epoch 83/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6926 - loss: 0.5931 - learning_rate: 0.0093\n",
      "Epoch 84/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7127 - loss: 0.5791 - learning_rate: 0.0093\n",
      "Epoch 85/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.6979 - loss: 0.5837 - learning_rate: 0.0093\n",
      "Epoch 86/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7117 - loss: 0.5725 - learning_rate: 0.0093\n",
      "Epoch 87/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6822 - loss: 0.5967 - learning_rate: 0.0093\n",
      "Epoch 88/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.6917 - loss: 0.5982 - learning_rate: 0.0092\n",
      "Epoch 89/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7113 - loss: 0.5714 - learning_rate: 0.0092\n",
      "Epoch 90/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7010 - loss: 0.5885 - learning_rate: 0.0092\n",
      "Epoch 91/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7260 - loss: 0.5724 - learning_rate: 0.0092\n",
      "Epoch 92/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7049 - loss: 0.5860 - learning_rate: 0.0092\n",
      "Epoch 93/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7113 - loss: 0.5701 - learning_rate: 0.0092\n",
      "Epoch 94/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6879 - loss: 0.6035 - learning_rate: 0.0092\n",
      "Epoch 95/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6979 - loss: 0.5845 - learning_rate: 0.0092\n",
      "Epoch 96/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7074 - loss: 0.5726 - learning_rate: 0.0092\n",
      "Epoch 97/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7332 - loss: 0.5570 - learning_rate: 0.0092\n",
      "Epoch 98/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6947 - loss: 0.5876 - learning_rate: 0.0092\n",
      "Epoch 99/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.6920 - loss: 0.5929 - learning_rate: 0.0091\n",
      "Epoch 100/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7035 - loss: 0.5940 - learning_rate: 0.0091\n",
      "Epoch 101/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.6987 - loss: 0.5851 - learning_rate: 0.0091\n",
      "Epoch 102/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7115 - loss: 0.5768 - learning_rate: 0.0091\n",
      "Epoch 103/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7067 - loss: 0.5870 - learning_rate: 0.0091\n",
      "Epoch 104/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6899 - loss: 0.5853 - learning_rate: 0.0091\n",
      "Epoch 105/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.6981 - loss: 0.5949 - learning_rate: 0.0091\n",
      "Epoch 106/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7110 - loss: 0.5707 - learning_rate: 0.0091\n",
      "Epoch 107/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7017 - loss: 0.5768 - learning_rate: 0.0091\n",
      "Epoch 108/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7226 - loss: 0.5752 - learning_rate: 0.0091\n",
      "Epoch 109/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6943 - loss: 0.5917 - learning_rate: 0.0091\n",
      "Epoch 110/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6961 - loss: 0.5886 - learning_rate: 0.0090\n",
      "Epoch 111/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7027 - loss: 0.5878 - learning_rate: 0.0090\n",
      "Epoch 112/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6984 - loss: 0.5917 - learning_rate: 0.0090\n",
      "Epoch 113/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7152 - loss: 0.5791 - learning_rate: 0.0090\n",
      "Epoch 114/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7141 - loss: 0.5812 - learning_rate: 0.0090\n",
      "Epoch 115/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7228 - loss: 0.5777 - learning_rate: 0.0090\n",
      "Epoch 116/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6926 - loss: 0.5873 - learning_rate: 0.0090\n",
      "Epoch 117/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6976 - loss: 0.5847 - learning_rate: 0.0090\n",
      "Epoch 118/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7277 - loss: 0.5708 - learning_rate: 0.0090\n",
      "Epoch 119/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7040 - loss: 0.5924 - learning_rate: 0.0090\n",
      "Epoch 120/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6862 - loss: 0.5914 - learning_rate: 0.0090\n",
      "Epoch 121/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7070 - loss: 0.5734 - learning_rate: 0.0089\n",
      "Epoch 122/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7023 - loss: 0.5939 - learning_rate: 0.0089\n",
      "Epoch 123/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7042 - loss: 0.5911 - learning_rate: 0.0089\n",
      "Epoch 124/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6938 - loss: 0.5910 - learning_rate: 0.0089\n",
      "Epoch 125/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7156 - loss: 0.5671 - learning_rate: 0.0089\n",
      "Epoch 126/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6901 - loss: 0.5803 - learning_rate: 0.0089\n",
      "Epoch 127/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7057 - loss: 0.5851 - learning_rate: 0.0089\n",
      "Epoch 128/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7100 - loss: 0.5838 - learning_rate: 0.0089\n",
      "Epoch 129/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6958 - loss: 0.5912 - learning_rate: 0.0089\n",
      "Epoch 130/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6920 - loss: 0.5931 - learning_rate: 0.0089\n",
      "Epoch 131/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6995 - loss: 0.5829 - learning_rate: 0.0089\n",
      "Epoch 132/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7046 - loss: 0.5810 - learning_rate: 0.0089\n",
      "Epoch 133/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7235 - loss: 0.5751 - learning_rate: 0.0088\n",
      "Epoch 134/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6946 - loss: 0.5967 - learning_rate: 0.0088\n",
      "Epoch 135/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.6984 - loss: 0.5837 - learning_rate: 0.0088\n",
      "Epoch 136/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7209 - loss: 0.5659 - learning_rate: 0.0088\n",
      "Epoch 137/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7145 - loss: 0.5774 - learning_rate: 0.0088\n",
      "Epoch 138/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7160 - loss: 0.5677 - learning_rate: 0.0088\n",
      "Epoch 139/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7099 - loss: 0.5828 - learning_rate: 0.0088\n",
      "Epoch 140/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7012 - loss: 0.5827 - learning_rate: 0.0088\n",
      "Epoch 141/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7160 - loss: 0.5784 - learning_rate: 0.0088\n",
      "Epoch 142/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7057 - loss: 0.5720 - learning_rate: 0.0088\n",
      "Epoch 143/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6905 - loss: 0.5797 - learning_rate: 0.0088\n",
      "Epoch 144/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7084 - loss: 0.5627 - learning_rate: 0.0087\n",
      "Epoch 145/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7237 - loss: 0.5648 - learning_rate: 0.0087\n",
      "Epoch 146/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7018 - loss: 0.5906 - learning_rate: 0.0087\n",
      "Epoch 147/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7052 - loss: 0.5844 - learning_rate: 0.0087\n",
      "Epoch 148/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7166 - loss: 0.5719 - learning_rate: 0.0087\n",
      "Epoch 149/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7002 - loss: 0.5801 - learning_rate: 0.0087\n",
      "Epoch 150/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7019 - loss: 0.5830 - learning_rate: 0.0087\n",
      "Epoch 151/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7013 - loss: 0.5818 - learning_rate: 0.0087\n",
      "Epoch 152/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7217 - loss: 0.5690 - learning_rate: 0.0087\n",
      "Epoch 153/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6997 - loss: 0.5896 - learning_rate: 0.0087\n",
      "Epoch 154/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7171 - loss: 0.5702 - learning_rate: 0.0087\n",
      "Epoch 155/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7042 - loss: 0.5818 - learning_rate: 0.0087\n",
      "Epoch 156/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7027 - loss: 0.5702 - learning_rate: 0.0086\n",
      "Epoch 157/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.6995 - loss: 0.5906 - learning_rate: 0.0086\n",
      "Epoch 158/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6995 - loss: 0.5895 - learning_rate: 0.0086\n",
      "Epoch 159/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7039 - loss: 0.5825 - learning_rate: 0.0086\n",
      "Epoch 160/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7045 - loss: 0.5920 - learning_rate: 0.0086\n",
      "Epoch 161/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7007 - loss: 0.5930 - learning_rate: 0.0086\n",
      "Epoch 162/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7142 - loss: 0.5735 - learning_rate: 0.0086\n",
      "Epoch 163/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7153 - loss: 0.5733 - learning_rate: 0.0086\n",
      "Epoch 164/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7092 - loss: 0.5764 - learning_rate: 0.0086\n",
      "Epoch 165/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7140 - loss: 0.5764 - learning_rate: 0.0086\n",
      "Epoch 166/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6995 - loss: 0.5846 - learning_rate: 0.0086\n",
      "Epoch 167/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7116 - loss: 0.5785 - learning_rate: 0.0085\n",
      "Epoch 168/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6972 - loss: 0.5899 - learning_rate: 0.0085\n",
      "Epoch 169/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7214 - loss: 0.5643 - learning_rate: 0.0085\n",
      "Epoch 170/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7184 - loss: 0.5718 - learning_rate: 0.0085\n",
      "Epoch 171/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.7210 - loss: 0.5649 - learning_rate: 0.0085\n",
      "Epoch 172/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7115 - loss: 0.5704 - learning_rate: 0.0085\n",
      "Epoch 173/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7096 - loss: 0.5820 - learning_rate: 0.0085\n",
      "Epoch 174/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7137 - loss: 0.5782 - learning_rate: 0.0085\n",
      "Epoch 175/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7123 - loss: 0.5779 - learning_rate: 0.0085\n",
      "Epoch 176/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.6943 - loss: 0.5941 - learning_rate: 0.0085\n",
      "Epoch 177/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7257 - loss: 0.5595 - learning_rate: 0.0085\n",
      "Epoch 178/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7143 - loss: 0.5634 - learning_rate: 0.0085\n",
      "Epoch 179/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7135 - loss: 0.5693 - learning_rate: 0.0084\n",
      "Epoch 180/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7175 - loss: 0.5648 - learning_rate: 0.0084\n",
      "Epoch 181/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7208 - loss: 0.5645 - learning_rate: 0.0084\n",
      "Epoch 182/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7345 - loss: 0.5564 - learning_rate: 0.0084\n",
      "Epoch 183/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7146 - loss: 0.5777 - learning_rate: 0.0084\n",
      "Epoch 184/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7108 - loss: 0.5805 - learning_rate: 0.0084\n",
      "Epoch 185/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6989 - loss: 0.5837 - learning_rate: 0.0084\n",
      "Epoch 186/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.6984 - loss: 0.5841 - learning_rate: 0.0084\n",
      "Epoch 187/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7057 - loss: 0.5768 - learning_rate: 0.0084\n",
      "Epoch 188/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7117 - loss: 0.5759 - learning_rate: 0.0084\n",
      "Epoch 189/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7264 - loss: 0.5693 - learning_rate: 0.0084\n",
      "Epoch 190/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7249 - loss: 0.5659 - learning_rate: 0.0084\n",
      "Epoch 191/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7186 - loss: 0.5769 - learning_rate: 0.0083\n",
      "Epoch 192/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7177 - loss: 0.5690 - learning_rate: 0.0083\n",
      "Epoch 193/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7066 - loss: 0.5881 - learning_rate: 0.0083\n",
      "Epoch 194/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6906 - loss: 0.5853 - learning_rate: 0.0083\n",
      "Epoch 195/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7214 - loss: 0.5635 - learning_rate: 0.0083\n",
      "Epoch 196/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.6905 - loss: 0.5965 - learning_rate: 0.0083\n",
      "Epoch 197/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7183 - loss: 0.5678 - learning_rate: 0.0083\n",
      "Epoch 198/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.7136 - loss: 0.5811 - learning_rate: 0.0083\n",
      "Epoch 199/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.7131 - loss: 0.5746 - learning_rate: 0.0083\n",
      "Epoch 200/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7115 - loss: 0.5660 - learning_rate: 0.0083\n",
      "Epoch 201/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6869 - loss: 0.5956 - learning_rate: 0.0083\n",
      "Epoch 202/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7295 - loss: 0.5699 - learning_rate: 0.0083\n",
      "Epoch 203/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7062 - loss: 0.5709 - learning_rate: 0.0082\n",
      "Epoch 204/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.6896 - loss: 0.5928 - learning_rate: 0.0082\n",
      "Epoch 205/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7036 - loss: 0.5858 - learning_rate: 0.0082\n",
      "Epoch 206/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7165 - loss: 0.5681 - learning_rate: 0.0082\n",
      "Epoch 207/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.6978 - loss: 0.5826 - learning_rate: 0.0082\n",
      "Epoch 208/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7093 - loss: 0.5836 - learning_rate: 0.0082\n",
      "Epoch 209/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7119 - loss: 0.5776 - learning_rate: 0.0082\n",
      "Epoch 210/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7095 - loss: 0.5790 - learning_rate: 0.0082\n",
      "Epoch 211/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6940 - loss: 0.5900 - learning_rate: 0.0082\n",
      "Epoch 212/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7343 - loss: 0.5526 - learning_rate: 0.0082\n",
      "Epoch 213/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7256 - loss: 0.5752 - learning_rate: 0.0082\n",
      "Epoch 214/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7201 - loss: 0.5704 - learning_rate: 0.0082\n",
      "Epoch 215/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7230 - loss: 0.5600 - learning_rate: 0.0081\n",
      "Epoch 216/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7147 - loss: 0.5730 - learning_rate: 0.0081\n",
      "Epoch 217/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7029 - loss: 0.5796 - learning_rate: 0.0081\n",
      "Epoch 218/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7119 - loss: 0.5638 - learning_rate: 0.0081\n",
      "Epoch 219/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7189 - loss: 0.5668 - learning_rate: 0.0081\n",
      "Epoch 220/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7070 - loss: 0.5732 - learning_rate: 0.0081\n",
      "Epoch 221/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.7145 - loss: 0.5733 - learning_rate: 0.0081\n",
      "Epoch 222/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7156 - loss: 0.5741 - learning_rate: 0.0081\n",
      "Epoch 223/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.7177 - loss: 0.5552 - learning_rate: 0.0081\n",
      "Epoch 224/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7220 - loss: 0.5649 - learning_rate: 0.0081\n",
      "Epoch 225/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.7292 - loss: 0.5576 - learning_rate: 0.0081\n",
      "Epoch 226/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7140 - loss: 0.5781 - learning_rate: 0.0081\n",
      "Epoch 227/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.6914 - loss: 0.5836 - learning_rate: 0.0080\n",
      "Epoch 228/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7184 - loss: 0.5753 - learning_rate: 0.0080\n",
      "Epoch 229/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7105 - loss: 0.5709 - learning_rate: 0.0080\n",
      "Epoch 230/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7155 - loss: 0.5596 - learning_rate: 0.0080\n",
      "Epoch 231/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7035 - loss: 0.5778 - learning_rate: 0.0080\n",
      "Epoch 232/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.7296 - loss: 0.5634 - learning_rate: 0.0080\n",
      "Epoch 233/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7250 - loss: 0.5602 - learning_rate: 0.0080\n",
      "Epoch 234/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7134 - loss: 0.5669 - learning_rate: 0.0080\n",
      "Epoch 235/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7252 - loss: 0.5703 - learning_rate: 0.0080\n",
      "Epoch 236/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7237 - loss: 0.5505 - learning_rate: 0.0080\n",
      "Epoch 237/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6969 - loss: 0.5687 - learning_rate: 0.0080\n",
      "Epoch 238/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7254 - loss: 0.5547 - learning_rate: 0.0080\n",
      "Epoch 239/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7196 - loss: 0.5719 - learning_rate: 0.0080\n",
      "Epoch 240/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7126 - loss: 0.5744 - learning_rate: 0.0079\n",
      "Epoch 241/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7244 - loss: 0.5574 - learning_rate: 0.0079\n",
      "Epoch 242/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7205 - loss: 0.5604 - learning_rate: 0.0079\n",
      "Epoch 243/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7175 - loss: 0.5668 - learning_rate: 0.0079\n",
      "Epoch 244/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.7046 - loss: 0.5758 - learning_rate: 0.0079\n",
      "Epoch 245/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7100 - loss: 0.5678 - learning_rate: 0.0079\n",
      "Epoch 246/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7141 - loss: 0.5647 - learning_rate: 0.0079\n",
      "Epoch 247/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7014 - loss: 0.5801 - learning_rate: 0.0079\n",
      "Epoch 248/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7274 - loss: 0.5714 - learning_rate: 0.0079\n",
      "Epoch 249/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7265 - loss: 0.5533 - learning_rate: 0.0079\n",
      "Epoch 250/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7191 - loss: 0.5666 - learning_rate: 0.0079\n",
      "Epoch 251/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7119 - loss: 0.5784 - learning_rate: 0.0079\n",
      "Epoch 252/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7049 - loss: 0.5811 - learning_rate: 0.0079\n",
      "Epoch 253/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7065 - loss: 0.5753 - learning_rate: 0.0078\n",
      "Epoch 254/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7063 - loss: 0.5759 - learning_rate: 0.0078\n",
      "Epoch 255/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7281 - loss: 0.5503 - learning_rate: 0.0078\n",
      "Epoch 256/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7254 - loss: 0.5597 - learning_rate: 0.0078\n",
      "Epoch 257/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7167 - loss: 0.5704 - learning_rate: 0.0078\n",
      "Epoch 258/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7211 - loss: 0.5661 - learning_rate: 0.0078\n",
      "Epoch 259/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7272 - loss: 0.5583 - learning_rate: 0.0078\n",
      "Epoch 260/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7202 - loss: 0.5734 - learning_rate: 0.0078\n",
      "Epoch 261/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7152 - loss: 0.5716 - learning_rate: 0.0078\n",
      "Epoch 262/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.6983 - loss: 0.5877 - learning_rate: 0.0078\n",
      "Epoch 263/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.6987 - loss: 0.5861 - learning_rate: 0.0078\n",
      "Epoch 264/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7324 - loss: 0.5675 - learning_rate: 0.0078\n",
      "Epoch 265/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7340 - loss: 0.5471 - learning_rate: 0.0077\n",
      "Epoch 266/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7284 - loss: 0.5530 - learning_rate: 0.0077\n",
      "Epoch 267/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7215 - loss: 0.5663 - learning_rate: 0.0077\n",
      "Epoch 268/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7171 - loss: 0.5604 - learning_rate: 0.0077\n",
      "Epoch 269/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7292 - loss: 0.5631 - learning_rate: 0.0077\n",
      "Epoch 270/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7123 - loss: 0.5784 - learning_rate: 0.0077\n",
      "Epoch 271/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7387 - loss: 0.5448 - learning_rate: 0.0077\n",
      "Epoch 272/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7218 - loss: 0.5594 - learning_rate: 0.0077\n",
      "Epoch 273/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7186 - loss: 0.5627 - learning_rate: 0.0077\n",
      "Epoch 274/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7451 - loss: 0.5453 - learning_rate: 0.0077\n",
      "Epoch 275/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7092 - loss: 0.5697 - learning_rate: 0.0077\n",
      "Epoch 276/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7155 - loss: 0.5804 - learning_rate: 0.0077\n",
      "Epoch 277/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7281 - loss: 0.5514 - learning_rate: 0.0077\n",
      "Epoch 278/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7266 - loss: 0.5561 - learning_rate: 0.0076\n",
      "Epoch 279/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7260 - loss: 0.5618 - learning_rate: 0.0076\n",
      "Epoch 280/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7154 - loss: 0.5659 - learning_rate: 0.0076\n",
      "Epoch 281/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7143 - loss: 0.5677 - learning_rate: 0.0076\n",
      "Epoch 282/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7376 - loss: 0.5463 - learning_rate: 0.0076\n",
      "Epoch 283/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7159 - loss: 0.5636 - learning_rate: 0.0076\n",
      "Epoch 284/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7312 - loss: 0.5500 - learning_rate: 0.0076\n",
      "Epoch 285/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7037 - loss: 0.5800 - learning_rate: 0.0076\n",
      "Epoch 286/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7151 - loss: 0.5713 - learning_rate: 0.0076\n",
      "Epoch 287/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7180 - loss: 0.5633 - learning_rate: 0.0076\n",
      "Epoch 288/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7392 - loss: 0.5498 - learning_rate: 0.0076\n",
      "Epoch 289/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7132 - loss: 0.5646 - learning_rate: 0.0076\n",
      "Epoch 290/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7092 - loss: 0.5643 - learning_rate: 0.0076\n",
      "Epoch 291/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7246 - loss: 0.5580 - learning_rate: 0.0076\n",
      "Epoch 292/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7239 - loss: 0.5615 - learning_rate: 0.0075\n",
      "Epoch 293/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7259 - loss: 0.5634 - learning_rate: 0.0075\n",
      "Epoch 294/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7164 - loss: 0.5550 - learning_rate: 0.0075\n",
      "Epoch 295/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7232 - loss: 0.5520 - learning_rate: 0.0075\n",
      "Epoch 296/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7332 - loss: 0.5410 - learning_rate: 0.0075\n",
      "Epoch 297/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7147 - loss: 0.5849 - learning_rate: 0.0075\n",
      "Epoch 298/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7195 - loss: 0.5631 - learning_rate: 0.0075\n",
      "Epoch 299/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7131 - loss: 0.5802 - learning_rate: 0.0075\n",
      "Epoch 300/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7196 - loss: 0.5636 - learning_rate: 0.0075\n",
      "Epoch 301/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7169 - loss: 0.5746 - learning_rate: 0.0075\n",
      "Epoch 302/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7211 - loss: 0.5540 - learning_rate: 0.0075\n",
      "Epoch 303/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7343 - loss: 0.5516 - learning_rate: 0.0075\n",
      "Epoch 304/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7247 - loss: 0.5590 - learning_rate: 0.0075\n",
      "Epoch 305/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7341 - loss: 0.5483 - learning_rate: 0.0074\n",
      "Epoch 306/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7190 - loss: 0.5624 - learning_rate: 0.0074\n",
      "Epoch 307/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7218 - loss: 0.5679 - learning_rate: 0.0074\n",
      "Epoch 308/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7214 - loss: 0.5601 - learning_rate: 0.0074\n",
      "Epoch 309/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7332 - loss: 0.5546 - learning_rate: 0.0074\n",
      "Epoch 310/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7157 - loss: 0.5721 - learning_rate: 0.0074\n",
      "Epoch 311/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7180 - loss: 0.5686 - learning_rate: 0.0074\n",
      "Epoch 312/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7246 - loss: 0.5647 - learning_rate: 0.0074\n",
      "Epoch 313/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7484 - loss: 0.5405 - learning_rate: 0.0074\n",
      "Epoch 314/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7170 - loss: 0.5584 - learning_rate: 0.0074\n",
      "Epoch 315/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7319 - loss: 0.5524 - learning_rate: 0.0074\n",
      "Epoch 316/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7055 - loss: 0.5801 - learning_rate: 0.0074\n",
      "Epoch 317/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7247 - loss: 0.5546 - learning_rate: 0.0074\n",
      "Epoch 318/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.7089 - loss: 0.5737 - learning_rate: 0.0073\n",
      "Epoch 319/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.7250 - loss: 0.5613 - learning_rate: 0.0073\n",
      "Epoch 320/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7300 - loss: 0.5512 - learning_rate: 0.0073\n",
      "Epoch 321/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7241 - loss: 0.5683 - learning_rate: 0.0073\n",
      "Epoch 322/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7096 - loss: 0.5666 - learning_rate: 0.0073\n",
      "Epoch 323/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7289 - loss: 0.5580 - learning_rate: 0.0073\n",
      "Epoch 324/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7172 - loss: 0.5724 - learning_rate: 0.0073\n",
      "Epoch 325/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7273 - loss: 0.5581 - learning_rate: 0.0073\n",
      "Epoch 326/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7242 - loss: 0.5701 - learning_rate: 0.0073\n",
      "Epoch 327/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7180 - loss: 0.5626 - learning_rate: 0.0073\n",
      "Epoch 328/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7219 - loss: 0.5631 - learning_rate: 0.0073\n",
      "Epoch 329/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7163 - loss: 0.5593 - learning_rate: 0.0073\n",
      "Epoch 330/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7182 - loss: 0.5705 - learning_rate: 0.0073\n",
      "Epoch 331/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7437 - loss: 0.5509 - learning_rate: 0.0073\n",
      "Epoch 332/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7282 - loss: 0.5489 - learning_rate: 0.0072\n",
      "Epoch 333/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7073 - loss: 0.5733 - learning_rate: 0.0072\n",
      "Epoch 334/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7159 - loss: 0.5701 - learning_rate: 0.0072\n",
      "Epoch 335/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.6959 - loss: 0.5712 - learning_rate: 0.0072\n",
      "Epoch 336/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7370 - loss: 0.5549 - learning_rate: 0.0072\n",
      "Epoch 337/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7206 - loss: 0.5635 - learning_rate: 0.0072\n",
      "Epoch 338/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7226 - loss: 0.5637 - learning_rate: 0.0072\n",
      "Epoch 339/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7129 - loss: 0.5797 - learning_rate: 0.0072\n",
      "Epoch 340/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7391 - loss: 0.5632 - learning_rate: 0.0072\n",
      "Epoch 341/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7361 - loss: 0.5592 - learning_rate: 0.0072\n",
      "Epoch 342/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7257 - loss: 0.5618 - learning_rate: 0.0072\n",
      "Epoch 343/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7320 - loss: 0.5510 - learning_rate: 0.0072\n",
      "Epoch 344/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7207 - loss: 0.5597 - learning_rate: 0.0072\n",
      "Epoch 345/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7121 - loss: 0.5681 - learning_rate: 0.0072\n",
      "Epoch 346/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7403 - loss: 0.5547 - learning_rate: 0.0071\n",
      "Epoch 347/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7232 - loss: 0.5568 - learning_rate: 0.0071\n",
      "Epoch 348/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7348 - loss: 0.5556 - learning_rate: 0.0071\n",
      "Epoch 349/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7302 - loss: 0.5533 - learning_rate: 0.0071\n",
      "Epoch 350/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7317 - loss: 0.5531 - learning_rate: 0.0071\n",
      "Epoch 351/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7104 - loss: 0.5659 - learning_rate: 0.0071\n",
      "Epoch 352/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7227 - loss: 0.5754 - learning_rate: 0.0071\n",
      "Epoch 353/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7164 - loss: 0.5676 - learning_rate: 0.0071\n",
      "Epoch 354/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7205 - loss: 0.5568 - learning_rate: 0.0071\n",
      "Epoch 355/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7416 - loss: 0.5398 - learning_rate: 0.0071\n",
      "Epoch 356/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7360 - loss: 0.5550 - learning_rate: 0.0071\n",
      "Epoch 357/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7200 - loss: 0.5624 - learning_rate: 0.0071\n",
      "Epoch 358/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7303 - loss: 0.5520 - learning_rate: 0.0071\n",
      "Epoch 359/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7322 - loss: 0.5475 - learning_rate: 0.0071\n",
      "Epoch 360/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7188 - loss: 0.5673 - learning_rate: 0.0070\n",
      "Epoch 361/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7153 - loss: 0.5701 - learning_rate: 0.0070\n",
      "Epoch 362/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.7450 - loss: 0.5354 - learning_rate: 0.0070\n",
      "Epoch 363/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7333 - loss: 0.5605 - learning_rate: 0.0070\n",
      "Epoch 364/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7162 - loss: 0.5670 - learning_rate: 0.0070\n",
      "Epoch 365/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7423 - loss: 0.5418 - learning_rate: 0.0070\n",
      "Epoch 366/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7295 - loss: 0.5550 - learning_rate: 0.0070\n",
      "Epoch 367/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7281 - loss: 0.5628 - learning_rate: 0.0070\n",
      "Epoch 368/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7336 - loss: 0.5502 - learning_rate: 0.0070\n",
      "Epoch 369/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7283 - loss: 0.5604 - learning_rate: 0.0070\n",
      "Epoch 370/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7184 - loss: 0.5570 - learning_rate: 0.0070\n",
      "Epoch 371/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7486 - loss: 0.5489 - learning_rate: 0.0070\n",
      "Epoch 372/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7224 - loss: 0.5677 - learning_rate: 0.0070\n",
      "Epoch 373/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7307 - loss: 0.5506 - learning_rate: 0.0070\n",
      "Epoch 374/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7182 - loss: 0.5594 - learning_rate: 0.0069\n",
      "Epoch 375/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7405 - loss: 0.5547 - learning_rate: 0.0069\n",
      "Epoch 376/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7434 - loss: 0.5417 - learning_rate: 0.0069\n",
      "Epoch 377/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7246 - loss: 0.5424 - learning_rate: 0.0069\n",
      "Epoch 378/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7388 - loss: 0.5513 - learning_rate: 0.0069\n",
      "Epoch 379/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7215 - loss: 0.5618 - learning_rate: 0.0069\n",
      "Epoch 380/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7411 - loss: 0.5358 - learning_rate: 0.0069\n",
      "Epoch 381/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7445 - loss: 0.5414 - learning_rate: 0.0069\n",
      "Epoch 382/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7264 - loss: 0.5618 - learning_rate: 0.0069\n",
      "Epoch 383/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7506 - loss: 0.5393 - learning_rate: 0.0069\n",
      "Epoch 384/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7195 - loss: 0.5563 - learning_rate: 0.0069\n",
      "Epoch 385/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7302 - loss: 0.5642 - learning_rate: 0.0069\n",
      "Epoch 386/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7151 - loss: 0.5812 - learning_rate: 0.0069\n",
      "Epoch 387/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7405 - loss: 0.5470 - learning_rate: 0.0069\n",
      "Epoch 388/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7139 - loss: 0.5549 - learning_rate: 0.0069\n",
      "Epoch 389/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7200 - loss: 0.5657 - learning_rate: 0.0068\n",
      "Epoch 390/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7424 - loss: 0.5499 - learning_rate: 0.0068\n",
      "Epoch 391/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7162 - loss: 0.5698 - learning_rate: 0.0068\n",
      "Epoch 392/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7268 - loss: 0.5547 - learning_rate: 0.0068\n",
      "Epoch 393/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7313 - loss: 0.5457 - learning_rate: 0.0068\n",
      "Epoch 394/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7342 - loss: 0.5491 - learning_rate: 0.0068\n",
      "Epoch 395/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7281 - loss: 0.5642 - learning_rate: 0.0068\n",
      "Epoch 396/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7210 - loss: 0.5774 - learning_rate: 0.0068\n",
      "Epoch 397/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7204 - loss: 0.5635 - learning_rate: 0.0068\n",
      "Epoch 398/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7110 - loss: 0.5667 - learning_rate: 0.0068\n",
      "Epoch 399/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7207 - loss: 0.5579 - learning_rate: 0.0068\n",
      "Epoch 400/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7250 - loss: 0.5529 - learning_rate: 0.0068\n",
      "Epoch 401/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7276 - loss: 0.5552 - learning_rate: 0.0068\n",
      "Epoch 402/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7251 - loss: 0.5484 - learning_rate: 0.0068\n",
      "Epoch 403/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.7314 - loss: 0.5549 - learning_rate: 0.0068\n",
      "Epoch 404/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7284 - loss: 0.5563 - learning_rate: 0.0067\n",
      "Epoch 405/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7091 - loss: 0.5801 - learning_rate: 0.0067\n",
      "Epoch 406/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7414 - loss: 0.5357 - learning_rate: 0.0067\n",
      "Epoch 407/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7367 - loss: 0.5467 - learning_rate: 0.0067\n",
      "Epoch 408/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7257 - loss: 0.5648 - learning_rate: 0.0067\n",
      "Epoch 409/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7169 - loss: 0.5658 - learning_rate: 0.0067\n",
      "Epoch 410/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7402 - loss: 0.5493 - learning_rate: 0.0067\n",
      "Epoch 411/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7350 - loss: 0.5483 - learning_rate: 0.0067\n",
      "Epoch 412/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.7259 - loss: 0.5598 - learning_rate: 0.0067\n",
      "Epoch 413/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7310 - loss: 0.5522 - learning_rate: 0.0067\n",
      "Epoch 414/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7358 - loss: 0.5579 - learning_rate: 0.0067\n",
      "Epoch 415/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7171 - loss: 0.5684 - learning_rate: 0.0067\n",
      "Epoch 416/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7178 - loss: 0.5656 - learning_rate: 0.0067\n",
      "Epoch 417/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7283 - loss: 0.5410 - learning_rate: 0.0067\n",
      "Epoch 418/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7199 - loss: 0.5613 - learning_rate: 0.0066\n",
      "Epoch 419/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7436 - loss: 0.5345 - learning_rate: 0.0066\n",
      "Epoch 420/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7383 - loss: 0.5455 - learning_rate: 0.0066\n",
      "Epoch 421/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7223 - loss: 0.5667 - learning_rate: 0.0066\n",
      "Epoch 422/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7426 - loss: 0.5483 - learning_rate: 0.0066\n",
      "Epoch 423/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7407 - loss: 0.5446 - learning_rate: 0.0066\n",
      "Epoch 424/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7457 - loss: 0.5453 - learning_rate: 0.0066\n",
      "Epoch 425/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7399 - loss: 0.5527 - learning_rate: 0.0066\n",
      "Epoch 426/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7374 - loss: 0.5359 - learning_rate: 0.0066\n",
      "Epoch 427/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7331 - loss: 0.5605 - learning_rate: 0.0066\n",
      "Epoch 428/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7295 - loss: 0.5501 - learning_rate: 0.0066\n",
      "Epoch 429/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7383 - loss: 0.5477 - learning_rate: 0.0066\n",
      "Epoch 430/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7332 - loss: 0.5377 - learning_rate: 0.0066\n",
      "Epoch 431/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7453 - loss: 0.5450 - learning_rate: 0.0066\n",
      "Epoch 432/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7439 - loss: 0.5406 - learning_rate: 0.0066\n",
      "Epoch 433/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.7187 - loss: 0.5681 - learning_rate: 0.0066\n",
      "Epoch 434/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7370 - loss: 0.5475 - learning_rate: 0.0065\n",
      "Epoch 435/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7289 - loss: 0.5544 - learning_rate: 0.0065\n",
      "Epoch 436/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7389 - loss: 0.5400 - learning_rate: 0.0065\n",
      "Epoch 437/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7256 - loss: 0.5456 - learning_rate: 0.0065\n",
      "Epoch 438/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7306 - loss: 0.5551 - learning_rate: 0.0065\n",
      "Epoch 439/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7278 - loss: 0.5563 - learning_rate: 0.0065\n",
      "Epoch 440/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7290 - loss: 0.5500 - learning_rate: 0.0065\n",
      "Epoch 441/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7280 - loss: 0.5473 - learning_rate: 0.0065\n",
      "Epoch 442/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7264 - loss: 0.5645 - learning_rate: 0.0065\n",
      "Epoch 443/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7242 - loss: 0.5597 - learning_rate: 0.0065\n",
      "Epoch 444/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7323 - loss: 0.5455 - learning_rate: 0.0065\n",
      "Epoch 445/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7233 - loss: 0.5564 - learning_rate: 0.0065\n",
      "Epoch 446/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7311 - loss: 0.5450 - learning_rate: 0.0065\n",
      "Epoch 447/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7302 - loss: 0.5538 - learning_rate: 0.0065\n",
      "Epoch 448/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7241 - loss: 0.5523 - learning_rate: 0.0065\n",
      "Epoch 449/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7361 - loss: 0.5504 - learning_rate: 0.0064\n",
      "Epoch 450/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7259 - loss: 0.5534 - learning_rate: 0.0064\n",
      "Epoch 451/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7273 - loss: 0.5522 - learning_rate: 0.0064\n",
      "Epoch 452/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7405 - loss: 0.5430 - learning_rate: 0.0064\n",
      "Epoch 453/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7309 - loss: 0.5539 - learning_rate: 0.0064\n",
      "Epoch 454/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7240 - loss: 0.5667 - learning_rate: 0.0064\n",
      "Epoch 455/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7501 - loss: 0.5368 - learning_rate: 0.0064\n",
      "Epoch 456/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7192 - loss: 0.5650 - learning_rate: 0.0064\n",
      "Epoch 457/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7291 - loss: 0.5571 - learning_rate: 0.0064\n",
      "Epoch 458/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7505 - loss: 0.5248 - learning_rate: 0.0064\n",
      "Epoch 459/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7267 - loss: 0.5582 - learning_rate: 0.0064\n",
      "Epoch 460/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7279 - loss: 0.5559 - learning_rate: 0.0064\n",
      "Epoch 461/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7197 - loss: 0.5534 - learning_rate: 0.0064\n",
      "Epoch 462/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7249 - loss: 0.5590 - learning_rate: 0.0064\n",
      "Epoch 463/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7384 - loss: 0.5498 - learning_rate: 0.0064\n",
      "Epoch 464/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7238 - loss: 0.5685 - learning_rate: 0.0064\n",
      "Epoch 465/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7390 - loss: 0.5385 - learning_rate: 0.0063\n",
      "Epoch 466/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7497 - loss: 0.5316 - learning_rate: 0.0063\n",
      "Epoch 467/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7245 - loss: 0.5556 - learning_rate: 0.0063\n",
      "Epoch 468/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7303 - loss: 0.5544 - learning_rate: 0.0063\n",
      "Epoch 469/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7254 - loss: 0.5514 - learning_rate: 0.0063\n",
      "Epoch 470/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7342 - loss: 0.5618 - learning_rate: 0.0063\n",
      "Epoch 471/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7286 - loss: 0.5452 - learning_rate: 0.0063\n",
      "Epoch 472/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7582 - loss: 0.5294 - learning_rate: 0.0063\n",
      "Epoch 473/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7404 - loss: 0.5447 - learning_rate: 0.0063\n",
      "Epoch 474/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7540 - loss: 0.5378 - learning_rate: 0.0063\n",
      "Epoch 475/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7273 - loss: 0.5544 - learning_rate: 0.0063\n",
      "Epoch 476/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7623 - loss: 0.5142 - learning_rate: 0.0063\n",
      "Epoch 477/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7387 - loss: 0.5471 - learning_rate: 0.0063\n",
      "Epoch 478/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7360 - loss: 0.5431 - learning_rate: 0.0063\n",
      "Epoch 479/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7368 - loss: 0.5690 - learning_rate: 0.0063\n",
      "Epoch 480/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7509 - loss: 0.5374 - learning_rate: 0.0062\n",
      "Epoch 481/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7226 - loss: 0.5612 - learning_rate: 0.0062\n",
      "Epoch 482/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7332 - loss: 0.5655 - learning_rate: 0.0062\n",
      "Epoch 483/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7216 - loss: 0.5563 - learning_rate: 0.0062\n",
      "Epoch 484/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7215 - loss: 0.5654 - learning_rate: 0.0062\n",
      "Epoch 485/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7299 - loss: 0.5610 - learning_rate: 0.0062\n",
      "Epoch 486/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7385 - loss: 0.5434 - learning_rate: 0.0062\n",
      "Epoch 487/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7301 - loss: 0.5503 - learning_rate: 0.0062\n",
      "Epoch 488/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7300 - loss: 0.5572 - learning_rate: 0.0062\n",
      "Epoch 489/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7207 - loss: 0.5630 - learning_rate: 0.0062\n",
      "Epoch 490/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7494 - loss: 0.5373 - learning_rate: 0.0062\n",
      "Epoch 491/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7567 - loss: 0.5276 - learning_rate: 0.0062\n",
      "Epoch 492/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7255 - loss: 0.5606 - learning_rate: 0.0062\n",
      "Epoch 493/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7486 - loss: 0.5351 - learning_rate: 0.0062\n",
      "Epoch 494/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7382 - loss: 0.5453 - learning_rate: 0.0062\n",
      "Epoch 495/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7378 - loss: 0.5502 - learning_rate: 0.0062\n",
      "Epoch 496/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7266 - loss: 0.5541 - learning_rate: 0.0062\n",
      "Epoch 497/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7508 - loss: 0.5471 - learning_rate: 0.0061\n",
      "Epoch 498/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7459 - loss: 0.5317 - learning_rate: 0.0061\n",
      "Epoch 499/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7492 - loss: 0.5324 - learning_rate: 0.0061\n",
      "Epoch 500/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7374 - loss: 0.5359 - learning_rate: 0.0061\n",
      "Epoch 501/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7379 - loss: 0.5402 - learning_rate: 0.0061\n",
      "Epoch 502/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.7378 - loss: 0.5492 - learning_rate: 0.0061\n",
      "Epoch 503/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7486 - loss: 0.5430 - learning_rate: 0.0061\n",
      "Epoch 504/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7437 - loss: 0.5383 - learning_rate: 0.0061\n",
      "Epoch 505/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7350 - loss: 0.5399 - learning_rate: 0.0061\n",
      "Epoch 506/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7369 - loss: 0.5451 - learning_rate: 0.0061\n",
      "Epoch 507/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7354 - loss: 0.5549 - learning_rate: 0.0061\n",
      "Epoch 508/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7421 - loss: 0.5392 - learning_rate: 0.0061\n",
      "Epoch 509/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7109 - loss: 0.5758 - learning_rate: 0.0061\n",
      "Epoch 510/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7112 - loss: 0.5740 - learning_rate: 0.0061\n",
      "Epoch 511/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7442 - loss: 0.5441 - learning_rate: 0.0061\n",
      "Epoch 512/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7539 - loss: 0.5375 - learning_rate: 0.0061\n",
      "Epoch 513/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7270 - loss: 0.5652 - learning_rate: 0.0060\n",
      "Epoch 514/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7478 - loss: 0.5405 - learning_rate: 0.0060\n",
      "Epoch 515/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7256 - loss: 0.5638 - learning_rate: 0.0060\n",
      "Epoch 516/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7247 - loss: 0.5501 - learning_rate: 0.0060\n",
      "Epoch 517/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7499 - loss: 0.5297 - learning_rate: 0.0060\n",
      "Epoch 518/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7440 - loss: 0.5434 - learning_rate: 0.0060\n",
      "Epoch 519/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7369 - loss: 0.5497 - learning_rate: 0.0060\n",
      "Epoch 520/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7488 - loss: 0.5358 - learning_rate: 0.0060\n",
      "Epoch 521/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7385 - loss: 0.5484 - learning_rate: 0.0060\n",
      "Epoch 522/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7305 - loss: 0.5413 - learning_rate: 0.0060\n",
      "Epoch 523/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7140 - loss: 0.5717 - learning_rate: 0.0060\n",
      "Epoch 524/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7325 - loss: 0.5449 - learning_rate: 0.0060\n",
      "Epoch 525/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7358 - loss: 0.5524 - learning_rate: 0.0060\n",
      "Epoch 526/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7450 - loss: 0.5365 - learning_rate: 0.0060\n",
      "Epoch 527/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7359 - loss: 0.5585 - learning_rate: 0.0060\n",
      "Epoch 528/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7419 - loss: 0.5540 - learning_rate: 0.0060\n",
      "Epoch 529/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7339 - loss: 0.5448 - learning_rate: 0.0060\n",
      "Epoch 530/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7261 - loss: 0.5567 - learning_rate: 0.0059\n",
      "Epoch 531/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7242 - loss: 0.5630 - learning_rate: 0.0059\n",
      "Epoch 532/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7366 - loss: 0.5503 - learning_rate: 0.0059\n",
      "Epoch 533/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7205 - loss: 0.5552 - learning_rate: 0.0059\n",
      "Epoch 534/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7350 - loss: 0.5397 - learning_rate: 0.0059\n",
      "Epoch 535/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7302 - loss: 0.5468 - learning_rate: 0.0059\n",
      "Epoch 536/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7321 - loss: 0.5466 - learning_rate: 0.0059\n",
      "Epoch 537/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7167 - loss: 0.5619 - learning_rate: 0.0059\n",
      "Epoch 538/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7503 - loss: 0.5362 - learning_rate: 0.0059\n",
      "Epoch 539/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7555 - loss: 0.5400 - learning_rate: 0.0059\n",
      "Epoch 540/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7342 - loss: 0.5430 - learning_rate: 0.0059\n",
      "Epoch 541/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.7322 - loss: 0.5578 - learning_rate: 0.0059\n",
      "Epoch 542/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7442 - loss: 0.5419 - learning_rate: 0.0059\n",
      "Epoch 543/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7410 - loss: 0.5585 - learning_rate: 0.0059\n",
      "Epoch 544/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7347 - loss: 0.5341 - learning_rate: 0.0059\n",
      "Epoch 545/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7377 - loss: 0.5370 - learning_rate: 0.0059\n",
      "Epoch 546/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7333 - loss: 0.5508 - learning_rate: 0.0059\n",
      "Epoch 547/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7457 - loss: 0.5422 - learning_rate: 0.0058\n",
      "Epoch 548/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7431 - loss: 0.5364 - learning_rate: 0.0058\n",
      "Epoch 549/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7440 - loss: 0.5323 - learning_rate: 0.0058\n",
      "Epoch 550/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7256 - loss: 0.5500 - learning_rate: 0.0058\n",
      "Epoch 551/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7422 - loss: 0.5387 - learning_rate: 0.0058\n",
      "Epoch 552/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7414 - loss: 0.5361 - learning_rate: 0.0058\n",
      "Epoch 553/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7437 - loss: 0.5369 - learning_rate: 0.0058\n",
      "Epoch 554/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7515 - loss: 0.5370 - learning_rate: 0.0058\n",
      "Epoch 555/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7469 - loss: 0.5453 - learning_rate: 0.0058\n",
      "Epoch 556/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7509 - loss: 0.5348 - learning_rate: 0.0058\n",
      "Epoch 557/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7438 - loss: 0.5403 - learning_rate: 0.0058\n",
      "Epoch 558/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7546 - loss: 0.5217 - learning_rate: 0.0058\n",
      "Epoch 559/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7626 - loss: 0.5226 - learning_rate: 0.0058\n",
      "Epoch 560/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7329 - loss: 0.5540 - learning_rate: 0.0058\n",
      "Epoch 561/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7367 - loss: 0.5587 - learning_rate: 0.0058\n",
      "Epoch 562/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7416 - loss: 0.5381 - learning_rate: 0.0058\n",
      "Epoch 563/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7411 - loss: 0.5456 - learning_rate: 0.0058\n",
      "Epoch 564/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7491 - loss: 0.5434 - learning_rate: 0.0057\n",
      "Epoch 565/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7294 - loss: 0.5534 - learning_rate: 0.0057\n",
      "Epoch 566/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7495 - loss: 0.5337 - learning_rate: 0.0057\n",
      "Epoch 567/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7476 - loss: 0.5293 - learning_rate: 0.0057\n",
      "Epoch 568/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7228 - loss: 0.5643 - learning_rate: 0.0057\n",
      "Epoch 569/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7179 - loss: 0.5639 - learning_rate: 0.0057\n",
      "Epoch 570/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7452 - loss: 0.5383 - learning_rate: 0.0057\n",
      "Epoch 571/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7623 - loss: 0.5240 - learning_rate: 0.0057\n",
      "Epoch 572/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7375 - loss: 0.5464 - learning_rate: 0.0057\n",
      "Epoch 573/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7377 - loss: 0.5459 - learning_rate: 0.0057\n",
      "Epoch 574/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7329 - loss: 0.5443 - learning_rate: 0.0057\n",
      "Epoch 575/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7436 - loss: 0.5407 - learning_rate: 0.0057\n",
      "Epoch 576/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7487 - loss: 0.5296 - learning_rate: 0.0057\n",
      "Epoch 577/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7287 - loss: 0.5511 - learning_rate: 0.0057\n",
      "Epoch 578/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7389 - loss: 0.5405 - learning_rate: 0.0057\n",
      "Epoch 579/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7389 - loss: 0.5281 - learning_rate: 0.0057\n",
      "Epoch 580/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7544 - loss: 0.5288 - learning_rate: 0.0057\n",
      "Epoch 581/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7383 - loss: 0.5426 - learning_rate: 0.0056\n",
      "Epoch 582/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7291 - loss: 0.5558 - learning_rate: 0.0056\n",
      "Epoch 583/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7527 - loss: 0.5302 - learning_rate: 0.0056\n",
      "Epoch 584/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7541 - loss: 0.5413 - learning_rate: 0.0056\n",
      "Epoch 585/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7229 - loss: 0.5563 - learning_rate: 0.0056\n",
      "Epoch 586/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7284 - loss: 0.5547 - learning_rate: 0.0056\n",
      "Epoch 587/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7611 - loss: 0.5284 - learning_rate: 0.0056\n",
      "Epoch 588/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7469 - loss: 0.5300 - learning_rate: 0.0056\n",
      "Epoch 589/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7364 - loss: 0.5446 - learning_rate: 0.0056\n",
      "Epoch 590/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7405 - loss: 0.5267 - learning_rate: 0.0056\n",
      "Epoch 591/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7389 - loss: 0.5446 - learning_rate: 0.0056\n",
      "Epoch 592/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7431 - loss: 0.5310 - learning_rate: 0.0056\n",
      "Epoch 593/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7260 - loss: 0.5623 - learning_rate: 0.0056\n",
      "Epoch 594/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7301 - loss: 0.5529 - learning_rate: 0.0056\n",
      "Epoch 595/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7610 - loss: 0.5237 - learning_rate: 0.0056\n",
      "Epoch 596/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7306 - loss: 0.5391 - learning_rate: 0.0056\n",
      "Epoch 597/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7398 - loss: 0.5468 - learning_rate: 0.0056\n",
      "Epoch 598/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7418 - loss: 0.5432 - learning_rate: 0.0056\n",
      "Epoch 599/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7351 - loss: 0.5457 - learning_rate: 0.0055\n",
      "Epoch 600/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7243 - loss: 0.5504 - learning_rate: 0.0055\n",
      "Epoch 601/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7195 - loss: 0.5685 - learning_rate: 0.0055\n",
      "Epoch 602/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7548 - loss: 0.5160 - learning_rate: 0.0055\n",
      "Epoch 603/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7580 - loss: 0.5251 - learning_rate: 0.0055\n",
      "Epoch 604/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7405 - loss: 0.5446 - learning_rate: 0.0055\n",
      "Epoch 605/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7390 - loss: 0.5419 - learning_rate: 0.0055\n",
      "Epoch 606/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7253 - loss: 0.5518 - learning_rate: 0.0055\n",
      "Epoch 607/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7371 - loss: 0.5529 - learning_rate: 0.0055\n",
      "Epoch 608/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.7652 - loss: 0.5245 - learning_rate: 0.0055\n",
      "Epoch 609/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7458 - loss: 0.5443 - learning_rate: 0.0055\n",
      "Epoch 610/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7347 - loss: 0.5383 - learning_rate: 0.0055\n",
      "Epoch 611/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7676 - loss: 0.5164 - learning_rate: 0.0055\n",
      "Epoch 612/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7491 - loss: 0.5271 - learning_rate: 0.0055\n",
      "Epoch 613/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7393 - loss: 0.5382 - learning_rate: 0.0055\n",
      "Epoch 614/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7563 - loss: 0.5286 - learning_rate: 0.0055\n",
      "Epoch 615/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7474 - loss: 0.5442 - learning_rate: 0.0055\n",
      "Epoch 616/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7369 - loss: 0.5519 - learning_rate: 0.0055\n",
      "Epoch 617/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7301 - loss: 0.5391 - learning_rate: 0.0054\n",
      "Epoch 618/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7288 - loss: 0.5640 - learning_rate: 0.0054\n",
      "Epoch 619/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7462 - loss: 0.5445 - learning_rate: 0.0054\n",
      "Epoch 620/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7452 - loss: 0.5448 - learning_rate: 0.0054\n",
      "Epoch 621/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7379 - loss: 0.5337 - learning_rate: 0.0054\n",
      "Epoch 622/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7588 - loss: 0.5200 - learning_rate: 0.0054\n",
      "Epoch 623/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7329 - loss: 0.5406 - learning_rate: 0.0054\n",
      "Epoch 624/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7466 - loss: 0.5354 - learning_rate: 0.0054\n",
      "Epoch 625/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7232 - loss: 0.5603 - learning_rate: 0.0054\n",
      "Epoch 626/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7309 - loss: 0.5380 - learning_rate: 0.0054\n",
      "Epoch 627/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7456 - loss: 0.5360 - learning_rate: 0.0054\n",
      "Epoch 628/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7446 - loss: 0.5381 - learning_rate: 0.0054\n",
      "Epoch 629/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7187 - loss: 0.5527 - learning_rate: 0.0054\n",
      "Epoch 630/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7431 - loss: 0.5417 - learning_rate: 0.0054\n",
      "Epoch 631/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7199 - loss: 0.5557 - learning_rate: 0.0054\n",
      "Epoch 632/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7457 - loss: 0.5377 - learning_rate: 0.0054\n",
      "Epoch 633/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7511 - loss: 0.5341 - learning_rate: 0.0054\n",
      "Epoch 634/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7434 - loss: 0.5487 - learning_rate: 0.0054\n",
      "Epoch 635/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7430 - loss: 0.5402 - learning_rate: 0.0054\n",
      "Epoch 636/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.7478 - loss: 0.5319 - learning_rate: 0.0053\n",
      "Epoch 637/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7414 - loss: 0.5380 - learning_rate: 0.0053\n",
      "Epoch 638/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7629 - loss: 0.5128 - learning_rate: 0.0053\n",
      "Epoch 639/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7549 - loss: 0.5257 - learning_rate: 0.0053\n",
      "Epoch 640/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7544 - loss: 0.5183 - learning_rate: 0.0053\n",
      "Epoch 641/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7473 - loss: 0.5412 - learning_rate: 0.0053\n",
      "Epoch 642/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7532 - loss: 0.5252 - learning_rate: 0.0053\n",
      "Epoch 643/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7505 - loss: 0.5346 - learning_rate: 0.0053\n",
      "Epoch 644/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7550 - loss: 0.5294 - learning_rate: 0.0053\n",
      "Epoch 645/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7395 - loss: 0.5270 - learning_rate: 0.0053\n",
      "Epoch 646/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7406 - loss: 0.5332 - learning_rate: 0.0053\n",
      "Epoch 647/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7341 - loss: 0.5286 - learning_rate: 0.0053\n",
      "Epoch 648/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7334 - loss: 0.5383 - learning_rate: 0.0053\n",
      "Epoch 649/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7544 - loss: 0.5351 - learning_rate: 0.0053\n",
      "Epoch 650/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7446 - loss: 0.5406 - learning_rate: 0.0053\n",
      "Epoch 651/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7343 - loss: 0.5526 - learning_rate: 0.0053\n",
      "Epoch 652/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7570 - loss: 0.5222 - learning_rate: 0.0053\n",
      "Epoch 653/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7622 - loss: 0.5221 - learning_rate: 0.0053\n",
      "Epoch 654/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7414 - loss: 0.5417 - learning_rate: 0.0053\n",
      "Epoch 655/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7437 - loss: 0.5309 - learning_rate: 0.0052\n",
      "Epoch 656/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7516 - loss: 0.5164 - learning_rate: 0.0052\n",
      "Epoch 657/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7473 - loss: 0.5279 - learning_rate: 0.0052\n",
      "Epoch 658/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7330 - loss: 0.5487 - learning_rate: 0.0052\n",
      "Epoch 659/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7405 - loss: 0.5498 - learning_rate: 0.0052\n",
      "Epoch 660/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7543 - loss: 0.5273 - learning_rate: 0.0052\n",
      "Epoch 661/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7366 - loss: 0.5445 - learning_rate: 0.0052\n",
      "Epoch 662/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7346 - loss: 0.5567 - learning_rate: 0.0052\n",
      "Epoch 663/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7620 - loss: 0.5187 - learning_rate: 0.0052\n",
      "Epoch 664/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7483 - loss: 0.5351 - learning_rate: 0.0052\n",
      "Epoch 665/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7478 - loss: 0.5440 - learning_rate: 0.0052\n",
      "Epoch 666/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7340 - loss: 0.5400 - learning_rate: 0.0052\n",
      "Epoch 667/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7481 - loss: 0.5307 - learning_rate: 0.0052\n",
      "Epoch 668/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7363 - loss: 0.5391 - learning_rate: 0.0052\n",
      "Epoch 669/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7305 - loss: 0.5551 - learning_rate: 0.0052\n",
      "Epoch 670/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7196 - loss: 0.5617 - learning_rate: 0.0052\n",
      "Epoch 671/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7537 - loss: 0.5318 - learning_rate: 0.0052\n",
      "Epoch 672/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7423 - loss: 0.5453 - learning_rate: 0.0052\n",
      "Epoch 673/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7460 - loss: 0.5352 - learning_rate: 0.0052\n",
      "Epoch 674/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.7394 - loss: 0.5494 - learning_rate: 0.0051\n",
      "Epoch 675/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7619 - loss: 0.5217 - learning_rate: 0.0051\n",
      "Epoch 676/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7452 - loss: 0.5277 - learning_rate: 0.0051\n",
      "Epoch 677/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7281 - loss: 0.5568 - learning_rate: 0.0051\n",
      "Epoch 678/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7478 - loss: 0.5354 - learning_rate: 0.0051\n",
      "Epoch 679/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7504 - loss: 0.5278 - learning_rate: 0.0051\n",
      "Epoch 680/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7405 - loss: 0.5365 - learning_rate: 0.0051\n",
      "Epoch 681/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7451 - loss: 0.5418 - learning_rate: 0.0051\n",
      "Epoch 682/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7474 - loss: 0.5318 - learning_rate: 0.0051\n",
      "Epoch 683/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7560 - loss: 0.5354 - learning_rate: 0.0051\n",
      "Epoch 684/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7604 - loss: 0.5221 - learning_rate: 0.0051\n",
      "Epoch 685/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7433 - loss: 0.5355 - learning_rate: 0.0051\n",
      "Epoch 686/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7455 - loss: 0.5383 - learning_rate: 0.0051\n",
      "Epoch 687/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7379 - loss: 0.5424 - learning_rate: 0.0051\n",
      "Epoch 688/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7591 - loss: 0.5201 - learning_rate: 0.0051\n",
      "Epoch 689/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7463 - loss: 0.5350 - learning_rate: 0.0051\n",
      "Epoch 690/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7532 - loss: 0.5139 - learning_rate: 0.0051\n",
      "Epoch 691/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7515 - loss: 0.5307 - learning_rate: 0.0051\n",
      "Epoch 692/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7339 - loss: 0.5447 - learning_rate: 0.0051\n",
      "Epoch 693/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7438 - loss: 0.5428 - learning_rate: 0.0051\n",
      "Epoch 694/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7573 - loss: 0.5225 - learning_rate: 0.0050\n",
      "Epoch 695/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7445 - loss: 0.5387 - learning_rate: 0.0050\n",
      "Epoch 696/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7420 - loss: 0.5508 - learning_rate: 0.0050\n",
      "Epoch 697/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7642 - loss: 0.5287 - learning_rate: 0.0050\n",
      "Epoch 698/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7538 - loss: 0.5284 - learning_rate: 0.0050\n",
      "Epoch 699/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7430 - loss: 0.5383 - learning_rate: 0.0050\n",
      "Epoch 700/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7448 - loss: 0.5492 - learning_rate: 0.0050\n",
      "Epoch 701/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7582 - loss: 0.5264 - learning_rate: 0.0050\n",
      "Epoch 702/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7416 - loss: 0.5474 - learning_rate: 0.0050\n",
      "Epoch 703/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7592 - loss: 0.5234 - learning_rate: 0.0050\n",
      "Epoch 704/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7734 - loss: 0.5043 - learning_rate: 0.0050\n",
      "Epoch 705/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7492 - loss: 0.5287 - learning_rate: 0.0050\n",
      "Epoch 706/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7519 - loss: 0.5355 - learning_rate: 0.0050\n",
      "Epoch 707/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7469 - loss: 0.5364 - learning_rate: 0.0050\n",
      "Epoch 708/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7516 - loss: 0.5370 - learning_rate: 0.0050\n",
      "Epoch 709/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7474 - loss: 0.5339 - learning_rate: 0.0050\n",
      "Epoch 710/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7570 - loss: 0.5191 - learning_rate: 0.0050\n",
      "Epoch 711/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7504 - loss: 0.5216 - learning_rate: 0.0050\n",
      "Epoch 712/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7441 - loss: 0.5322 - learning_rate: 0.0050\n",
      "Epoch 713/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7328 - loss: 0.5493 - learning_rate: 0.0050\n",
      "Epoch 714/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7437 - loss: 0.5553 - learning_rate: 0.0049\n",
      "Epoch 715/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7521 - loss: 0.5250 - learning_rate: 0.0049\n",
      "Epoch 716/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7457 - loss: 0.5393 - learning_rate: 0.0049\n",
      "Epoch 717/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7526 - loss: 0.5285 - learning_rate: 0.0049\n",
      "Epoch 718/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7326 - loss: 0.5417 - learning_rate: 0.0049\n",
      "Epoch 719/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7568 - loss: 0.5303 - learning_rate: 0.0049\n",
      "Epoch 720/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7447 - loss: 0.5402 - learning_rate: 0.0049\n",
      "Epoch 721/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7583 - loss: 0.5361 - learning_rate: 0.0049\n",
      "Epoch 722/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7536 - loss: 0.5439 - learning_rate: 0.0049\n",
      "Epoch 723/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7589 - loss: 0.5263 - learning_rate: 0.0049\n",
      "Epoch 724/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7407 - loss: 0.5381 - learning_rate: 0.0049\n",
      "Epoch 725/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7401 - loss: 0.5406 - learning_rate: 0.0049\n",
      "Epoch 726/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7409 - loss: 0.5486 - learning_rate: 0.0049\n",
      "Epoch 727/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7490 - loss: 0.5339 - learning_rate: 0.0049\n",
      "Epoch 728/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7397 - loss: 0.5339 - learning_rate: 0.0049\n",
      "Epoch 729/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7637 - loss: 0.5133 - learning_rate: 0.0049\n",
      "Epoch 730/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7453 - loss: 0.5359 - learning_rate: 0.0049\n",
      "Epoch 731/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7413 - loss: 0.5402 - learning_rate: 0.0049\n",
      "Epoch 732/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7437 - loss: 0.5268 - learning_rate: 0.0049\n",
      "Epoch 733/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7399 - loss: 0.5327 - learning_rate: 0.0049\n",
      "Epoch 734/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7540 - loss: 0.5343 - learning_rate: 0.0048\n",
      "Epoch 735/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7671 - loss: 0.5182 - learning_rate: 0.0048\n",
      "Epoch 736/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7498 - loss: 0.5368 - learning_rate: 0.0048\n",
      "Epoch 737/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7494 - loss: 0.5400 - learning_rate: 0.0048\n",
      "Epoch 738/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7459 - loss: 0.5225 - learning_rate: 0.0048\n",
      "Epoch 739/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7389 - loss: 0.5420 - learning_rate: 0.0048\n",
      "Epoch 740/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7484 - loss: 0.5291 - learning_rate: 0.0048\n",
      "Epoch 741/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7477 - loss: 0.5293 - learning_rate: 0.0048\n",
      "Epoch 742/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7634 - loss: 0.5092 - learning_rate: 0.0048\n",
      "Epoch 743/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7577 - loss: 0.5167 - learning_rate: 0.0048\n",
      "Epoch 744/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7579 - loss: 0.5330 - learning_rate: 0.0048\n",
      "Epoch 745/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7494 - loss: 0.5474 - learning_rate: 0.0048\n",
      "Epoch 746/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7557 - loss: 0.5239 - learning_rate: 0.0048\n",
      "Epoch 747/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7487 - loss: 0.5338 - learning_rate: 0.0048\n",
      "Epoch 748/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7550 - loss: 0.5202 - learning_rate: 0.0048\n",
      "Epoch 749/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7470 - loss: 0.5301 - learning_rate: 0.0048\n",
      "Epoch 750/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7558 - loss: 0.5219 - learning_rate: 0.0048\n",
      "Epoch 751/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7437 - loss: 0.5220 - learning_rate: 0.0048\n",
      "Epoch 752/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7476 - loss: 0.5324 - learning_rate: 0.0048\n",
      "Epoch 753/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7619 - loss: 0.5184 - learning_rate: 0.0048\n",
      "Epoch 754/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7537 - loss: 0.5212 - learning_rate: 0.0048\n",
      "Epoch 755/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7493 - loss: 0.5316 - learning_rate: 0.0047\n",
      "Epoch 756/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7549 - loss: 0.5328 - learning_rate: 0.0047\n",
      "Epoch 757/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7598 - loss: 0.5225 - learning_rate: 0.0047\n",
      "Epoch 758/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7408 - loss: 0.5302 - learning_rate: 0.0047\n",
      "Epoch 759/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7546 - loss: 0.5095 - learning_rate: 0.0047\n",
      "Epoch 760/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7515 - loss: 0.5315 - learning_rate: 0.0047\n",
      "Epoch 761/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7595 - loss: 0.5255 - learning_rate: 0.0047\n",
      "Epoch 762/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7628 - loss: 0.5165 - learning_rate: 0.0047\n",
      "Epoch 763/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7406 - loss: 0.5482 - learning_rate: 0.0047\n",
      "Epoch 764/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7319 - loss: 0.5480 - learning_rate: 0.0047\n",
      "Epoch 765/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7640 - loss: 0.5170 - learning_rate: 0.0047\n",
      "Epoch 766/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7434 - loss: 0.5413 - learning_rate: 0.0047\n",
      "Epoch 767/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7336 - loss: 0.5559 - learning_rate: 0.0047\n",
      "Epoch 768/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7487 - loss: 0.5205 - learning_rate: 0.0047\n",
      "Epoch 769/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7439 - loss: 0.5341 - learning_rate: 0.0047\n",
      "Epoch 770/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7494 - loss: 0.5200 - learning_rate: 0.0047\n",
      "Epoch 771/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7535 - loss: 0.5296 - learning_rate: 0.0047\n",
      "Epoch 772/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7525 - loss: 0.5204 - learning_rate: 0.0047\n",
      "Epoch 773/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7336 - loss: 0.5496 - learning_rate: 0.0047\n",
      "Epoch 774/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7612 - loss: 0.5187 - learning_rate: 0.0047\n",
      "Epoch 775/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7381 - loss: 0.5424 - learning_rate: 0.0047\n",
      "Epoch 776/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7523 - loss: 0.5286 - learning_rate: 0.0046\n",
      "Epoch 777/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7401 - loss: 0.5528 - learning_rate: 0.0046\n",
      "Epoch 778/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7502 - loss: 0.5265 - learning_rate: 0.0046\n",
      "Epoch 779/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7488 - loss: 0.5362 - learning_rate: 0.0046\n",
      "Epoch 780/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7429 - loss: 0.5323 - learning_rate: 0.0046\n",
      "Epoch 781/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7494 - loss: 0.5300 - learning_rate: 0.0046\n",
      "Epoch 782/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7547 - loss: 0.5437 - learning_rate: 0.0046\n",
      "Epoch 783/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7521 - loss: 0.5161 - learning_rate: 0.0046\n",
      "Epoch 784/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7456 - loss: 0.5392 - learning_rate: 0.0046\n",
      "Epoch 785/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7477 - loss: 0.5354 - learning_rate: 0.0046\n",
      "Epoch 786/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7534 - loss: 0.5311 - learning_rate: 0.0046\n",
      "Epoch 787/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7717 - loss: 0.5107 - learning_rate: 0.0046\n",
      "Epoch 788/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7429 - loss: 0.5302 - learning_rate: 0.0046\n",
      "Epoch 789/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7611 - loss: 0.5194 - learning_rate: 0.0046\n",
      "Epoch 790/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7494 - loss: 0.5237 - learning_rate: 0.0046\n",
      "Epoch 791/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7465 - loss: 0.5311 - learning_rate: 0.0046\n",
      "Epoch 792/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7481 - loss: 0.5254 - learning_rate: 0.0046\n",
      "Epoch 793/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7461 - loss: 0.5346 - learning_rate: 0.0046\n",
      "Epoch 794/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7344 - loss: 0.5370 - learning_rate: 0.0046\n",
      "Epoch 795/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7622 - loss: 0.5280 - learning_rate: 0.0046\n",
      "Epoch 796/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7727 - loss: 0.5159 - learning_rate: 0.0046\n",
      "Epoch 797/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7590 - loss: 0.5224 - learning_rate: 0.0046\n",
      "Epoch 798/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7469 - loss: 0.5298 - learning_rate: 0.0045\n",
      "Epoch 799/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7466 - loss: 0.5311 - learning_rate: 0.0045\n",
      "Epoch 800/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7276 - loss: 0.5392 - learning_rate: 0.0045\n",
      "Epoch 801/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7550 - loss: 0.5145 - learning_rate: 0.0045\n",
      "Epoch 802/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7482 - loss: 0.5381 - learning_rate: 0.0045\n",
      "Epoch 803/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7438 - loss: 0.5358 - learning_rate: 0.0045\n",
      "Epoch 804/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7534 - loss: 0.5305 - learning_rate: 0.0045\n",
      "Epoch 805/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7697 - loss: 0.5103 - learning_rate: 0.0045\n",
      "Epoch 806/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7502 - loss: 0.5458 - learning_rate: 0.0045\n",
      "Epoch 807/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7574 - loss: 0.5229 - learning_rate: 0.0045\n",
      "Epoch 808/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7551 - loss: 0.5270 - learning_rate: 0.0045\n",
      "Epoch 809/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7443 - loss: 0.5290 - learning_rate: 0.0045\n",
      "Epoch 810/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7580 - loss: 0.5177 - learning_rate: 0.0045\n",
      "Epoch 811/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7465 - loss: 0.5289 - learning_rate: 0.0045\n",
      "Epoch 812/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7426 - loss: 0.5246 - learning_rate: 0.0045\n",
      "Epoch 813/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7485 - loss: 0.5315 - learning_rate: 0.0045\n",
      "Epoch 814/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7542 - loss: 0.5202 - learning_rate: 0.0045\n",
      "Epoch 815/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.7611 - loss: 0.5230 - learning_rate: 0.0045\n",
      "Epoch 816/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7482 - loss: 0.5349 - learning_rate: 0.0045\n",
      "Epoch 817/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7688 - loss: 0.5175 - learning_rate: 0.0045\n",
      "Epoch 818/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7356 - loss: 0.5372 - learning_rate: 0.0045\n",
      "Epoch 819/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7554 - loss: 0.5239 - learning_rate: 0.0045\n",
      "Epoch 820/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7711 - loss: 0.5235 - learning_rate: 0.0044\n",
      "Epoch 821/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7397 - loss: 0.5432 - learning_rate: 0.0044\n",
      "Epoch 822/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7528 - loss: 0.5160 - learning_rate: 0.0044\n",
      "Epoch 823/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7511 - loss: 0.5203 - learning_rate: 0.0044\n",
      "Epoch 824/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7485 - loss: 0.5410 - learning_rate: 0.0044\n",
      "Epoch 825/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7485 - loss: 0.5243 - learning_rate: 0.0044\n",
      "Epoch 826/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7539 - loss: 0.5233 - learning_rate: 0.0044\n",
      "Epoch 827/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7494 - loss: 0.5371 - learning_rate: 0.0044\n",
      "Epoch 828/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7503 - loss: 0.5212 - learning_rate: 0.0044\n",
      "Epoch 829/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7585 - loss: 0.5310 - learning_rate: 0.0044\n",
      "Epoch 830/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.7391 - loss: 0.5304 - learning_rate: 0.0044\n",
      "Epoch 831/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7564 - loss: 0.5202 - learning_rate: 0.0044\n",
      "Epoch 832/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7339 - loss: 0.5434 - learning_rate: 0.0044\n",
      "Epoch 833/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7560 - loss: 0.5324 - learning_rate: 0.0044\n",
      "Epoch 834/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7619 - loss: 0.5185 - learning_rate: 0.0044\n",
      "Epoch 835/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7743 - loss: 0.5102 - learning_rate: 0.0044\n",
      "Epoch 836/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7449 - loss: 0.5266 - learning_rate: 0.0044\n",
      "Epoch 837/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7411 - loss: 0.5401 - learning_rate: 0.0044\n",
      "Epoch 838/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7591 - loss: 0.5169 - learning_rate: 0.0044\n",
      "Epoch 839/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7520 - loss: 0.5302 - learning_rate: 0.0044\n",
      "Epoch 840/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7450 - loss: 0.5447 - learning_rate: 0.0044\n",
      "Epoch 841/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7513 - loss: 0.5282 - learning_rate: 0.0044\n",
      "Epoch 842/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7434 - loss: 0.5433 - learning_rate: 0.0044\n",
      "Epoch 843/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7580 - loss: 0.5107 - learning_rate: 0.0043\n",
      "Epoch 844/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7355 - loss: 0.5404 - learning_rate: 0.0043\n",
      "Epoch 845/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7544 - loss: 0.5210 - learning_rate: 0.0043\n",
      "Epoch 846/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7595 - loss: 0.5386 - learning_rate: 0.0043\n",
      "Epoch 847/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7585 - loss: 0.5179 - learning_rate: 0.0043\n",
      "Epoch 848/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7712 - loss: 0.5239 - learning_rate: 0.0043\n",
      "Epoch 849/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7622 - loss: 0.5264 - learning_rate: 0.0043\n",
      "Epoch 850/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7563 - loss: 0.5323 - learning_rate: 0.0043\n",
      "Epoch 851/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7579 - loss: 0.5344 - learning_rate: 0.0043\n",
      "Epoch 852/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7545 - loss: 0.5249 - learning_rate: 0.0043\n",
      "Epoch 853/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7487 - loss: 0.5387 - learning_rate: 0.0043\n",
      "Epoch 854/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7574 - loss: 0.5120 - learning_rate: 0.0043\n",
      "Epoch 855/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7595 - loss: 0.5258 - learning_rate: 0.0043\n",
      "Epoch 856/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7401 - loss: 0.5306 - learning_rate: 0.0043\n",
      "Epoch 857/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7414 - loss: 0.5441 - learning_rate: 0.0043\n",
      "Epoch 858/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7832 - loss: 0.4973 - learning_rate: 0.0043\n",
      "Epoch 859/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7687 - loss: 0.5023 - learning_rate: 0.0043\n",
      "Epoch 860/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7651 - loss: 0.5187 - learning_rate: 0.0043\n",
      "Epoch 861/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7534 - loss: 0.5177 - learning_rate: 0.0043\n",
      "Epoch 862/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7674 - loss: 0.5125 - learning_rate: 0.0043\n",
      "Epoch 863/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7444 - loss: 0.5389 - learning_rate: 0.0043\n",
      "Epoch 864/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7758 - loss: 0.4898 - learning_rate: 0.0043\n",
      "Epoch 865/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7507 - loss: 0.5233 - learning_rate: 0.0043\n",
      "Epoch 866/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7569 - loss: 0.5258 - learning_rate: 0.0042\n",
      "Epoch 867/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7457 - loss: 0.5250 - learning_rate: 0.0042\n",
      "Epoch 868/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7517 - loss: 0.5230 - learning_rate: 0.0042\n",
      "Epoch 869/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7613 - loss: 0.5021 - learning_rate: 0.0042\n",
      "Epoch 870/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7509 - loss: 0.5184 - learning_rate: 0.0042\n",
      "Epoch 871/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.7617 - loss: 0.5266 - learning_rate: 0.0042\n",
      "Epoch 872/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.7432 - loss: 0.5339 - learning_rate: 0.0042\n",
      "Epoch 873/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7530 - loss: 0.5218 - learning_rate: 0.0042\n",
      "Epoch 874/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7438 - loss: 0.5325 - learning_rate: 0.0042\n",
      "Epoch 875/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7543 - loss: 0.5168 - learning_rate: 0.0042\n",
      "Epoch 876/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7520 - loss: 0.5358 - learning_rate: 0.0042\n",
      "Epoch 877/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7535 - loss: 0.5148 - learning_rate: 0.0042\n",
      "Epoch 878/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7622 - loss: 0.5203 - learning_rate: 0.0042\n",
      "Epoch 879/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7533 - loss: 0.5310 - learning_rate: 0.0042\n",
      "Epoch 880/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7772 - loss: 0.5102 - learning_rate: 0.0042\n",
      "Epoch 881/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7608 - loss: 0.5151 - learning_rate: 0.0042\n",
      "Epoch 882/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7514 - loss: 0.5338 - learning_rate: 0.0042\n",
      "Epoch 883/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7396 - loss: 0.5264 - learning_rate: 0.0042\n",
      "Epoch 884/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7420 - loss: 0.5421 - learning_rate: 0.0042\n",
      "Epoch 885/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7786 - loss: 0.5125 - learning_rate: 0.0042\n",
      "Epoch 886/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7600 - loss: 0.5155 - learning_rate: 0.0042\n",
      "Epoch 887/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7415 - loss: 0.5486 - learning_rate: 0.0042\n",
      "Epoch 888/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7479 - loss: 0.5191 - learning_rate: 0.0042\n",
      "Epoch 889/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7724 - loss: 0.5115 - learning_rate: 0.0042\n",
      "Epoch 890/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7509 - loss: 0.5341 - learning_rate: 0.0041\n",
      "Epoch 891/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7328 - loss: 0.5580 - learning_rate: 0.0041\n",
      "Epoch 892/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7720 - loss: 0.4955 - learning_rate: 0.0041\n",
      "Epoch 893/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7575 - loss: 0.5299 - learning_rate: 0.0041\n",
      "Epoch 894/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7603 - loss: 0.5226 - learning_rate: 0.0041\n",
      "Epoch 895/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7659 - loss: 0.5070 - learning_rate: 0.0041\n",
      "Epoch 896/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7497 - loss: 0.5218 - learning_rate: 0.0041\n",
      "Epoch 897/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7665 - loss: 0.5207 - learning_rate: 0.0041\n",
      "Epoch 898/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7660 - loss: 0.5099 - learning_rate: 0.0041\n",
      "Epoch 899/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7521 - loss: 0.5218 - learning_rate: 0.0041\n",
      "Epoch 900/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7628 - loss: 0.5102 - learning_rate: 0.0041\n",
      "Epoch 901/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7483 - loss: 0.5300 - learning_rate: 0.0041\n",
      "Epoch 902/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7596 - loss: 0.5129 - learning_rate: 0.0041\n",
      "Epoch 903/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7644 - loss: 0.5082 - learning_rate: 0.0041\n",
      "Epoch 904/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7559 - loss: 0.5458 - learning_rate: 0.0041\n",
      "Epoch 905/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7408 - loss: 0.5276 - learning_rate: 0.0041\n",
      "Epoch 906/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7713 - loss: 0.5139 - learning_rate: 0.0041\n",
      "Epoch 907/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7496 - loss: 0.5433 - learning_rate: 0.0041\n",
      "Epoch 908/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7577 - loss: 0.5311 - learning_rate: 0.0041\n",
      "Epoch 909/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7732 - loss: 0.5106 - learning_rate: 0.0041\n",
      "Epoch 910/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7561 - loss: 0.5161 - learning_rate: 0.0041\n",
      "Epoch 911/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7620 - loss: 0.5204 - learning_rate: 0.0041\n",
      "Epoch 912/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7479 - loss: 0.5297 - learning_rate: 0.0041\n",
      "Epoch 913/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7651 - loss: 0.5172 - learning_rate: 0.0041\n",
      "Epoch 914/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7677 - loss: 0.5035 - learning_rate: 0.0040\n",
      "Epoch 915/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7535 - loss: 0.5177 - learning_rate: 0.0040\n",
      "Epoch 916/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7584 - loss: 0.5164 - learning_rate: 0.0040\n",
      "Epoch 917/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7426 - loss: 0.5277 - learning_rate: 0.0040\n",
      "Epoch 918/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7645 - loss: 0.5131 - learning_rate: 0.0040\n",
      "Epoch 919/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7524 - loss: 0.5285 - learning_rate: 0.0040\n",
      "Epoch 920/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7704 - loss: 0.5171 - learning_rate: 0.0040\n",
      "Epoch 921/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7561 - loss: 0.5106 - learning_rate: 0.0040\n",
      "Epoch 922/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7547 - loss: 0.5285 - learning_rate: 0.0040\n",
      "Epoch 923/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7601 - loss: 0.5148 - learning_rate: 0.0040\n",
      "Epoch 924/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7562 - loss: 0.5265 - learning_rate: 0.0040\n",
      "Epoch 925/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7467 - loss: 0.5292 - learning_rate: 0.0040\n",
      "Epoch 926/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7617 - loss: 0.5165 - learning_rate: 0.0040\n",
      "Epoch 927/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7682 - loss: 0.5116 - learning_rate: 0.0040\n",
      "Epoch 928/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7621 - loss: 0.5224 - learning_rate: 0.0040\n",
      "Epoch 929/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7541 - loss: 0.5235 - learning_rate: 0.0040\n",
      "Epoch 930/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.7613 - loss: 0.5104 - learning_rate: 0.0040\n",
      "Epoch 931/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7831 - loss: 0.5105 - learning_rate: 0.0040\n",
      "Epoch 932/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7594 - loss: 0.5298 - learning_rate: 0.0040\n",
      "Epoch 933/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7562 - loss: 0.5245 - learning_rate: 0.0040\n",
      "Epoch 934/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7710 - loss: 0.4966 - learning_rate: 0.0040\n",
      "Epoch 935/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7710 - loss: 0.5033 - learning_rate: 0.0040\n",
      "Epoch 936/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7604 - loss: 0.5267 - learning_rate: 0.0040\n",
      "Epoch 937/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7549 - loss: 0.5293 - learning_rate: 0.0040\n",
      "Epoch 938/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7591 - loss: 0.5201 - learning_rate: 0.0040\n",
      "Epoch 939/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7730 - loss: 0.5130 - learning_rate: 0.0039\n",
      "Epoch 940/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7619 - loss: 0.5157 - learning_rate: 0.0039\n",
      "Epoch 941/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7540 - loss: 0.5190 - learning_rate: 0.0039\n",
      "Epoch 942/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.7601 - loss: 0.5245 - learning_rate: 0.0039\n",
      "Epoch 943/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7681 - loss: 0.5079 - learning_rate: 0.0039\n",
      "Epoch 944/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7588 - loss: 0.5141 - learning_rate: 0.0039\n",
      "Epoch 945/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7627 - loss: 0.5104 - learning_rate: 0.0039\n",
      "Epoch 946/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7656 - loss: 0.5083 - learning_rate: 0.0039\n",
      "Epoch 947/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7652 - loss: 0.5188 - learning_rate: 0.0039\n",
      "Epoch 948/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7480 - loss: 0.5234 - learning_rate: 0.0039\n",
      "Epoch 949/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7596 - loss: 0.5181 - learning_rate: 0.0039\n",
      "Epoch 950/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7403 - loss: 0.5286 - learning_rate: 0.0039\n",
      "Epoch 951/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7572 - loss: 0.5177 - learning_rate: 0.0039\n",
      "Epoch 952/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7467 - loss: 0.5332 - learning_rate: 0.0039\n",
      "Epoch 953/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7648 - loss: 0.5281 - learning_rate: 0.0039\n",
      "Epoch 954/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7559 - loss: 0.5249 - learning_rate: 0.0039\n",
      "Epoch 955/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7424 - loss: 0.5366 - learning_rate: 0.0039\n",
      "Epoch 956/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7722 - loss: 0.5046 - learning_rate: 0.0039\n",
      "Epoch 957/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7483 - loss: 0.5293 - learning_rate: 0.0039\n",
      "Epoch 958/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.7420 - loss: 0.5481 - learning_rate: 0.0039\n",
      "Epoch 959/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7726 - loss: 0.5098 - learning_rate: 0.0039\n",
      "Epoch 960/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7698 - loss: 0.5061 - learning_rate: 0.0039\n",
      "Epoch 961/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.7629 - loss: 0.5058 - learning_rate: 0.0039\n",
      "Epoch 962/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7458 - loss: 0.5377 - learning_rate: 0.0039\n",
      "Epoch 963/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7614 - loss: 0.5223 - learning_rate: 0.0039\n",
      "Epoch 964/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7439 - loss: 0.5312 - learning_rate: 0.0039\n",
      "Epoch 965/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7687 - loss: 0.5110 - learning_rate: 0.0038\n",
      "Epoch 966/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7408 - loss: 0.5426 - learning_rate: 0.0038\n",
      "Epoch 967/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.7678 - loss: 0.5117 - learning_rate: 0.0038\n",
      "Epoch 968/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7494 - loss: 0.5222 - learning_rate: 0.0038\n",
      "Epoch 969/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7714 - loss: 0.5138 - learning_rate: 0.0038\n",
      "Epoch 970/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7673 - loss: 0.5063 - learning_rate: 0.0038\n",
      "Epoch 971/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7523 - loss: 0.5273 - learning_rate: 0.0038\n",
      "Epoch 972/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7590 - loss: 0.5176 - learning_rate: 0.0038\n",
      "Epoch 973/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7477 - loss: 0.5295 - learning_rate: 0.0038\n",
      "Epoch 974/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7445 - loss: 0.5280 - learning_rate: 0.0038\n",
      "Epoch 975/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7585 - loss: 0.5165 - learning_rate: 0.0038\n",
      "Epoch 976/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7571 - loss: 0.5067 - learning_rate: 0.0038\n",
      "Epoch 977/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7697 - loss: 0.5123 - learning_rate: 0.0038\n",
      "Epoch 978/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7671 - loss: 0.5115 - learning_rate: 0.0038\n",
      "Epoch 979/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7585 - loss: 0.5071 - learning_rate: 0.0038\n",
      "Epoch 980/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7673 - loss: 0.4994 - learning_rate: 0.0038\n",
      "Epoch 981/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7586 - loss: 0.5286 - learning_rate: 0.0038\n",
      "Epoch 982/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7458 - loss: 0.5318 - learning_rate: 0.0038\n",
      "Epoch 983/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7565 - loss: 0.5235 - learning_rate: 0.0038\n",
      "Epoch 984/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7658 - loss: 0.5154 - learning_rate: 0.0038\n",
      "Epoch 985/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7561 - loss: 0.5222 - learning_rate: 0.0038\n",
      "Epoch 986/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7644 - loss: 0.5135 - learning_rate: 0.0038\n",
      "Epoch 987/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7739 - loss: 0.5043 - learning_rate: 0.0038\n",
      "Epoch 988/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7623 - loss: 0.5143 - learning_rate: 0.0038\n",
      "Epoch 989/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7534 - loss: 0.5299 - learning_rate: 0.0038\n",
      "Epoch 990/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7660 - loss: 0.5169 - learning_rate: 0.0038\n",
      "Epoch 991/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7657 - loss: 0.5109 - learning_rate: 0.0037\n",
      "Epoch 992/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7664 - loss: 0.5204 - learning_rate: 0.0037\n",
      "Epoch 993/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7701 - loss: 0.4967 - learning_rate: 0.0037\n",
      "Epoch 994/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.7570 - loss: 0.5126 - learning_rate: 0.0037\n",
      "Epoch 995/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7646 - loss: 0.5295 - learning_rate: 0.0037\n",
      "Epoch 996/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7682 - loss: 0.5098 - learning_rate: 0.0037\n",
      "Epoch 997/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7470 - loss: 0.5353 - learning_rate: 0.0037\n",
      "Epoch 998/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7509 - loss: 0.5297 - learning_rate: 0.0037\n",
      "Epoch 999/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7599 - loss: 0.5192 - learning_rate: 0.0037\n",
      "Epoch 1000/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7746 - loss: 0.5054 - learning_rate: 0.0037\n",
      "Epoch 1001/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7580 - loss: 0.5145 - learning_rate: 0.0037\n",
      "Epoch 1002/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7512 - loss: 0.5407 - learning_rate: 0.0037\n",
      "Epoch 1003/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7775 - loss: 0.4972 - learning_rate: 0.0037\n",
      "Epoch 1004/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.7563 - loss: 0.5347 - learning_rate: 0.0037\n",
      "Epoch 1005/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7541 - loss: 0.5317 - learning_rate: 0.0037\n",
      "Epoch 1006/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7586 - loss: 0.5150 - learning_rate: 0.0037\n",
      "Epoch 1007/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7605 - loss: 0.5141 - learning_rate: 0.0037\n",
      "Epoch 1008/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7571 - loss: 0.5242 - learning_rate: 0.0037\n",
      "Epoch 1009/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7719 - loss: 0.5065 - learning_rate: 0.0037\n",
      "Epoch 1010/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7645 - loss: 0.5097 - learning_rate: 0.0037\n",
      "Epoch 1011/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7652 - loss: 0.4997 - learning_rate: 0.0037\n",
      "Epoch 1012/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7865 - loss: 0.4977 - learning_rate: 0.0037\n",
      "Epoch 1013/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7749 - loss: 0.5090 - learning_rate: 0.0037\n",
      "Epoch 1014/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7580 - loss: 0.5242 - learning_rate: 0.0037\n",
      "Epoch 1015/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7408 - loss: 0.5332 - learning_rate: 0.0037\n",
      "Epoch 1016/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7459 - loss: 0.5262 - learning_rate: 0.0037\n",
      "Epoch 1017/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7645 - loss: 0.5057 - learning_rate: 0.0037\n",
      "Epoch 1018/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7565 - loss: 0.5245 - learning_rate: 0.0036\n",
      "Epoch 1019/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7662 - loss: 0.5178 - learning_rate: 0.0036\n",
      "Epoch 1020/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7665 - loss: 0.5033 - learning_rate: 0.0036\n",
      "Epoch 1021/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7511 - loss: 0.5254 - learning_rate: 0.0036\n",
      "Epoch 1022/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.7897 - loss: 0.4979 - learning_rate: 0.0036\n",
      "Epoch 1023/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7586 - loss: 0.5262 - learning_rate: 0.0036\n",
      "Epoch 1024/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7693 - loss: 0.5014 - learning_rate: 0.0036\n",
      "Epoch 1025/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7553 - loss: 0.5294 - learning_rate: 0.0036\n",
      "Epoch 1026/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7654 - loss: 0.5205 - learning_rate: 0.0036\n",
      "Epoch 1027/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7638 - loss: 0.5205 - learning_rate: 0.0036\n",
      "Epoch 1028/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7623 - loss: 0.5155 - learning_rate: 0.0036\n",
      "Epoch 1029/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7582 - loss: 0.5191 - learning_rate: 0.0036\n",
      "Epoch 1030/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7619 - loss: 0.5227 - learning_rate: 0.0036\n",
      "Epoch 1031/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7643 - loss: 0.5201 - learning_rate: 0.0036\n",
      "Epoch 1032/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.7670 - loss: 0.5168 - learning_rate: 0.0036\n",
      "Epoch 1033/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7779 - loss: 0.5076 - learning_rate: 0.0036\n",
      "Epoch 1034/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7511 - loss: 0.5212 - learning_rate: 0.0036\n",
      "Epoch 1035/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7597 - loss: 0.5208 - learning_rate: 0.0036\n",
      "Epoch 1036/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7635 - loss: 0.5134 - learning_rate: 0.0036\n",
      "Epoch 1037/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7560 - loss: 0.5303 - learning_rate: 0.0036\n",
      "Epoch 1038/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7565 - loss: 0.5183 - learning_rate: 0.0036\n",
      "Epoch 1039/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7708 - loss: 0.5320 - learning_rate: 0.0036\n",
      "Epoch 1040/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7602 - loss: 0.5070 - learning_rate: 0.0036\n",
      "Epoch 1041/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7606 - loss: 0.5058 - learning_rate: 0.0036\n",
      "Epoch 1042/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7384 - loss: 0.5603 - learning_rate: 0.0036\n",
      "Epoch 1043/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7620 - loss: 0.5156 - learning_rate: 0.0036\n",
      "Epoch 1044/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7589 - loss: 0.5226 - learning_rate: 0.0036\n",
      "Epoch 1045/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7476 - loss: 0.5263 - learning_rate: 0.0036\n",
      "Epoch 1046/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7563 - loss: 0.5093 - learning_rate: 0.0035\n",
      "Epoch 1047/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7621 - loss: 0.5175 - learning_rate: 0.0035\n",
      "Epoch 1048/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7670 - loss: 0.5078 - learning_rate: 0.0035\n",
      "Epoch 1049/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7639 - loss: 0.5143 - learning_rate: 0.0035\n",
      "Epoch 1050/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7651 - loss: 0.5129 - learning_rate: 0.0035\n",
      "Epoch 1051/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7565 - loss: 0.5317 - learning_rate: 0.0035\n",
      "Epoch 1052/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7499 - loss: 0.5237 - learning_rate: 0.0035\n",
      "Epoch 1053/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7511 - loss: 0.5420 - learning_rate: 0.0035\n",
      "Epoch 1054/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7829 - loss: 0.4872 - learning_rate: 0.0035\n",
      "Epoch 1055/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7622 - loss: 0.5258 - learning_rate: 0.0035\n",
      "Epoch 1056/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7730 - loss: 0.5161 - learning_rate: 0.0035\n",
      "Epoch 1057/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7661 - loss: 0.5187 - learning_rate: 0.0035\n",
      "Epoch 1058/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7603 - loss: 0.5124 - learning_rate: 0.0035\n",
      "Epoch 1059/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7679 - loss: 0.5140 - learning_rate: 0.0035\n",
      "Epoch 1060/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7638 - loss: 0.5277 - learning_rate: 0.0035\n",
      "Epoch 1061/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7698 - loss: 0.5030 - learning_rate: 0.0035\n",
      "Epoch 1062/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7668 - loss: 0.5086 - learning_rate: 0.0035\n",
      "Epoch 1063/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7723 - loss: 0.5099 - learning_rate: 0.0035\n",
      "Epoch 1064/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7658 - loss: 0.5181 - learning_rate: 0.0035\n",
      "Epoch 1065/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7732 - loss: 0.5064 - learning_rate: 0.0035\n",
      "Epoch 1066/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7609 - loss: 0.5117 - learning_rate: 0.0035\n",
      "Epoch 1067/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7642 - loss: 0.5105 - learning_rate: 0.0035\n",
      "Epoch 1068/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7579 - loss: 0.5282 - learning_rate: 0.0035\n",
      "Epoch 1069/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7330 - loss: 0.5424 - learning_rate: 0.0035\n",
      "Epoch 1070/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7552 - loss: 0.5146 - learning_rate: 0.0035\n",
      "Epoch 1071/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7718 - loss: 0.5178 - learning_rate: 0.0035\n",
      "Epoch 1072/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7489 - loss: 0.5326 - learning_rate: 0.0035\n",
      "Epoch 1073/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7612 - loss: 0.5115 - learning_rate: 0.0035\n",
      "Epoch 1074/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7659 - loss: 0.5121 - learning_rate: 0.0035\n",
      "Epoch 1075/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7651 - loss: 0.5112 - learning_rate: 0.0034\n",
      "Epoch 1076/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7794 - loss: 0.4879 - learning_rate: 0.0034\n",
      "Epoch 1077/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7681 - loss: 0.5133 - learning_rate: 0.0034\n",
      "Epoch 1078/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7627 - loss: 0.5063 - learning_rate: 0.0034\n",
      "Epoch 1079/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7772 - loss: 0.5053 - learning_rate: 0.0034\n",
      "Epoch 1080/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7715 - loss: 0.5124 - learning_rate: 0.0034\n",
      "Epoch 1081/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7778 - loss: 0.5020 - learning_rate: 0.0034\n",
      "Epoch 1082/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7634 - loss: 0.5221 - learning_rate: 0.0034\n",
      "Epoch 1083/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7844 - loss: 0.5054 - learning_rate: 0.0034\n",
      "Epoch 1084/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7751 - loss: 0.5124 - learning_rate: 0.0034\n",
      "Epoch 1085/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7626 - loss: 0.5134 - learning_rate: 0.0034\n",
      "Epoch 1086/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7679 - loss: 0.5085 - learning_rate: 0.0034\n",
      "Epoch 1087/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7595 - loss: 0.5159 - learning_rate: 0.0034\n",
      "Epoch 1088/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7660 - loss: 0.5238 - learning_rate: 0.0034\n",
      "Epoch 1089/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7529 - loss: 0.5220 - learning_rate: 0.0034\n",
      "Epoch 1090/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7787 - loss: 0.4941 - learning_rate: 0.0034\n",
      "Epoch 1091/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.7683 - loss: 0.5048 - learning_rate: 0.0034\n",
      "Epoch 1092/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7539 - loss: 0.5307 - learning_rate: 0.0034\n",
      "Epoch 1093/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7639 - loss: 0.5143 - learning_rate: 0.0034\n",
      "Epoch 1094/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7667 - loss: 0.5044 - learning_rate: 0.0034\n",
      "Epoch 1095/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7657 - loss: 0.5165 - learning_rate: 0.0034\n",
      "Epoch 1096/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7584 - loss: 0.5256 - learning_rate: 0.0034\n",
      "Epoch 1097/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7579 - loss: 0.5288 - learning_rate: 0.0034\n",
      "Epoch 1098/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7730 - loss: 0.4998 - learning_rate: 0.0034\n",
      "Epoch 1099/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.7746 - loss: 0.5048 - learning_rate: 0.0034\n",
      "Epoch 1100/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7710 - loss: 0.5088 - learning_rate: 0.0034\n",
      "Epoch 1101/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7689 - loss: 0.5087 - learning_rate: 0.0034\n",
      "Epoch 1102/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7630 - loss: 0.5187 - learning_rate: 0.0034\n",
      "Epoch 1103/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.7665 - loss: 0.5053 - learning_rate: 0.0034\n",
      "Epoch 1104/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7647 - loss: 0.5083 - learning_rate: 0.0033\n",
      "Epoch 1105/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7610 - loss: 0.5282 - learning_rate: 0.0033\n",
      "Epoch 1106/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7554 - loss: 0.5288 - learning_rate: 0.0033\n",
      "Epoch 1107/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.7554 - loss: 0.5317 - learning_rate: 0.0033\n",
      "Epoch 1108/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7682 - loss: 0.5149 - learning_rate: 0.0033\n",
      "Epoch 1109/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7668 - loss: 0.5245 - learning_rate: 0.0033\n",
      "Epoch 1110/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7907 - loss: 0.4922 - learning_rate: 0.0033\n",
      "Epoch 1111/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.7598 - loss: 0.5285 - learning_rate: 0.0033\n",
      "Epoch 1112/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7502 - loss: 0.5345 - learning_rate: 0.0033\n",
      "Epoch 1113/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7637 - loss: 0.5148 - learning_rate: 0.0033\n",
      "Epoch 1114/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7750 - loss: 0.5093 - learning_rate: 0.0033\n",
      "Epoch 1115/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7578 - loss: 0.5171 - learning_rate: 0.0033\n",
      "Epoch 1116/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7751 - loss: 0.5005 - learning_rate: 0.0033\n",
      "Epoch 1117/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7656 - loss: 0.5299 - learning_rate: 0.0033\n",
      "Epoch 1118/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7760 - loss: 0.5114 - learning_rate: 0.0033\n",
      "Epoch 1119/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.7721 - loss: 0.5117 - learning_rate: 0.0033\n",
      "Epoch 1120/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7751 - loss: 0.5136 - learning_rate: 0.0033\n",
      "Epoch 1121/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7793 - loss: 0.5001 - learning_rate: 0.0033\n",
      "Epoch 1122/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7786 - loss: 0.5085 - learning_rate: 0.0033\n",
      "Epoch 1123/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7800 - loss: 0.4953 - learning_rate: 0.0033\n",
      "Epoch 1124/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7549 - loss: 0.5240 - learning_rate: 0.0033\n",
      "Epoch 1125/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7858 - loss: 0.5059 - learning_rate: 0.0033\n",
      "Epoch 1126/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7603 - loss: 0.5123 - learning_rate: 0.0033\n",
      "Epoch 1127/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7793 - loss: 0.5057 - learning_rate: 0.0033\n",
      "Epoch 1128/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7600 - loss: 0.5270 - learning_rate: 0.0033\n",
      "Epoch 1129/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7637 - loss: 0.5205 - learning_rate: 0.0033\n",
      "Epoch 1130/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7784 - loss: 0.4964 - learning_rate: 0.0033\n",
      "Epoch 1131/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7637 - loss: 0.5213 - learning_rate: 0.0033\n",
      "Epoch 1132/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7570 - loss: 0.5326 - learning_rate: 0.0033\n",
      "Epoch 1133/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7601 - loss: 0.5170 - learning_rate: 0.0033\n",
      "Epoch 1134/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7693 - loss: 0.4916 - learning_rate: 0.0032\n",
      "Epoch 1135/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.7676 - loss: 0.5142 - learning_rate: 0.0032\n",
      "Epoch 1136/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7803 - loss: 0.5091 - learning_rate: 0.0032\n",
      "Epoch 1137/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7722 - loss: 0.5171 - learning_rate: 0.0032\n",
      "Epoch 1138/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7744 - loss: 0.5134 - learning_rate: 0.0032\n",
      "Epoch 1139/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.7644 - loss: 0.5088 - learning_rate: 0.0032\n",
      "Epoch 1140/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.7739 - loss: 0.5046 - learning_rate: 0.0032\n",
      "Epoch 1141/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7747 - loss: 0.5050 - learning_rate: 0.0032\n",
      "Epoch 1142/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7794 - loss: 0.5030 - learning_rate: 0.0032\n",
      "Epoch 1143/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.7845 - loss: 0.5096 - learning_rate: 0.0032\n",
      "Epoch 1144/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7664 - loss: 0.5235 - learning_rate: 0.0032\n",
      "Epoch 1145/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7601 - loss: 0.5187 - learning_rate: 0.0032\n",
      "Epoch 1146/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7825 - loss: 0.4908 - learning_rate: 0.0032\n",
      "Epoch 1147/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7550 - loss: 0.5216 - learning_rate: 0.0032\n",
      "Epoch 1148/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7569 - loss: 0.5184 - learning_rate: 0.0032\n",
      "Epoch 1149/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7721 - loss: 0.4982 - learning_rate: 0.0032\n",
      "Epoch 1150/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7731 - loss: 0.5005 - learning_rate: 0.0032\n",
      "Epoch 1151/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7750 - loss: 0.5074 - learning_rate: 0.0032\n",
      "Epoch 1152/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7688 - loss: 0.5224 - learning_rate: 0.0032\n",
      "Epoch 1153/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7690 - loss: 0.5084 - learning_rate: 0.0032\n",
      "Epoch 1154/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7779 - loss: 0.5016 - learning_rate: 0.0032\n",
      "Epoch 1155/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7740 - loss: 0.4992 - learning_rate: 0.0032\n",
      "Epoch 1156/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.7809 - loss: 0.4974 - learning_rate: 0.0032\n",
      "Epoch 1157/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7701 - loss: 0.5082 - learning_rate: 0.0032\n",
      "Epoch 1158/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7790 - loss: 0.5016 - learning_rate: 0.0032\n",
      "Epoch 1159/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7577 - loss: 0.5199 - learning_rate: 0.0032\n",
      "Epoch 1160/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7812 - loss: 0.5011 - learning_rate: 0.0032\n",
      "Epoch 1161/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7736 - loss: 0.5136 - learning_rate: 0.0032\n",
      "Epoch 1162/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7774 - loss: 0.4950 - learning_rate: 0.0032\n",
      "Epoch 1163/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7779 - loss: 0.4985 - learning_rate: 0.0032\n",
      "Epoch 1164/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7506 - loss: 0.5303 - learning_rate: 0.0032\n",
      "Epoch 1165/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7739 - loss: 0.5100 - learning_rate: 0.0032\n",
      "Epoch 1166/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7645 - loss: 0.5158 - learning_rate: 0.0031\n",
      "Epoch 1167/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7628 - loss: 0.5202 - learning_rate: 0.0031\n",
      "Epoch 1168/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7691 - loss: 0.5179 - learning_rate: 0.0031\n",
      "Epoch 1169/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7611 - loss: 0.5259 - learning_rate: 0.0031\n",
      "Epoch 1170/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7710 - loss: 0.5064 - learning_rate: 0.0031\n",
      "Epoch 1171/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7768 - loss: 0.5002 - learning_rate: 0.0031\n",
      "Epoch 1172/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7772 - loss: 0.5054 - learning_rate: 0.0031\n",
      "Epoch 1173/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7671 - loss: 0.5097 - learning_rate: 0.0031\n",
      "Epoch 1174/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7651 - loss: 0.5189 - learning_rate: 0.0031\n",
      "Epoch 1175/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7744 - loss: 0.5003 - learning_rate: 0.0031\n",
      "Epoch 1176/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7612 - loss: 0.5124 - learning_rate: 0.0031\n",
      "Epoch 1177/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.7801 - loss: 0.5033 - learning_rate: 0.0031\n",
      "Epoch 1178/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7805 - loss: 0.5023 - learning_rate: 0.0031\n",
      "Epoch 1179/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7626 - loss: 0.5114 - learning_rate: 0.0031\n",
      "Epoch 1180/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7670 - loss: 0.5087 - learning_rate: 0.0031\n",
      "Epoch 1181/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7835 - loss: 0.4909 - learning_rate: 0.0031\n",
      "Epoch 1182/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7831 - loss: 0.5021 - learning_rate: 0.0031\n",
      "Epoch 1183/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7788 - loss: 0.4973 - learning_rate: 0.0031\n",
      "Epoch 1184/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7811 - loss: 0.4982 - learning_rate: 0.0031\n",
      "Epoch 1185/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7764 - loss: 0.4943 - learning_rate: 0.0031\n",
      "Epoch 1186/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.7592 - loss: 0.5228 - learning_rate: 0.0031\n",
      "Epoch 1187/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7687 - loss: 0.5195 - learning_rate: 0.0031\n",
      "Epoch 1188/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7609 - loss: 0.5193 - learning_rate: 0.0031\n",
      "Epoch 1189/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7838 - loss: 0.4946 - learning_rate: 0.0031\n",
      "Epoch 1190/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.7630 - loss: 0.5072 - learning_rate: 0.0031\n",
      "Epoch 1191/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7822 - loss: 0.4857 - learning_rate: 0.0031\n",
      "Epoch 1192/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7759 - loss: 0.4994 - learning_rate: 0.0031\n",
      "Epoch 1193/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7704 - loss: 0.4970 - learning_rate: 0.0031\n",
      "Epoch 1194/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7805 - loss: 0.5083 - learning_rate: 0.0031\n",
      "Epoch 1195/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7689 - loss: 0.5074 - learning_rate: 0.0031\n",
      "Epoch 1196/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7608 - loss: 0.5238 - learning_rate: 0.0031\n",
      "Epoch 1197/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7708 - loss: 0.5052 - learning_rate: 0.0031\n",
      "Epoch 1198/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7555 - loss: 0.5165 - learning_rate: 0.0030\n",
      "Epoch 1199/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.7739 - loss: 0.5111 - learning_rate: 0.0030\n",
      "Epoch 1200/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7680 - loss: 0.5028 - learning_rate: 0.0030\n",
      "Epoch 1201/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7879 - loss: 0.4993 - learning_rate: 0.0030\n",
      "Epoch 1202/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.7923 - loss: 0.4901 - learning_rate: 0.0030\n",
      "Epoch 1203/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7717 - loss: 0.5057 - learning_rate: 0.0030\n",
      "Epoch 1204/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7659 - loss: 0.5071 - learning_rate: 0.0030\n",
      "Epoch 1205/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7749 - loss: 0.4934 - learning_rate: 0.0030\n",
      "Epoch 1206/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.7842 - loss: 0.4987 - learning_rate: 0.0030\n",
      "Epoch 1207/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7780 - loss: 0.4983 - learning_rate: 0.0030\n",
      "Epoch 1208/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7885 - loss: 0.4905 - learning_rate: 0.0030\n",
      "Epoch 1209/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7980 - loss: 0.4815 - learning_rate: 0.0030\n",
      "Epoch 1210/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7602 - loss: 0.5155 - learning_rate: 0.0030\n",
      "Epoch 1211/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7689 - loss: 0.5152 - learning_rate: 0.0030\n",
      "Epoch 1212/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7732 - loss: 0.4985 - learning_rate: 0.0030\n",
      "Epoch 1213/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7743 - loss: 0.5056 - learning_rate: 0.0030\n",
      "Epoch 1214/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.7762 - loss: 0.5038 - learning_rate: 0.0030\n",
      "Epoch 1215/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7706 - loss: 0.5039 - learning_rate: 0.0030\n",
      "Epoch 1216/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7637 - loss: 0.5288 - learning_rate: 0.0030\n",
      "Epoch 1217/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7744 - loss: 0.4969 - learning_rate: 0.0030\n",
      "Epoch 1218/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7668 - loss: 0.5135 - learning_rate: 0.0030\n",
      "Epoch 1219/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7853 - loss: 0.4951 - learning_rate: 0.0030\n",
      "Epoch 1220/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7637 - loss: 0.5089 - learning_rate: 0.0030\n",
      "Epoch 1221/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7717 - loss: 0.5048 - learning_rate: 0.0030\n",
      "Epoch 1222/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7873 - loss: 0.4927 - learning_rate: 0.0030\n",
      "Epoch 1223/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7764 - loss: 0.4961 - learning_rate: 0.0030\n",
      "Epoch 1224/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7671 - loss: 0.5118 - learning_rate: 0.0030\n",
      "Epoch 1225/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7827 - loss: 0.4979 - learning_rate: 0.0030\n",
      "Epoch 1226/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.7646 - loss: 0.5226 - learning_rate: 0.0030\n",
      "Epoch 1227/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7810 - loss: 0.4982 - learning_rate: 0.0030\n",
      "Epoch 1228/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7549 - loss: 0.5203 - learning_rate: 0.0030\n",
      "Epoch 1229/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7869 - loss: 0.4903 - learning_rate: 0.0030\n",
      "Epoch 1230/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7856 - loss: 0.4884 - learning_rate: 0.0030\n",
      "Epoch 1231/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7749 - loss: 0.5082 - learning_rate: 0.0029\n",
      "Epoch 1232/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7830 - loss: 0.4961 - learning_rate: 0.0029\n",
      "Epoch 1233/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7813 - loss: 0.4903 - learning_rate: 0.0029\n",
      "Epoch 1234/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7699 - loss: 0.5102 - learning_rate: 0.0029\n",
      "Epoch 1235/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7663 - loss: 0.5159 - learning_rate: 0.0029\n",
      "Epoch 1236/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7643 - loss: 0.5044 - learning_rate: 0.0029\n",
      "Epoch 1237/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7694 - loss: 0.5008 - learning_rate: 0.0029\n",
      "Epoch 1238/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7884 - loss: 0.4954 - learning_rate: 0.0029\n",
      "Epoch 1239/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7669 - loss: 0.5156 - learning_rate: 0.0029\n",
      "Epoch 1240/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7864 - loss: 0.4797 - learning_rate: 0.0029\n",
      "Epoch 1241/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7900 - loss: 0.4932 - learning_rate: 0.0029\n",
      "Epoch 1242/1500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7724 - loss: 0.5159 - learning_rate: 0.0029\n",
      "Epoch 1243/1500\n",
      "\u001b[1m 1/67\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7812 - loss: 0.4724"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.001).numpy())\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                             # patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_generator, batch_size=1024, epochs=1500, callbacks=[lr_scheduler ]) #default batch=32\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7554 - loss: 0.5576\n",
      "Final test set loss: 0.598434\n",
      "Final test set accuracy: 0.726562\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(Xtest, ytest)\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_ = range(1,len(acc)+1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_, acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs_, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_, loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs_, val_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], 'r', label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 使用相同的 history 對象\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplot_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m, in \u001b[0;36mplot_accuracy\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and Validation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], 'r', label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'b', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 使用相同的 history 對象\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_excel(\"01test.xlsx\")\n",
    "\n",
    "feature_ex = ['手機螢幕溫度(平均)', '手機背蓋溫度(平均)', '充電時間指標', '手機電池電量', 'CPU跑分階級', '上網頻率指標', '通話頻率指標', '內容容量比率']\n",
    "test_data = test[feature_ex].to_numpy()\n",
    "\n",
    "test_data=data_normalized(test_data)\n",
    "test_data=data_standardized(test_data)\n",
    "test_data=data_normalized(test_data)\n",
    "test_data=data_standardized(test_data)\n",
    "\n",
    "pca=PCA(n_components=6)\n",
    "test_data_pca=pca.fit(test_data).transform(test_data)\n",
    "test_data=test_data_pca\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans = model.predict(test_data)\n",
    "print(np.mean(predicted_ans))\n",
    "predicted_classes = (predicted_ans > 0.5).astype(int)\n",
    "\n",
    "\n",
    "print(predicted_classes .shape)\n",
    "\n",
    "if predicted_classes .ndim > 1:\n",
    "    predicted_classes  = predicted_classes .squeeze()\n",
    "print(predicted_classes .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'id': test.id, 'Underclocking': predicted_classes })\n",
    "my_submission.to_csv('submision_67_7472.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model-cross \n",
    "def create_model(input_dim):\n",
    "    l2_regularizer = tf.keras.regularizers.l2(0.001)\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_features,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),   \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "input_dim = x_data.shape[1]  # 获取输入特征的数量\n",
    "\n",
    "for train_index, test_index in kf.split(x_data):\n",
    "    # 分割数据\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    # 创建模型\n",
    "    model = create_model(input_dim)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # 评估模型\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    scores.append(score[1])  # 假设我们关心的是准确率\n",
    "\n",
    "# 打印每折的准确率以及平均准确率\n",
    "print(\"每折的准确率:\", scores)\n",
    "print(\"平均准确率:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "def build_model(n_layers, input_dim, regularization_rate=0.01, dropout_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(input_dim,), kernel_regularizer=l2(regularization_rate)))\n",
    "    for _ in range(n_layers - 1):\n",
    "        model.add(Dense(64 // _ if 64 // _ > 4 else 4, activation='relu', kernel_regularizer=l2(regularization_rate)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, y_train, x_test, y_test, epochs=50):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), verbose=0)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_data.shape[1]  # 假設x_data已經定義並準備好了\n",
    "regularization_rate = 0.01\n",
    "dropout_rate = 0.001\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "max_layers = 20  # 嘗試的最大層數\n",
    "results = {}\n",
    "\n",
    "for n_layers in range(1, max_layers + 1):\n",
    "    model = build_model(n_layers, input_dim, regularization_rate, dropout_rate)\n",
    "    history = evaluate_model(model, x_train, y_train, x_test, y_test)\n",
    "    accuracy = np.max(history.history['val_accuracy'])  # 取最好的驗證準確率\n",
    "    results[n_layers] = accuracy\n",
    "    print(f\"Tested {n_layers} layers: Validation Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# 找到最佳層數\n",
    "best_layers = max(results, key=results.get)\n",
    "print(f\"Best number of layers: {best_layers} with Accuracy: {results[best_layers]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ecaae8ee4afd5bfff7a9898a6bb698a1db0284ded0ac21bd42c4412026a1621f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
